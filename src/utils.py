"""Utility helpers for logging, dedupe, and formatting."""

from __future__ import annotations

import hashlib
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Set

import colorlog


def setup_logger(name: str, level: str = "INFO") -> logging.Logger:
    """Configure a color logger that also writes to file."""
    logger = logging.getLogger(name)
    logger.setLevel(getattr(logging, level.upper(), logging.INFO))

    if logger.handlers:
        return logger

    console_handler = colorlog.StreamHandler()
    console_handler.setFormatter(
        colorlog.ColoredFormatter(
            "%(log_color)s%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            log_colors={
                "DEBUG": "cyan",
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "CRITICAL": "red,bg_white",
            },
        )
    )
    logger.addHandler(console_handler)

    Path("./logs").mkdir(exist_ok=True)
    file_handler = logging.FileHandler("./logs/app.log", encoding="utf-8")
    file_handler.setFormatter(
        logging.Formatter("%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    )
    logger.addHandler(file_handler)

    return logger


class MessageDeduplicator:
    """Deduplicate messages by hash within a time window."""

    def __init__(self, window_hours: int = 24):
        self.seen_hashes: Dict[str, datetime] = {}
        self.window_hours = window_hours

    def is_duplicate(self, text: str) -> bool:
        """Return True if the message text appeared recently."""
        self._cleanup_expired()

        message_hash = hashlib.md5(text.encode("utf-8")).hexdigest()
        if message_hash in self.seen_hashes:
            return True

        self.seen_hashes[message_hash] = datetime.now()
        return False

    def _cleanup_expired(self) -> None:
        cutoff = datetime.now() - timedelta(hours=self.window_hours)
        expired = [key for key, timestamp in self.seen_hashes.items() if timestamp < cutoff]
        for key in expired:
            del self.seen_hashes[key]


def contains_keywords(text: str, keywords: Set[str]) -> bool:
    """Check if text contains any keyword (case-insensitive)."""
    if not keywords:
        return True

    text_lower = text.lower()
    return any(keyword in text_lower for keyword in keywords)


ACTION_LABELS = {
    "buy": "ä¹°å…¥",
    "sell": "å–å‡º",
    "observe": "è§‚æœ›",
}

STRENGTH_LABELS = {
    "low": "ä½",
    "medium": "ä¸­",
    "high": "é«˜",
}

DIRECTION_LABELS = {
    "long": "åšå¤š",
    "short": "åšç©º",
    "neutral": "ä¸­æ€§",
}

EVENT_TYPE_LABELS = {
    "listing": "ä¸Šçº¿/æŒ‚ç‰Œ",
    "delisting": "ä¸‹æ¶/é€€å¸‚",
    "hack": "å®‰å…¨/æ”»å‡»",
    "regulation": "ç›‘ç®¡/æ”¿ç­–",
    "funding": "èèµ„/å‹Ÿèµ„",
    "whale": "å·¨é²¸åŠ¨å‘",
    "liquidation": "æ¸…ç®—/çˆ†ä»“",
    "partnership": "åˆä½œ/é›†æˆ",
    "product_launch": "äº§å“å‘å¸ƒ/ä¸»ç½‘",
    "governance": "æ²»ç†ææ¡ˆ",
    "macro": "å®è§‚åŠ¨å‘",
    "celebrity": "åäººè¨€è®º",
    "airdrop": "ç©ºæŠ•æ¿€åŠ±",
    "other": "å…¶ä»–",
}

RISK_FLAG_LABELS = {
    "price_volatility": "ä»·æ ¼æ³¢åŠ¨",
    "liquidity_risk": "æµåŠ¨æ€§é£é™©",
    "regulation_risk": "åˆè§„é£é™©",
    "confidence_low": "ç½®ä¿¡åº¦ä½",
    "data_incomplete": "ä¿¡æ¯ä¸å®Œæ•´",
}


def format_forwarded_message(
    *,
    source_channel: str,
    timestamp: datetime,
    translated_text: str | None = None,
    original_text: str | None = None,
    show_original: bool = False,
    ai_summary: str | None = None,
    ai_action: str | None = None,
    ai_direction: str | None = None,
    ai_event_type: str | None = None,
    ai_asset: str | None = None,
    ai_asset_names: str | None = None,
    ai_confidence: float | None = None,
    ai_strength: str | None = None,
    ai_risk_flags: list[str] | None = None,
    ai_notes: str | None = None,
) -> str:
    """Compose a compact forwarding message emphasising actionable insights."""

    ai_risk_flags = ai_risk_flags or []
    ai_notes = (ai_notes or "").strip()
    ai_asset = (ai_asset or "").strip()
    ai_asset_names = (ai_asset_names or "").strip()
    translated_text = (translated_text or "").strip()
    original_text = (original_text or "").strip()

    parts: list[str] = ["ğŸ”” **åŠ å¯†æ–°é—»ç›‘å¬**\n\n"]

    # ä¿¡å·æ‘˜è¦ï¼šç¿»è¯‘æ–‡æœ¬ä¸ AI æ‘˜è¦åˆ†åˆ«åˆ—å‡ºï¼Œä¾¿äºå¿«é€Ÿæµè§ˆ
    summary_segments: list[str] = []
    if translated_text:
        summary_segments.append(translated_text)
    elif original_text:
        summary_segments.append(original_text)

    if ai_summary and ai_summary not in summary_segments:
        summary_segments.append(ai_summary)

    if summary_segments:
        parts.append("âš¡ **ä¿¡å·æ‘˜è¦**\n")
        for segment in summary_segments:
            parts.append(f"- {segment}\n")
        parts.append("\n")

    # æ“ä½œè¦ç‚¹ï¼Œä»…å½“æœ‰ AI ç»“æœæ—¶å±•ç¤º
    if ai_summary:
        action_value = ACTION_LABELS.get(ai_action or "observe", ai_action or "observe")
        confidence_text = (
            f"{ai_confidence:.2f}" if ai_confidence is not None else "æœªçŸ¥"
        )
        parts.append("ğŸ¯ **æ“ä½œè¦ç‚¹**\n")

        if ai_asset or ai_asset_names:
            asset_line = ai_asset
            if ai_asset_names and ai_asset:
                asset_line = f"{ai_asset_names} ({ai_asset})"
            elif ai_asset_names:
                asset_line = ai_asset_names
            elif ai_asset:
                asset_line = ai_asset
            else:
                asset_line = "æœªè¯†åˆ«"
            parts.append(f"- **æ ‡çš„**: {asset_line}\n")

        parts.append(f"- **åŠ¨ä½œ**: {action_value}")
        if ai_direction:
            direction_cn = DIRECTION_LABELS.get(ai_direction, ai_direction)
            parts[-1] += f"ï¼ˆæ–¹å‘: {direction_cn}ï¼‰"
        parts[-1] += "\n"

        parts.append(f"- **ç½®ä¿¡åº¦**: {confidence_text}")
        if ai_strength:
            strength_cn = STRENGTH_LABELS.get(ai_strength, ai_strength)
            parts[-1] += f" Â· å¼ºåº¦: {strength_cn}"
        parts[-1] += "\n"

        localized_flags = [
            RISK_FLAG_LABELS.get(flag, flag) for flag in ai_risk_flags if flag
        ]
        if localized_flags:
            parts.append(f"- âš ï¸ **é£é™©**: {'ã€'.join(localized_flags)}\n")

        if ai_notes:
            parts.append(f"- ğŸ“ **å¤‡æ³¨**: {ai_notes}\n")

        parts.append("\n")

    # æ¥æºä¸æ—¶é—´
    parts.append(f"ğŸ“¡ **æ¥æº**: {source_channel}\n")
    parts.append(f"ğŸ•’ **æ—¶é—´**: {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\n")

    # åŸæ–‡è§†æƒ…å†µå±•ç¤º
    if show_original and original_text:
        parts.append("\nğŸ§¾ **åŸæ–‡**\n")
        parts.append(f"```\n{original_text}\n```\n")

    return "".join(parts)
