"""Supabase-backed memory retrieval implementation."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from typing import Iterable, Sequence

from ..db.repositories import MemoryRepository as UnifiedMemoryRepository
from ..db.supabase_client import SupabaseClient, SupabaseError
from ..utils import setup_logger
from .types import MemoryContext, MemoryEntry


logger = setup_logger(__name__)


@dataclass
class MemoryRepositoryConfig:
    """Configuration parameters controlling memory retrieval."""

    max_notes: int = 3
    similarity_threshold: float = 0.85
    lookback_hours: int = 72
    min_confidence: float = 0.6


class SupabaseMemoryRepository:
    """Fetch past AI signals for prompt enrichment."""

    def __init__(self, client: SupabaseClient, config: MemoryRepositoryConfig | None = None) -> None:
        self._client = client
        self._config = config or MemoryRepositoryConfig()
        # ä½¿ç”¨ç»Ÿä¸€çš„ MemoryRepository æ¥è°ƒç”¨æ–°çš„ search_memory RPC
        self._unified_repo = UnifiedMemoryRepository(client)

    async def fetch_memories(
        self,
        *,
        embedding: Sequence[float] | None,
        asset_codes: Iterable[str] | None = None,
        keywords: Iterable[str] | None = None,
    ) -> MemoryContext:
        """Retrieve similar events from Supabase via unified search_memory RPC.

        Args:
            embedding: Vector representing current message semantics.
            asset_codes: Optional list of asset codes to narrow the search.
            keywords: Optional list of keywords for keyword-based search fallback.
        """
        # å¦‚æœæ²¡æœ‰ embeddingï¼Œä½¿ç”¨å…³é”®è¯æ£€ç´¢ï¼›å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›ç©º
        if embedding is None and not keywords:
            return MemoryContext()

        try:
            if embedding is not None:
                if len(embedding) == 0:
                    logger.debug("ğŸ” è·³è¿‡ Supabase æ£€ç´¢ï¼šembedding å‘é‡ä¸ºç©º")
                    embedding = None
        except TypeError:  # pragma: no cover - tolerate non-sized sequences
            logger.debug("ğŸ” æ— æ³•è·å– embedding é•¿åº¦ï¼Œç»§ç»­æ‰§è¡Œ Supabase æ£€ç´¢")

        # å‡†å¤‡å…³é”®è¯åˆ—è¡¨
        keyword_list = [kw.strip() for kw in (keywords or []) if kw and kw.strip()]
        asset_list = [code.strip().upper() for code in (asset_codes or []) if code and code.strip()]

        logger.info(
            f"ğŸ” SupabaseMemoryRepository: å¼€å§‹ç»Ÿä¸€æ£€ç´¢ (RPC: search_memory) - "
            f"threshold={self._config.similarity_threshold:.2f}, "
            f"count={self._config.max_notes}, "
            f"min_confidence={self._config.min_confidence:.2f}, "
            f"time_window={self._config.lookback_hours}h, "
            f"assets={asset_list or 'æ— '}, "
            f"keywords={keyword_list if keyword_list else 'æ— '}, "
            f"embedding={'æœ‰' if embedding else 'æ— '}"
        )

        try:
            # è°ƒç”¨ç»Ÿä¸€çš„ search_memory RPCï¼ˆå‘é‡ä¼˜å…ˆï¼Œè‡ªåŠ¨é™çº§å…³é”®è¯ï¼‰
            search_result = await self._unified_repo.search_memory(
                embedding_1536=list(embedding) if embedding else None,
                keywords=keyword_list if keyword_list else None,
                asset_codes=asset_list if asset_list else None,
                match_threshold=float(self._config.similarity_threshold),
                min_confidence=float(self._config.min_confidence),
                time_window_hours=int(self._config.lookback_hours),
                match_count=int(self._config.max_notes),
            )

            hits = search_result.get("hits", [])
            stats = search_result.get("stats", {})
            total_hits = stats.get("total", 0)
            vector_hits = stats.get("vector", 0)
            keyword_hits = stats.get("keyword", 0)

            logger.info(
                f"âœ… SupabaseMemoryRepository: ç»Ÿä¸€æ£€ç´¢å®Œæˆ - "
                f"total={total_hits}, vector={vector_hits}, keyword={keyword_hits}"
            )

            # å±•ç¤ºè¿”å›çš„ hits æ‘˜è¦ä¿¡æ¯
            if hits:
                logger.info(f"ğŸ“‹ RPC è¿”å›ç»“æœæ‘˜è¦ ({len(hits)} æ¡):")
                for idx, hit in enumerate(hits[:5], 1):  # æœ€å¤šæ˜¾ç¤ºå‰5æ¡
                    match_type = hit.get("match_type", "unknown")
                    similarity = hit.get("similarity") or hit.get("combined_score") or 0.0
                    event_id = hit.get("news_event_id", "N/A")
                    content_preview = (
                        (hit.get("translated_text") or hit.get("content_text") or "")[:60]
                    ).replace("\n", " ")
                    logger.info(
                        f"  [{idx}] match_type={match_type}, similarity={similarity:.3f}, "
                        f"event_id={event_id}, preview={content_preview}..."
                    )
                if len(hits) > 5:
                    logger.info(f"  ... è¿˜æœ‰ {len(hits) - 5} æ¡ç»“æœ")

            if total_hits == 0:
                logger.debug(
                    f"âš ï¸ ç»Ÿä¸€æ£€ç´¢è¿”å›ç©ºç»“æœ - å¯èƒ½åŸå› :\n"
                    f"   1) æ—¶é—´çª—å£å¤ªçŸ­ ({self._config.lookback_hours}h)\n"
                    f"   2) ç›¸ä¼¼åº¦é˜ˆå€¼å¤ªé«˜ ({self._config.similarity_threshold})\n"
                    f"   3) ç½®ä¿¡åº¦é˜ˆå€¼å¤ªé«˜ ({self._config.min_confidence})\n"
                    f"   4) æ•°æ®åº“ä¸­æ— åŒ¹é…è®°å½•"
                )
                return MemoryContext()

        except SupabaseError as exc:
            logger.warning(f"âš ï¸  SupabaseMemoryRepository: RPC search_memory è°ƒç”¨å¤±è´¥ - {exc}")
            return MemoryContext()
        except Exception as exc:  # pylint: disable=broad-except
            logger.warning(f"âš ï¸  SupabaseMemoryRepository: è®°å¿†æ£€ç´¢å‡ºç°æœªçŸ¥å¼‚å¸¸ - {exc}")
            return MemoryContext()

        # æ ¹æ® news_event_id æŸ¥è¯¢å®Œæ•´çš„ä¿¡å·ä¿¡æ¯
        entries: list[MemoryEntry] = []
        logger.info(f"ğŸ” å¼€å§‹å¤„ç† {len(hits)} æ¡ RPC è¿”å›ç»“æœï¼Œæ„å»º MemoryEntry...")
        for idx, hit in enumerate(hits):
            if not isinstance(hit, dict):
                logger.warning(f"â­ï¸  ç¬¬ {idx} æ¡: è·³è¿‡ï¼ˆéå­—å…¸ç±»å‹ï¼‰")
                continue

            news_event_id = hit.get("news_event_id")
            if not news_event_id:
                logger.warning(f"â­ï¸  ç¬¬ {idx} æ¡: è·³è¿‡ï¼ˆç¼ºå°‘ news_event_idï¼‰")
                continue

            # æ ¹æ® news_event_id æŸ¥è¯¢ ai_signals è·å–å®Œæ•´ä¿¡æ¯
            try:
                signal_record = await self._client.select_one(
                    "ai_signals",
                    filters={"news_event_id": news_event_id},
                    columns="id,summary_cn,assets,action,confidence,created_at",
                )

                if not signal_record:
                    # å¦‚æœæ²¡æœ‰ä¿¡å·è®°å½•ï¼Œå°è¯•ä½¿ç”¨ RPC è¿”å›çš„æ•°æ®æˆ–æŸ¥è¯¢ news_events
                    logger.info(f"âš ï¸  ç¬¬ {idx} æ¡ (event_id={news_event_id}): æœªæ‰¾åˆ° ai_signalsï¼Œå°è¯•ä» RPC æ•°æ®æˆ– news_events è·å–")
                    
                    # ä¼˜å…ˆä½¿ç”¨ RPC è¿”å›çš„æ–‡æœ¬å­—æ®µï¼ˆé¿å…é¢å¤–çš„æ•°æ®åº“æŸ¥è¯¢ï¼‰
                    summary = (
                        hit.get("translated_text")
                        or hit.get("content_text")
                        or ""
                    )
                    
                    # å°è¯•ä» news_events è·å–æ›´å¤šä¿¡æ¯ï¼ˆåŒ…æ‹¬ created_atï¼‰
                    event_record = await self._client.select_one(
                        "news_events",
                        filters={"id": news_event_id},
                        columns="id,created_at,summary,translated_text",
                    )
                    
                    if event_record:
                        # å¦‚æœæ‰¾åˆ° event_recordï¼Œä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„æ–‡æœ¬ï¼ˆå¯èƒ½æ›´å®Œæ•´ï¼‰
                        summary = (
                            event_record.get("summary")
                            or event_record.get("translated_text")
                            or summary  # å›é€€åˆ° RPC è¿”å›çš„æ•°æ®
                        )
                        created_raw = event_record.get("created_at")
                    else:
                        # å¦‚æœæ²¡æœ‰ event_recordï¼Œä½¿ç”¨ RPC è¿”å›çš„ created_at
                        created_raw = hit.get("created_at")
                        logger.info(f"âš ï¸  ç¬¬ {idx} æ¡ (event_id={news_event_id}): æœªæ‰¾åˆ° news_events è®°å½•ï¼Œä½¿ç”¨ RPC è¿”å›çš„æ•°æ®")
                    
                    # åªè¦æœ‰ summaryï¼Œå°±åˆ›å»ºæ¡ç›®
                    if summary and summary.strip():
                        try:
                            created_at = (
                                datetime.fromisoformat(created_raw.replace("Z", "+00:00"))
                                if isinstance(created_raw, str) and created_raw
                                else datetime.utcnow()
                            )
                        except (TypeError, ValueError):
                            created_at = datetime.utcnow()

                        entry = MemoryEntry(
                            id=str(news_event_id),
                            created_at=created_at,
                            assets=[],
                            action="observe",
                            confidence=0.0,
                            summary=summary.strip(),
                            similarity=float(hit.get("similarity") or hit.get("combined_score") or 0.0),
                        )
                        entries.append(entry)
                        logger.info(
                            f"âœ… ç¬¬ {idx} æ¡: åˆ›å»º MemoryEntry - event_id={news_event_id}, "
                            f"summary_len={len(summary)}, source={'news_events' if event_record else 'RPC'}"
                        )
                    else:
                        logger.warning(
                            f"â­ï¸  ç¬¬ {idx} æ¡ (event_id={news_event_id}): è·³è¿‡ï¼ˆsummary ä¸ºç©ºï¼‰ - "
                            f"RPC translated_text={bool(hit.get('translated_text'))}, "
                            f"RPC content_text={bool(hit.get('content_text'))}, "
                            f"event_record={'å­˜åœ¨' if event_record else 'ä¸å­˜åœ¨'}"
                        )
                    continue

                # è§£æä¿¡å·è®°å½•
                created_raw = signal_record.get("created_at") or hit.get("created_at")
                try:
                    created_at = (
                        datetime.fromisoformat(created_raw.replace("Z", "+00:00"))
                        if isinstance(created_raw, str)
                        else datetime.utcnow()
                    )
                except (TypeError, ValueError):
                    created_at = datetime.utcnow()

                summary = str(signal_record.get("summary_cn", "")).strip()
                if not summary:
                    summary = hit.get("translated_text") or hit.get("content_text") or ""
                    summary = summary.strip()

                if not summary:
                    logger.warning(f"â­ï¸  ç¬¬ {idx} æ¡: è·³è¿‡ï¼ˆsummary ä¸ºç©ºï¼‰- news_event_id={news_event_id}")
                    continue

                assets_field = signal_record.get("assets")
                if isinstance(assets_field, str):
                    assets_list = [
                        item.strip().upper()
                        for item in assets_field.split(",")
                        if item.strip()
                    ]
                elif isinstance(assets_field, (list, tuple)):
                    assets_list = [str(item).strip().upper() for item in assets_field if str(item).strip()]
                else:
                    assets_list = []

                entry = MemoryEntry(
                    id=str(signal_record.get("id", news_event_id)),
                    created_at=created_at,
                    assets=assets_list,
                    action=str(signal_record.get("action", "observe")).lower(),
                    confidence=float(signal_record.get("confidence", 0.0)),
                    summary=summary,
                    similarity=float(hit.get("similarity") or hit.get("combined_score") or 0.0),
                )
                logger.info(
                    f"âœ… ç¬¬ {idx} æ¡: æ·»åŠ è®°å¿† - id={entry.id[:8]}..., "
                    f"match_type={hit.get('match_type', 'unknown')}, "
                    f"similarity={entry.similarity:.3f}, confidence={entry.confidence:.3f}, "
                    f"assets={entry.assets}, action={entry.action}"
                )
                entries.append(entry)

            except Exception as exc:  # pylint: disable=broad-except
                logger.warning(f"âš ï¸  ç¬¬ {idx} æ¡: æŸ¥è¯¢ä¿¡å·ä¿¡æ¯å¤±è´¥ - news_event_id={news_event_id}, error={exc}")
                continue

        logger.info(f"ğŸ“ˆ æ€»å…±å¤„ç†å¾—åˆ° {len(entries)} æ¡æœ‰æ•ˆè®°å¿†ï¼ˆä» {len(hits)} æ¡ RPC ç»“æœä¸­ï¼‰")
        entries.sort(key=lambda item: item.similarity, reverse=True)
        top_entries = entries[: self._config.max_notes]
        if top_entries:
            logger.info(
                f"âœ… SupabaseMemoryRepository: æœ€ç»ˆè¿”å› {len(top_entries)} æ¡å†å²è®°å¿† "
                f"(é˜ˆå€¼={self._config.similarity_threshold:.2f}, æ—¶é—´çª—å£={self._config.lookback_hours}h)"
            )
            # å±•ç¤ºæœ€ç»ˆè¿”å›çš„è®°å¿†æ¡ç›®è¯¦æƒ…
            logger.info("ğŸ“ è¿”å›çš„è®°å¿†æ¡ç›®:")
            for idx, entry in enumerate(top_entries, 1):
                summary_preview = entry.summary[:80].replace("\n", " ") if entry.summary else ""
                logger.info(
                    f"  [{idx}] id={entry.id[:8]}..., assets={entry.assets}, "
                    f"action={entry.action}, confidence={entry.confidence:.3f}, "
                    f"similarity={entry.similarity:.3f}\n"
                    f"      summary: {summary_preview}{'...' if len(entry.summary) > 80 else ''}"
                )
        else:
            logger.warning(
                f"âš ï¸  SupabaseMemoryRepository: æœªæ£€ç´¢åˆ°ç›¸ä¼¼å†å²è®°å¿† "
                f"(RPC è¿”å› {len(hits)} æ¡ï¼Œä½†å¤„ç†åå¾—åˆ° {len(entries)} æ¡æœ‰æ•ˆæ¡ç›®) - "
                f"é˜ˆå€¼={self._config.similarity_threshold:.2f}, "
                f"æ—¶é—´çª—å£={self._config.lookback_hours}h"
            )

        context = MemoryContext()
        context.extend(top_entries)
        logger.info(f"ğŸ“¤ SupabaseMemoryRepository: è¿”å› MemoryContextï¼ŒåŒ…å« {len(context.entries)} æ¡è®°å¿†")
        return context
