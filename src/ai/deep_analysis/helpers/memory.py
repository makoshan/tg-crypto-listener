"""è®°å¿†æ£€ç´¢ Helper å‡½æ•°"""
from __future__ import annotations

import inspect
import logging
from typing import TYPE_CHECKING, Iterable, Optional, Sequence

from .formatters import format_memory_evidence as _format_memory_evidence

if TYPE_CHECKING:
    from src.ai.deep_analysis.gemini import GeminiDeepAnalysisEngine
    from src.ai.signal_engine import EventPayload, SignalResult
    from src.memory.types import MemoryContext, MemoryEntry

logger = logging.getLogger(__name__)


async def fetch_memory_entries(
    *,
    engine: "GeminiDeepAnalysisEngine",
    payload: "EventPayload",
    preliminary: "SignalResult",
    limit: Optional[int] = None,
) -> list[dict]:
    """
    ç‹¬ç«‹çš„è®°å¿†æ£€ç´¢ Helperï¼Œå¯åœ¨å¤šå¤„å¤ç”¨ï¼š
    1. _tool_fetch_memories (Function Calling å·¥å…·)
    2. _node_context_gather (LangGraph èŠ‚ç‚¹)

    Args:
        engine: GeminiDeepAnalysisEngine å®ä¾‹
        payload: äº‹ä»¶è½½è·
        preliminary: åˆæ­¥åˆ†æç»“æœ
        limit: æœ€å¤§è¿”å›æ•°é‡ï¼ˆNone ä½¿ç”¨é»˜è®¤å€¼ï¼‰

    Returns:
        list[dict]: æ ¼å¼åŒ–çš„è®°å¿†æ¡ç›®åˆ—è¡¨ï¼ˆprompt_dict æ ¼å¼ï¼‰
    """
    if not engine._memory or not engine._memory.enabled:
        logger.debug("è®°å¿†ç³»ç»Ÿæœªå¯ç”¨æˆ–ä¸å¯ç”¨")
        return []

    limit = limit or engine._memory_limit
    # ä»…ä½¿ç”¨å¿«é€Ÿåˆ†ææä¾›çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆkeywords å­—æ®µï¼‰ï¼Œä¸ä½¿ç”¨ payload.keywords_hit
    # å› ä¸ºå¿«é€Ÿåˆ†æçš„ç»“æœç»è¿‡ AI è¯†åˆ«ï¼Œæ¯”ç›´æ¥æ–‡æœ¬åŒ¹é…æ›´å‡†ç¡®
    # ä½¿ç”¨å¿«é€Ÿåˆ†æç”Ÿæˆçš„ keywords å­—æ®µï¼ˆåŒ…å« asset å’Œ event_typeï¼‰
    keywords = list(preliminary.keywords) if preliminary.keywords else []
    asset_codes = _normalise_asset_codes(preliminary.asset)

    logger.info(
        "ğŸ” LangGraph ContextGather æ£€ç´¢å…³é”®è¯ç»„åˆï¼ˆä»…ä½¿ç”¨å¿«é€Ÿåˆ†æç»“æœï¼‰ - "
        f"preliminary.keywords={keywords}, "
        f"preliminary.asset={preliminary.asset or 'NONE'}, "
        f"preliminary.event_type={preliminary.event_type or 'NONE'}, "
        f"asset_codes={asset_codes}"
    )

    repo = engine._memory.repository
    if repo is None:
        logger.warning("è®°å¿†ä»“å‚¨æœªåˆå§‹åŒ–")
        return []

    entries: Optional[Sequence[MemoryEntry]] = None

    # å¤„ç†å¼‚æ­¥ fetch_memories æ–¹æ³•
    if hasattr(repo, "fetch_memories") and inspect.iscoroutinefunction(repo.fetch_memories):
        kwargs = {"embedding": None, "asset_codes": asset_codes}
        parameters = inspect.signature(repo.fetch_memories).parameters
        if "keywords" in parameters:
            kwargs["keywords"] = keywords

        try:
            context = await repo.fetch_memories(**kwargs)  # type: ignore[arg-type]
        except Exception as exc:
            logger.warning("Supabase è®°å¿†æ£€ç´¢å¤±è´¥: %s", exc)
            return []

        if isinstance(context, tuple) and len(context) == 2:
            # MemoryContext æ˜¯ NamedTuple
            entries = context[0]  # context.entries
        else:
            entries = []

    # å¤„ç†åŒæ­¥ fetch_memories æ–¹æ³•
    elif hasattr(repo, "fetch_memories"):
        kwargs = {"embedding": None, "asset_codes": asset_codes}
        parameters = inspect.signature(repo.fetch_memories).parameters
        if "keywords" in parameters:
            kwargs["keywords"] = keywords

        try:
            context = repo.fetch_memories(**kwargs)  # type: ignore[arg-type]
        except Exception as exc:
            logger.warning("è®°å¿†æ£€ç´¢å¤±è´¥: %s", exc)
            return []

        if inspect.iscoroutine(context):
            context = await context

        if isinstance(context, tuple) and len(context) == 2:
            entries = context[0]
        elif isinstance(context, Iterable):
            entries = list(context)

    # å¤„ç† load_entries æ–¹æ³•ï¼ˆæœ¬åœ°è®°å¿†ï¼‰
    elif hasattr(repo, "load_entries"):
        try:
            entries = repo.load_entries(  # type: ignore[attr-defined]
                keywords=keywords,
                limit=limit,
                min_confidence=engine._memory_min_confidence,
            )
        except Exception as exc:
            logger.warning("æœ¬åœ°è®°å¿†æ£€ç´¢å¤±è´¥: %s", exc)
            return []

    else:
        logger.warning("æœªçŸ¥çš„è®°å¿†ä»“å‚¨ç±»å‹: %s", type(repo).__name__)
        return []

    # è½¬æ¢ä¸º prompt dict æ ¼å¼
    prompt_entries = _memory_entries_to_prompt(entries)[:limit] if entries else []
    return prompt_entries


def _normalise_asset_codes(raw_value) -> list[str]:
    """æ ‡å‡†åŒ–èµ„äº§ä»£ç åˆ—è¡¨"""
    if not raw_value:
        return []
    if isinstance(raw_value, str):
        tokens = [token.strip().upper() for token in raw_value.split(",") if token.strip()]
    elif isinstance(raw_value, Iterable):
        tokens = [str(token).strip().upper() for token in raw_value if str(token).strip()]
    else:
        tokens = []
    return [token for token in tokens if token]


def _memory_entries_to_prompt(entries: Optional[Sequence] | Iterable | None) -> list[dict]:
    """å°†è®°å¿†æ¡ç›®è½¬æ¢ä¸º prompt dict æ ¼å¼"""
    if not entries:
        return []

    payload: list[dict] = []
    for entry in entries:
        try:
            if hasattr(entry, "to_prompt_dict"):
                payload.append(entry.to_prompt_dict())
            else:
                payload.append(dict(entry))  # type: ignore[arg-type]
        except Exception as exc:
            logger.warning("è®°å¿†æ¡ç›®è½¬æ¢å¤±è´¥: %s", exc)
            continue

    return payload


def format_memory_evidence(entries: list[dict]) -> str:
    """
    å‘åå…¼å®¹çš„æ ¼å¼åŒ–å‡½æ•°ï¼Œå¤ç”¨ helpers.formatters ä¸­çš„å®ç°
    ä»¥åœ¨èŠ‚ç‚¹å’Œæµ‹è¯•ä¸­ä¿æŒç»Ÿä¸€çš„å¯¼å…¥è·¯å¾„ã€‚
    """
    return _format_memory_evidence(entries)
