"""AI Signal Engine orchestrating OpenAI-compatible inference."""

from __future__ import annotations

import asyncio
import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, Optional, Sequence

from ..utils import setup_logger
from ..memory import MemoryBackendBundle, create_memory_backend
from .gemini_client import AiServiceError, GeminiClient
from .deep_analysis import (
    DeepAnalysisEngine,
    DeepAnalysisError,
    create_deep_analysis_engine,
)

try:  # pragma: no cover - optional dependency
    import httpx
except ImportError:  # pragma: no cover - runtime fallback
    httpx = None  # type: ignore

logger = setup_logger(__name__)

ALLOWED_ACTIONS = {"buy", "sell", "observe"}
ALLOWED_DIRECTIONS = {"long", "short", "neutral"}
ALLOWED_STRENGTH = {"low", "medium", "high"}
NO_ASSET_TOKENS = {
    "",
    "NONE",
    "æ— ",
    "NA",
    "N/A",
    "GENERAL",
    "GENERAL_CRYPTO",
    "CRYPTO",
    "MARKET",
    "MACRO",
}
FORBIDDEN_ASSET_PREFIXES = {"SP", "DJ", "ND", "HSI", "CSI", "FTSE"}
FORBIDDEN_ASSET_CODES = {
    "SPX",
    "SP500",
    "S&P500",
    "TSLA",
    "AAPL",
    "MSFT",
    "META",
    "AMZN",
    "NVDA",
    "BABA",
}
ASSET_CODE_REGEX = re.compile(r"^[A-Z0-9]{2,10}$")
ALLOWED_EVENT_TYPES = {
    "listing",
    "delisting",
    "hack",
    "regulation",
    "funding",
    "whale",
    "liquidation",
    "partnership",
    "product_launch",
    "governance",
    "macro",
    "celebrity",
    "airdrop",
    "scam_alert",      # ç–‘ä¼¼éª—å±€æˆ–é«˜é£é™©æŠ•æœºï¼ˆrug pullã€pump & dump ç­‰ï¼‰
    "other",
}
ALLOWED_RISK_FLAGS = {
    "price_volatility",
    "liquidity_risk",
    "regulation_risk",
    "confidence_low",
    "data_incomplete",
    "vague_timeline",      # æ—¶é—´çº¿æ¨¡ç³Šï¼ˆ"å³å°†"ã€"è¿‘æœŸ"ã€"ä¸ä¹…"ç­‰ï¼‰
    "speculative",         # æŠ•æœºæ€§/æ— å®è´¨å†…å®¹ï¼ˆ"å¤§äº‹ä»¶"ã€"é‡è¦æ›´æ–°"ç­‰ï¼‰
    "unverifiable",        # æ— æ³•éªŒè¯çš„å£°æ˜æˆ–é¢„æœŸ
}


@dataclass
class EventPayload:
    """Normalized data sent to the AI layer."""

    text: str
    source: str
    timestamp: datetime
    translated_text: Optional[str] = None
    language: str = "unknown"
    translation_confidence: float = 0.0
    keywords_hit: list[str] = field(default_factory=list)
    historical_reference: Dict[str, Any] = field(default_factory=dict)
    media: list[Dict[str, Any]] = field(default_factory=list)


@dataclass
class SignalResult:
    """AI decision packaged for downstream consumers."""

    status: str
    summary: str = ""
    event_type: str = "other"
    asset: str = ""
    asset_names: str = ""
    action: str = "observe"
    direction: str = "neutral"
    confidence: float = 0.0
    strength: str = "low"
    risk_flags: list[str] = field(default_factory=list)
    raw_response: str = ""
    notes: str = ""
    error: Optional[str] = None
    links: list[str] = field(default_factory=list)

    @property
    def should_execute_hot_path(self) -> bool:
        return (
            self.status == "success"
            and self.action in {"buy", "sell"}
        )

    def is_high_value_signal(
        self,
        *,
        confidence_threshold: float = 0.75,
    ) -> bool:
        """Determine if signal qualifies for Claude deep analysis.

        Args:
            confidence_threshold: Minimum confidence for high-value classification

        Returns:
            True if signal meets high-value criteria
        """
        if self.status != "success":
            return False

        # Only trigger Claude for high confidence signals
        return self.confidence >= confidence_threshold


@dataclass
class OpenAIChatResponse:
    """Structured response returned by OpenAI-compatible models."""

    text: str


class OpenAIChatClient:
    """Generic client for OpenAI-compatible chat completion APIs."""

    def __init__(
        self,
        api_key: str,
        model_name: str,
        *,
        base_url: str,
        timeout: float,
        max_retries: int,
        retry_backoff_seconds: float,
        extra_headers: Optional[Dict[str, str]] = None,
    ) -> None:
        if not api_key:
            raise AiServiceError("AI API key is required")
        if httpx is None:
            raise AiServiceError("httpx æœªå®‰è£…ï¼Œè¯·å…ˆåœ¨ç¯å¢ƒä¸­å®‰è£…è¯¥ä¾èµ–")

        normalized_base = (base_url or "").strip()
        if not normalized_base:
            normalized_base = "https://api.openai.com/v1"
        self._endpoint = normalized_base.rstrip("/") + "/chat/completions"
        self._api_key = api_key
        self._model = model_name
        self._timeout = float(timeout)
        self._max_retries = max(0, int(max_retries))
        self._retry_backoff = max(0.0, float(retry_backoff_seconds))
        self._headers: Dict[str, str] = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        if extra_headers:
            for key, value in extra_headers.items():
                if key and value is not None:
                    self._headers[str(key)] = str(value)

    async def generate_signal(self, messages: Sequence[Dict[str, str]]) -> OpenAIChatResponse:
        """Execute prompt against OpenAI-compatible API and return text."""

        if not messages:
            raise AiServiceError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        payload = {
            "model": self._model,
            "messages": list(messages),
        }

        last_exc: Exception | None = None
        last_error_message = "AI è°ƒç”¨å¤±è´¥"
        last_error_temporary = False

        for attempt in range(self._max_retries + 1):
            try:
                async with httpx.AsyncClient(timeout=self._timeout) as client:
                    response = await client.post(
                        self._endpoint,
                        headers=self._headers,
                        json=payload,
                    )
                response.raise_for_status()
            except asyncio.CancelledError:
                raise
            except httpx.TimeoutException as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI è¯·æ±‚è¶…æ—¶"
                last_error_temporary = True
                logger.warning(
                    "AI è¯·æ±‚è¶…æ—¶ (attempt %s/%s)",
                    attempt + 1,
                    self._max_retries + 1,
                )
            except httpx.HTTPStatusError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                status_code = exc.response.status_code
                last_error_message = f"AI æœåŠ¡ç«¯è¿”å›é”™è¯¯çŠ¶æ€ç : {status_code}"
                last_error_temporary = status_code == 429 or 500 <= status_code < 600
                logger.warning(
                    "AI HTTP çŠ¶æ€é”™è¯¯ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    last_error_message,
                )
                logger.debug("AI å“åº”å†…å®¹: %s", exc.response.text)
            except httpx.RequestError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI ç½‘ç»œè¿æ¥å¼‚å¸¸"
                last_error_temporary = True
                logger.warning(
                    "AI ç½‘ç»œå¼‚å¸¸ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    exc,
                )
            else:
                try:
                    data = response.json()
                except json.JSONDecodeError as exc:
                    raise AiServiceError("AI è¿”å›é JSON å†…å®¹") from exc

                choices = data.get("choices", [])
                if not choices:
                    raise AiServiceError("AI è¿”å›ç¼ºå°‘ choices å­—æ®µ")
                first_choice = choices[0] or {}
                message = first_choice.get("message") or {}
                content = message.get("content")
                if isinstance(content, list):
                    content = "".join(
                        part.get("text", "") if isinstance(part, dict) else str(part)
                        for part in content
                    )
                if not content:
                    raise AiServiceError("AI è¿”å›ç©ºå†…å®¹")
                return OpenAIChatResponse(text=str(content))

            if attempt < self._max_retries and self._retry_backoff > 0:
                backoff = self._retry_backoff * (2 ** attempt)
                logger.debug(
                    "AI å°†åœ¨ %.2f ç§’åé‡è¯• (attempt %s/%s)",
                    backoff,
                    attempt + 1,
                    self._max_retries + 1,
                )
                await asyncio.sleep(backoff)

        raise AiServiceError(last_error_message, temporary=last_error_temporary) from last_exc


class AiSignalEngine:
    """Coordinate optional AI powered signal generation with dual-engine routing."""

    def __init__(
        self,
        enabled: bool,
        client: Optional[OpenAIChatClient],
        threshold: float,
        semaphore: asyncio.Semaphore,
        *,
        provider_label: str = "AI",
        deep_analysis_engine: Optional[DeepAnalysisEngine] = None,
        deep_analysis_fallback: Optional[DeepAnalysisEngine] = None,
        deep_analysis_min_interval: float = 25.0,
        high_value_threshold: float = 0.75,
    ) -> None:
        self.enabled = enabled and client is not None
        self._client = client
        self._threshold = threshold
        self._semaphore = semaphore
        self._provider_label = provider_label or "AI"
        self._high_value_threshold = high_value_threshold
        self._deep_min_interval = float(deep_analysis_min_interval)
        self._last_deep_call_time: float = 0.0
        self._deep_enabled: bool = False
        self._deep_engine: DeepAnalysisEngine | None = None
        self._deep_fallback_engine: DeepAnalysisEngine | None = None
        self._deep_provider_label: str = ""
        self._deep_fallback_label: str = ""
        self._memory_bundle: MemoryBackendBundle | None = None
        self.attach_deep_analysis_engine(deep_analysis_engine, fallback=deep_analysis_fallback)

        if not self.enabled:
            logger.debug("AiSignalEngine æœªå¯ç”¨æˆ–ç¼ºå°‘å®¢æˆ·ç«¯ï¼Œæ‰€æœ‰æ¶ˆæ¯å°†è·³è¿‡ AI åˆ†æ")

    def attach_deep_analysis_engine(
        self,
        engine: Optional[DeepAnalysisEngine],
        *,
        fallback: Optional[DeepAnalysisEngine] = None,
    ) -> None:
        self._deep_engine = engine
        self._deep_fallback_engine = fallback
        self._deep_provider_label = engine.provider_name if engine else ""
        self._deep_fallback_label = fallback.provider_name if fallback else ""
        self._deep_enabled = engine is not None

        if engine:
            logger.info("ğŸ¤– æ·±åº¦åˆ†æå·²å¯ç”¨ (provider=%s)", self._deep_provider_label or "unknown")
        if fallback:
            logger.info("ğŸ” æ·±åº¦åˆ†æå¤‡ç”¨å¼•æ“å·²é…ç½® (provider=%s)", self._deep_fallback_label or "unknown")


    @classmethod
    def from_config(cls, config: Any) -> "AiSignalEngine":
        if not getattr(config, "AI_ENABLED", False):
            logger.debug("é…ç½®å…³é—­ AI åŠŸèƒ½ï¼Œé‡‡ç”¨ä¼ ç»Ÿè½¬å‘æµç¨‹")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label="AI",
            )

        provider_raw = str(getattr(config, "AI_PROVIDER", "gemini")).strip().lower()
        provider_alias = {
            "chatgpt": "openai",
            "gpt": "openai",
            "openai": "openai",
            "deepseek": "deepseek",
            "qwen": "qwen",
            "åƒé—®": "qwen",
            "qianwen": "qwen",
            "gemini": "gemini",
        }
        provider = provider_alias.get(provider_raw, provider_raw or "gemini")
        provider_label = provider.upper() if provider else "AI"

        api_key = (
            getattr(config, "AI_API_KEY", None)
            or getattr(config, "GEMINI_API_KEY", None)
            or ""
        )

        if not api_key:
            logger.warning("AI å·²å¯ç”¨ä½†æœªæä¾› API Keyï¼Œè‡ªåŠ¨é™çº§ä¸ºè·³è¿‡ AI åˆ†æ")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label=provider_label,
            )

        base_url = getattr(config, "AI_BASE_URL", "").strip()
        if not base_url:
            base_url = {
                "openai": "https://api.openai.com/v1",
                "deepseek": "https://api.deepseek.com",
                "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "gemini": "https://generativelanguage.googleapis.com/v1beta/openai",
            }.get(provider, "https://api.openai.com/v1")

        extra_headers: Dict[str, str] = {}
        raw_headers = getattr(config, "AI_EXTRA_HEADERS", "")
        if raw_headers:
            try:
                parsed = json.loads(raw_headers)
            except (TypeError, ValueError):
                logger.warning("AI_EXTRA_HEADERS ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°†å¿½ç•¥è¯¥é…ç½®")
            else:
                if isinstance(parsed, dict):
                    extra_headers = {
                        str(key): str(value)
                        for key, value in parsed.items()
                        if value is not None
                    }

        try:
            # Use native GeminiClient for Gemini (supports multimodal)
            if provider == "gemini":
                client = GeminiClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gemini-2.0-flash-exp"),
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                )
            else:
                # Use OpenAI-compatible client for others
                client = OpenAIChatClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gpt-4o-mini"),
                    base_url=base_url,
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                    extra_headers=extra_headers or None,
                )
        except AiServiceError as exc:
            logger.warning("AI åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ: %s", exc, exc_info=True)
            return cls(False, None, getattr(config, "AI_SIGNAL_THRESHOLD", 0.0), asyncio.Semaphore(1))

        concurrency = max(1, int(getattr(config, "AI_MAX_CONCURRENCY", 1)))
        high_value_threshold = getattr(config, "HIGH_VALUE_CONFIDENCE_THRESHOLD", 0.75)
        deep_min_interval = getattr(config, "DEEP_ANALYSIS_MIN_INTERVAL", 25.0)

        engine = cls(
            True,
            client,
            getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
            asyncio.Semaphore(concurrency),
            provider_label=provider_label,
            deep_analysis_min_interval=deep_min_interval,
            high_value_threshold=high_value_threshold,
        )

        memory_bundle = create_memory_backend(config)
        engine._memory_bundle = memory_bundle

        deep_config = getattr(config, "get_deep_analysis_config", lambda: {})()
        deep_engine: DeepAnalysisEngine | None = None
        fallback_engine: DeepAnalysisEngine | None = None

        if deep_config.get("enabled"):
            provider_name = deep_config.get("provider", "claude")
            try:
                deep_engine = create_deep_analysis_engine(
                    provider=provider_name,
                    config=config,
                    parse_callback=engine._parse_response_text,
                    memory_bundle=memory_bundle,
                )
            except DeepAnalysisError as exc:
                logger.warning("æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", provider_name, exc)

            fallback_name = deep_config.get("fallback_provider")
            if fallback_name and fallback_name != provider_name:
                try:
                    fallback_engine = create_deep_analysis_engine(
                        provider=fallback_name,
                        config=config,
                        parse_callback=engine._parse_response_text,
                        memory_bundle=memory_bundle,
                    )
                except DeepAnalysisError as exc:
                    logger.warning("å¤‡ç”¨æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", fallback_name, exc)

        engine.attach_deep_analysis_engine(deep_engine, fallback=fallback_engine)
        return engine

    async def analyse(self, payload: EventPayload) -> SignalResult:
        if not self.enabled or not self._client:
            logger.debug("AI å·²ç¦ç”¨ï¼Œsource=%s çš„æ¶ˆæ¯ç›´æ¥è·³è¿‡", payload.source)
            return SignalResult(status="skip", summary="AI disabled")

        messages = build_signal_prompt(payload)
        logger.debug(
            "AI åˆ†æå¼€å§‹: source=%s len=%d lang=%s preview=%s",
            payload.source,
            len(payload.text),
            payload.language,
            payload.text[:80].replace("\n", " "),
        )

        # Extract images for GeminiClient multimodal support
        images = None
        if isinstance(self._client, GeminiClient) and payload.media:
            images = [
                {"base64": img["base64"], "mime_type": img["mime_type"]}
                for img in payload.media
                if img.get("base64") and img.get("mime_type")
            ]
            if images:
                logger.debug("AI åˆ†æåŒ…å« %d å¼ å›¾ç‰‡", len(images))

        # Step 1: Gemini fast analysis (90%)
        async with self._semaphore:
            try:
                if isinstance(self._client, GeminiClient):
                    response = await self._client.generate_signal(messages, images=images)
                else:
                    response = await self._client.generate_signal(messages)
            except AiServiceError as exc:
                is_temporary = getattr(exc, "temporary", False)
                logger.warning(
                    "AI è°ƒç”¨å¤±è´¥: %s",
                    exc,
                    exc_info=not is_temporary,
                )
                return SignalResult(status="error", error=str(exc))

        logger.debug("%s è¿”å›é•¿åº¦: %d", self._provider_label, len(response.text))
        self._log_ai_response_debug(self._provider_label, response.text)
        gemini_result = self._parse_response(response)

        # Step 2: Determine whether to trigger deep analysis
        is_high_value = gemini_result.is_high_value_signal(
            confidence_threshold=self._high_value_threshold,
        )

        logger.debug(
            "ğŸ¤– %s åˆ†æå®Œæˆ: action=%s confidence=%.2f event_type=%s asset=%s is_high_value=%s",
            self._provider_label,
            gemini_result.action,
            gemini_result.confidence,
            gemini_result.event_type,
            gemini_result.asset,
            is_high_value,
        )

        # æ’é™¤ä½ä»·å€¼äº‹ä»¶ç±»å‹ï¼ˆmacroã€other è§¦å‘è¿‡å¤šä¸”ä»·å€¼ä½ï¼Œscam_alert å·²ç»æ˜¯é£é™©è­¦å‘Šï¼‰
        excluded_event_types = {"macro", "other", "airdrop", "governance", "celebrity", "scam_alert"}
        should_skip_deep = gemini_result.event_type in excluded_event_types

        deep_engine = self._deep_engine
        fallback_engine = self._deep_fallback_engine
        deep_label = self._deep_provider_label or "deep"
        fallback_label = self._deep_fallback_label or "fallback"

        # é¢‘ç‡é™åˆ¶æ£€æŸ¥
        import time

        time_since_last_call = time.time() - self._last_deep_call_time
        rate_limited = time_since_last_call < self._deep_min_interval

        if should_skip_deep and is_high_value:
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆä½ä»·å€¼äº‹ä»¶ç±»å‹ %sï¼‰: confidence=%.2f asset=%s",
                gemini_result.event_type,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif rate_limited and is_high_value and self._deep_enabled:
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆé¢‘ç‡é™åˆ¶ï¼Œè·ä¸Šæ¬¡è°ƒç”¨ %.1f ç§’ï¼‰: confidence=%.2f asset=%s",
                time_since_last_call,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif self._deep_enabled and deep_engine and is_high_value:
            logger.info(
                "ğŸ§  è§¦å‘ %s æ·±åº¦åˆ†æ: event_type=%s confidence=%.2f asset=%s (é˜ˆå€¼: %.2f)",
                deep_label,
                gemini_result.event_type,
                gemini_result.confidence,
                gemini_result.asset,
                self._high_value_threshold,
            )
            self._last_deep_call_time = time.time()
            try:
                deep_result = await deep_engine.analyse(payload, gemini_result)
                logger.info(
                    "âœ… %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f (%s åˆåˆ¤: %.2f) asset=%s",
                    deep_label,
                    deep_result.action,
                    deep_result.confidence,
                    self._provider_label,
                    gemini_result.confidence,
                    deep_result.asset,
                )
                return deep_result
            except DeepAnalysisError as exc:
                logger.warning(
                    "âš ï¸ %s æ·±åº¦åˆ†æå¤±è´¥ï¼Œå°†å°è¯•å¤‡ç”¨æˆ–å›é€€åˆ°ä¸»åˆ†æç»“æœ: %s",
                    deep_label,
                    exc,
                    exc_info=True,
                )
                if fallback_engine:
                    try:
                        logger.info("ğŸ” å°è¯•å¤‡ç”¨æ·±åº¦å¼•æ“ %s", fallback_label)
                        fallback_result = await fallback_engine.analyse(payload, gemini_result)
                        logger.info(
                            "âœ… å¤‡ç”¨å¼•æ“ %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f",
                            fallback_label,
                            fallback_result.action,
                            fallback_result.confidence,
                        )
                        return fallback_result
                    except DeepAnalysisError as fallback_exc:
                        logger.warning(
                            "âš ï¸ å¤‡ç”¨æ·±åº¦å¼•æ“ %s å¤±è´¥: %s",
                            fallback_label,
                            fallback_exc,
                            exc_info=True,
                        )

        return gemini_result

    @staticmethod
    def _log_ai_response_debug(label: str, text: str) -> None:
        """Log raw AI responses with truncation to avoid noisy logs."""
        if not text:
            logger.debug("%s åŸå§‹å“åº”ä¸ºç©ºå­—ç¬¦ä¸²", label)
            return

        snippet = text.strip()
        max_length = 800
        if len(snippet) > max_length:
            snippet = f"{snippet[:max_length]}â€¦(truncated)"
        logger.debug("%s åŸå§‹å“åº”: %s", label, snippet)

    def _parse_response(self, response: OpenAIChatResponse) -> SignalResult:
        return self._parse_response_text(response.text)

    def _parse_response_text(self, text: str) -> SignalResult:
        raw_text = (text or "").strip()
        normalized_text = self._prepare_json_text(raw_text)

        asset = ""
        try:
            data = json.loads(normalized_text)
            # Parse confidence safely for debug log
            confidence_debug = data.get("confidence", 0.0)
            if isinstance(confidence_debug, str):
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence_debug = confidence_map.get(confidence_debug.lower(), 0.0)
            else:
                try:
                    confidence_debug = float(confidence_debug)
                except (ValueError, TypeError):
                    confidence_debug = 0.0

            logger.debug(
                "AI JSON è§£ææˆåŠŸ: action=%s confidence=%.2f",
                data.get("action"),
                confidence_debug,
            )
            summary = str(data.get("summary", "")).strip()
            event_type = str(data.get("event_type", "other")).lower()
            asset_field = data.get("asset", "")
            asset_name_field = (
                data.get("asset_name")
                or data.get("asset_names")
                or data.get("asset_display")
                or ""
            )
            action = str(data.get("action", "observe")).lower()
            direction = str(data.get("direction", "neutral")).lower()
            strength = str(data.get("strength", "low")).lower()

            # Handle confidence - should be float but AI sometimes returns string like "high"
            confidence_raw = data.get("confidence", 0.0)
            if isinstance(confidence_raw, str):
                # Map string values to numeric confidence
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence = confidence_map.get(confidence_raw.lower(), 0.0)
                logger.warning(
                    "AI è¿”å›äº†å­—ç¬¦ä¸² confidence '%s'ï¼Œå·²è½¬æ¢ä¸ºæ•°å­— %.2f",
                    confidence_raw,
                    confidence,
                )
            else:
                try:
                    confidence = float(confidence_raw)
                except (ValueError, TypeError):
                    logger.warning(
                        "æ— æ³•è§£æ confidence å€¼ '%s'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.0",
                        confidence_raw,
                    )
                    confidence = 0.0
            risk_flags = data.get("risk_flags", []) or []
            if not isinstance(risk_flags, list):
                risk_flags = [str(risk_flags)]
            notes = str(data.get("notes", "")).strip()
            links_raw = data.get("links", [])
            if isinstance(links_raw, str):
                links = [links_raw]
            elif isinstance(links_raw, list):
                links = [str(item).strip() for item in links_raw if str(item).strip()]
            else:
                links = []
            if links:
                # å»é‡åŒæ—¶ä¿æŒé¡ºåºï¼Œé¿å…åŒä¸€æ¥æºè¢«é‡å¤æ¸²æŸ“
                links = list(dict.fromkeys(links))
            if isinstance(asset_field, (list, tuple)):
                asset = ",".join(str(item).strip() for item in asset_field if str(item).strip())
            else:
                asset = str(asset_field).strip()
            if isinstance(asset_name_field, (list, tuple)):
                asset_names = "ã€".join(
                    str(item).strip() for item in asset_name_field if str(item).strip()
                )
            else:
                asset_names = str(asset_name_field).strip()
        except json.JSONDecodeError:
            logger.debug(
                "AI è¿”å›æ— æ³•è§£æä¸º JSONï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ‘˜è¦: %s",
                normalized_text[:120].replace("\n", " "),
            )
            summary = "AI è¿”å›æ ¼å¼å¼‚å¸¸ï¼Œå·²å¿½ç•¥åŸå§‹å†…å®¹"
            event_type = "other"
            asset = ""
            asset_names = ""
            action = "observe"
            direction = "neutral"
            strength = "low"
            confidence = 0.0
            risk_flags = ["confidence_low"]
            notes = ""
            links = []

        event_type = event_type if event_type in ALLOWED_EVENT_TYPES else "other"
        action = action if action in ALLOWED_ACTIONS else "observe"
        direction = direction if direction in ALLOWED_DIRECTIONS else "neutral"
        if strength not in ALLOWED_STRENGTH:
            strength = "low"

        asset = asset.upper().strip()
        asset_tokens = [token.strip() for token in asset.split(",") if token.strip()]
        normalized_assets = []
        for token in asset_tokens:
            if token in NO_ASSET_TOKENS:
                continue
            if not ASSET_CODE_REGEX.match(token):
                continue
            if any(token.startswith(prefix) for prefix in FORBIDDEN_ASSET_PREFIXES):
                continue
            if token in FORBIDDEN_ASSET_CODES:
                continue
            normalized_assets.append(token)
        if asset_names:
            canonical_name = asset_names.strip()
            upper_name = canonical_name.upper()
            if upper_name in {"NONE", "NA", "N/A"} or canonical_name in {"æ— ", "æš‚æ— "}:
                asset_names = ""

        if not normalized_assets:
            asset = "NONE"
            asset_names = ""
        else:
            asset = ",".join(normalized_assets)
            if not asset_names:
                asset_names = ",".join(normalized_assets)
        confidence = max(0.0, min(1.0, round(confidence, 2)))
        filtered_flags = []
        for flag in risk_flags:
            if not isinstance(flag, str):
                continue
            value = flag.strip()
            if value in ALLOWED_RISK_FLAGS:
                filtered_flags.append(value)
        if not filtered_flags and confidence < 0.3:
            filtered_flags.append("confidence_low")

        # ä¿è¯æ‰€æœ‰æ¨é€é™„å¸¦æ‘˜è¦ï¼Œä½†ç½®ä¿¡åº¦ä½äº 0.4 ä¼šè¢«ä¸Šå±‚è¿‡æ»¤
        effective_threshold = max(self._threshold, 0.4)
        # ä»…å½“æ¨¡å‹è¯†åˆ«åˆ°åŠ å¯†è´§å¸æ ‡çš„æ—¶æ‰æ¨é€
        has_crypto_asset = asset != "NONE"

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å™ªéŸ³æ ‡å¿—ï¼ˆspeculativeã€vague_timelineã€unverifiableï¼‰
        noise_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_noise_flag = any(flag in noise_flags for flag in filtered_flags)

        # å¦‚æœåŒ…å«å™ªéŸ³æ ‡å¿—ä¸”ç½®ä¿¡åº¦ä¸è¶³ï¼Œè‡ªåŠ¨é™çº§ä¸º skip
        # æ³¨ï¼šå³ä½¿æœ‰å™ªéŸ³æ ‡å¿—ï¼Œå¦‚æœç½®ä¿¡åº¦ >= 0.7 ä»å¯èƒ½æ˜¯æœ‰ä»·å€¼çš„ä¿¡å·ï¼ˆå¦‚çŸ¥åäººå£«çš„æ¨¡ç³Šé¢„å‘Šï¼‰
        if has_noise_flag and confidence < 0.7:
            status = "skip"
        elif confidence >= effective_threshold and has_crypto_asset:
            status = "success"
        else:
            status = "skip"

        if not has_crypto_asset and "data_incomplete" not in filtered_flags:
            filtered_flags.append("data_incomplete")

        return SignalResult(
            status=status,
            summary=summary,
            event_type=event_type,
            asset=asset,
            asset_names=asset_names,
            action=action,
            direction=direction,
            confidence=confidence,
            strength=strength,
            risk_flags=filtered_flags,
            raw_response=raw_text,
            notes=notes,
            links=links,
        )


    @staticmethod
    def _prepare_json_text(text: str) -> str:
        """Strip Markdown/code fences and return best-effort JSON payload."""
        candidate = text.strip()
        if candidate.startswith("```") and candidate.endswith("```"):
            candidate = candidate[3:-3].strip()
        if candidate.lower().startswith("json"):
            candidate = candidate[4:].strip("\n :")
        if candidate.lower().startswith("python"):
            candidate = candidate[6:].strip("\n :")
        candidate = candidate.lstrip()
        if candidate.startswith("{") or candidate.startswith("["):
            return candidate
        return candidate


def build_signal_prompt(payload: EventPayload) -> list[dict[str, str]]:
    context = {
        "source": payload.source,
        "timestamp": payload.timestamp.isoformat(),
        "language": payload.language,
        "translation_confidence": payload.translation_confidence,
        "original_text": payload.text,
        "translated_text": payload.translated_text or payload.text,
        "keywords_hit": payload.keywords_hit,
        "historical_reference": payload.historical_reference,
        "media_attachments": payload.media,
    }

    context_json = json.dumps(context, ensure_ascii=False)

    system_prompt = (
        "ä½ æ˜¯åŠ å¯†äº¤æ˜“å°çš„èµ„æ·±åˆ†æå¸ˆï¼Œéœ€è¦ä»å¤šè¯­ç§å¿«è®¯ä¸­å¿«é€Ÿæç‚¼å¯äº¤æ˜“ä¿¡å·ã€‚\n"
        "åŠ¡å¿…ä»…è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç¦æ­¢ç”Ÿæˆå¤šæ®µ JSONã€åˆ—è¡¨å¤–å±‚æˆ– Markdown ä»£ç å—ï¼Œè¾“å‡ºå‰åä¸å¾—é™„åŠ  ```ã€#ã€è¯´æ˜æ–‡å­—æˆ–é¢å¤–æ®µè½ã€‚\n"
        "JSON å­—æ®µå›ºå®šä¸º summaryã€event_typeã€assetã€asset_nameã€actionã€directionã€confidenceã€strengthã€risk_flagsã€notesã€‚\n"
        "event_type ä»…èƒ½å– listingã€delistingã€hackã€regulationã€fundingã€whaleã€liquidationã€partnershipã€product_launchã€governanceã€macroã€celebrityã€airdropã€scam_alertã€otherã€‚\n"
        "action ä¸º buyã€sellã€observeï¼›direction ä¸º longã€shortã€neutralï¼›strength ä»…å– highã€mediumã€lowã€‚\n"
        "å¦‚äº‹ä»¶æ¶‰åŠå¤šä¸ªå¸ç§ï¼Œasset å¯ä¸ºæ•°ç»„ï¼ˆå¦‚ [\"BTC\",\"ETH\"]ï¼‰ï¼Œasset_name ç”¨ç®€ä½“ä¸­æ–‡åä»¥é¡¿å·æˆ–é€—å·åˆ†éš”ï¼›è‹¥æ— æ³•ç¡®è®¤å¸ç§åˆ™ asset=NONEã€asset_name=æ— ï¼Œå¹¶åœ¨ notes è§£é‡ŠåŸå› ã€‚\n"
        "\n## ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰\n"
        "confidence è¡¡é‡è¯¥ä¿¡å·æ˜¯å¦å€¼å¾—æ‰§è¡Œï¼š0.7-1.0 é«˜å¯ä¿¡ã€0.4-0.7 ä¸­ç­‰ã€0.0-0.4 ä»…æç¤ºé£é™©æˆ–å™ªéŸ³ï¼›å³ä½¿äº‹ä»¶çœŸå®ä½†ä¸å¯æ‰§è¡Œï¼Œä¹Ÿåº”é™ä½ confidence è‡³ â‰¤0.4ã€‚\n"
        "\n## é£é™©æ ‡å¿—ï¼ˆrisk_flagsï¼‰\n"
        "risk_flags æ•°ç»„ä»…å…è®¸ price_volatilityã€liquidity_riskã€regulation_riskã€confidence_lowã€data_incompleteã€vague_timelineã€speculativeã€unverifiableã€‚\n"
        "ä»…åœ¨å®é™…è§¦å‘æ—¶æ·»åŠ æ ‡å¿—ï¼Œé¿å…å †ç Œï¼›å½“ confidence <0.4 æˆ–ç¼ºå°‘å…³é”®æ•°æ®ï¼Œå¯åŠ å…¥ confidence_low æˆ– data_incompleteã€‚\n"
        "\n## ä¿¡å·åˆ¤æ–­è§„åˆ™\n"
        "1. æ—¶é—´æ¨¡ç³Šï¼ˆ\"è¿‘æœŸ\"ã€\"soon\" ç­‰ï¼‰â†’ æ·»åŠ  vague_timelineï¼Œå¹¶é™ä½ confidenceã€‚\n"
        "2. å†…å®¹ç¬¼ç»Ÿã€ç¼ºä¹æŒ‡æ ‡æˆ–åªæ˜¯æƒ…ç»ªè¡¨è¿° â†’ æ·»åŠ  speculativeï¼Œå¹¶å°† action è®¾ä¸º observe æˆ– confidence â‰¤0.5ã€‚\n"
        "3. æ¥æºæ— æ³•éªŒè¯æˆ–ä¸ºä¼ é—» â†’ æ·»åŠ  unverifiableï¼Œå¹¶å°† action=observeã€‚\n"
        "4. ä»…å½“äº‹ä»¶ç›´æ¥æ¶‰åŠåŠ å¯†èµ„äº§ï¼ˆ2-10 ä½å¤§å†™/æ•°å­—ï¼‰æ‰å¡«å†™ assetï¼›è‚¡ç¥¨ã€æŒ‡æ•°ã€ETF ç­‰éåŠ å¯†æ ‡çš„å¿…é¡»è¿”å› NONEã€‚\n"
        "5. è‹¥æä¾›é“¾ä¸Šæ•°æ®ã€æˆäº¤é‡ã€èµ„é‡‘æµç­‰å®¢è§‚æŒ‡æ ‡ï¼Œå¯æ®æ­¤æé«˜ confidenceï¼Œå¹¶åœ¨ notes æ¦‚è¿°å…³é”®æ•°å­—ã€‚\n"
        "6. Meme å¸çˆ†æ–™ã€è¥é”€æ–‡æ¡ˆæˆ–æ´»åŠ¨é¢„å‘Šè‹¥ç¼ºå°‘å¯æ‰§è¡Œç»†èŠ‚ï¼Œåº”è¾“å‡º event_type=scam_alert æˆ– otherï¼Œaction=observeï¼Œconfidence â‰¤0.4ï¼Œå¹¶è¯´æ˜é£é™©ã€‚\n"
        "7. äº¤æ˜“æ‰€/è¡ç”Ÿå“ä¸Šçº¿ä»…å…¬å‘Šè€Œæ— æˆäº¤ã€èµ„é‡‘è´¹ç‡ã€æµåŠ¨æ€§æŒ‡æ ‡æ—¶ï¼Œaction=observeã€direction=neutralï¼Œconfidence â‰¤0.5ï¼Œå¿…è¦æ—¶æ ‡è®° speculative æˆ– data_incompleteã€‚\n"
        "\n## å†å²å‚è€ƒ\n"
        "historical_reference.entries è‹¥éç©ºï¼Œè¯·å¯¹æ¯”ç›¸ä¼¼æ¡ˆä¾‹å¹¶åœ¨ notes ç®€è¿°ç»“è®ºï¼ˆå¦‚â€œä¸ 2024-08 BTC ETF å‡€æµå…¥ç±»ä¼¼â€ï¼‰ï¼›è‹¥ä¸ºç©ºå¯å¿½ç•¥ã€‚\n"
        "\n## å›¾ç‰‡å¤„ç†\n"
        "è¯†åˆ«å›¾ç‰‡ä¸­çš„äº¤æ˜“å¯¹ã€å…¬å‘Šä¸»ä½“æˆ–é“¾ä¸ŠæŒ‡æ ‡ï¼›è‹¥å›¾ç‰‡ä¸åŠ å¯†æ— å…³æˆ–æ— æ³•è¯»å‡ºï¼Œè¯· asset=NONE å¹¶æ·»åŠ  data_incompleteï¼Œnotes è¯´æ˜â€œå›¾ç‰‡æ— æ³•è¯†åˆ«â€æˆ–â€œä¸åŠ å¯†æ— å…³â€ã€‚\n"
        "\næ‰€æœ‰å­—æ®µä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œç¦æ­¢è¾“å‡º Markdownã€è¡¨æ ¼æˆ–å¤šä½™è§£é‡Šï¼Œç¡®ä¿ JSON å¯ç›´æ¥è§£æã€‚"
    )

    user_prompt = (
        "è¯·ç»“åˆä»¥ä¸‹äº‹ä»¶ä¸Šä¸‹æ–‡ç»™å‡ºæœ€å…·æ“ä½œæ€§çš„å»ºè®®ï¼Œè‹¥åŒ…å«å¤šæ¡ä¿¡æ¯éœ€ç»¼åˆåˆ¤æ–­ï¼š\n"
        f"```json\n{context_json}\n```\n"
        "è¿”å›ä»…åŒ…å«ä¸Šè¿°å­—æ®µçš„ JSON å­—ç¬¦ä¸²ï¼Œç¦æ­¢å‡ºç°é¢å¤–æ–‡æœ¬ï¼›å¤šèµ„äº§è¯·ä½¿ç”¨ asset æ•°ç»„ï¼Œnotes ç®€æ´è¯´æ˜å…³é”®è¦ç‚¹æˆ–é£é™©ã€‚"
    )

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
