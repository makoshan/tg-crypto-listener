"""AI Signal Engine orchestrating OpenAI-compatible inference."""

from __future__ import annotations

import asyncio
import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, Optional, Sequence

from ..utils import analyze_event_intensity, setup_logger
from ..memory import MemoryBackendBundle, create_memory_backend
from .gemini_client import AiServiceError, GeminiClient
from .deep_analysis import (
    DeepAnalysisEngine,
    DeepAnalysisError,
    create_deep_analysis_engine,
)

try:  # pragma: no cover - optional dependency
    import httpx
except ImportError:  # pragma: no cover - runtime fallback
    httpx = None  # type: ignore

logger = setup_logger(__name__)

ALLOWED_ACTIONS = {"buy", "sell", "observe"}
ALLOWED_DIRECTIONS = {"long", "short", "neutral"}
ALLOWED_STRENGTH = {"low", "medium", "high"}
ALLOWED_TIMEFRAMES = {"short", "medium", "long"}  # çŸ­æœŸï¼ˆ<1å‘¨ï¼‰ã€ä¸­æœŸï¼ˆ1å‘¨-1æœˆï¼‰ã€é•¿æœŸï¼ˆ>1æœˆï¼‰
NO_ASSET_TOKENS = {
    "",
    "NONE",
    "æ— ",
    "NA",
    "N/A",
    "GENERAL",
    "GENERAL_CRYPTO",
    "CRYPTO",
    "MARKET",
    "MACRO",
}
# FORBIDDEN_ASSET_PREFIXES and FORBIDDEN_ASSET_CODES have been removed
# Stock codes are now allowed to be recognized as assets if AI identifies them

# BLOCKED_LOW_MARKETCAP_TOKENS has been removed
# These tokens (TRUMP, MAGA, PEPE2, FLOKI2, SHIB2, DOGE2) are now filtered
# at message level via BLOCK_KEYWORDS, so they won't reach AI analysis stage.

ASSET_CODE_REGEX = re.compile(r"^[A-Z0-9]{2,10}$")
ALLOWED_EVENT_TYPES = {
    "listing",
    "delisting",
    "hack",
    "regulation",
    "funding",
    "whale",
    "liquidation",
    "partnership",
    "product_launch",
    "governance",
    "macro",
    "celebrity",
    "airdrop",
    "scam_alert",      # ç–‘ä¼¼éª—å±€æˆ–é«˜é£é™©æŠ•æœºï¼ˆrug pullã€pump & dump ç­‰ï¼‰
    "other",
}
ALLOWED_RISK_FLAGS = {
    "price_volatility",
    "liquidity_risk",
    "regulation_risk",
    "confidence_low",
    "data_incomplete",
    "vague_timeline",      # æ—¶é—´çº¿æ¨¡ç³Šï¼ˆ"å³å°†"ã€"è¿‘æœŸ"ã€"ä¸ä¹…"ç­‰ï¼‰
    "speculative",         # æŠ•æœºæ€§/æ— å®è´¨å†…å®¹ï¼ˆ"å¤§äº‹ä»¶"ã€"é‡è¦æ›´æ–°"ç­‰ï¼‰
    "unverifiable",        # æ— æ³•éªŒè¯çš„å£°æ˜æˆ–é¢„æœŸ
    "stale_event",         # è¿‡æœŸäº‹ä»¶ï¼ˆ>72å°æ—¶ï¼‰æˆ–äº‹åå›é¡¾
}


@dataclass
class EventPayload:
    """Normalized data sent to the AI layer."""

    text: str
    source: str
    timestamp: datetime
    translated_text: Optional[str] = None
    language: str = "unknown"
    translation_confidence: float = 0.0
    keywords_hit: list[str] = field(default_factory=list)
    historical_reference: Dict[str, Any] = field(default_factory=dict)
    media: list[Dict[str, Any]] = field(default_factory=list)
    is_priority_kol: bool = False


@dataclass
class SignalResult:
    """AI decision packaged for downstream consumers."""

    status: str
    summary: str = ""
    event_type: str = "other"
    asset: str = ""
    asset_names: str = ""
    action: str = "observe"
    direction: str = "neutral"
    confidence: float = 0.0
    strength: str = "low"
    timeframe: str = "medium"  # short/medium/long - å»ºè®®æŒä»“æ—¶é—´èŒƒå›´
    risk_flags: list[str] = field(default_factory=list)
    raw_response: str = ""
    notes: str = ""
    error: Optional[str] = None
    links: list[str] = field(default_factory=list)
    alert: str = ""
    severity: str = ""

    @property
    def should_execute_hot_path(self) -> bool:
        return (
            self.status == "success"
            and self.action in {"buy", "sell"}
        )

    def is_high_value_signal(
        self,
        *,
        confidence_threshold: float = 0.75,
    ) -> bool:
        """Determine if signal qualifies for Claude deep analysis.

        Args:
            confidence_threshold: Minimum confidence for high-value classification

        Returns:
            True if signal meets high-value criteria
        """
        if self.status != "success":
            return False

        # Only trigger Claude for high confidence signals
        return self.confidence >= confidence_threshold


@dataclass
class OpenAIChatResponse:
    """Structured response returned by OpenAI-compatible models."""

    text: str


class OpenAIChatClient:
    """Generic client for OpenAI-compatible chat completion APIs."""

    def __init__(
        self,
        api_key: str,
        model_name: str,
        *,
        base_url: str,
        timeout: float,
        max_retries: int,
        retry_backoff_seconds: float,
        extra_headers: Optional[Dict[str, str]] = None,
    ) -> None:
        if not api_key:
            raise AiServiceError("AI API key is required")
        if httpx is None:
            raise AiServiceError("httpx æœªå®‰è£…ï¼Œè¯·å…ˆåœ¨ç¯å¢ƒä¸­å®‰è£…è¯¥ä¾èµ–")

        normalized_base = (base_url or "").strip()
        if not normalized_base:
            normalized_base = "https://api.openai.com/v1"
        self._endpoint = normalized_base.rstrip("/") + "/chat/completions"
        self._api_key = api_key
        self._model = model_name
        self._timeout = float(timeout)
        self._max_retries = max(0, int(max_retries))
        self._retry_backoff = max(0.0, float(retry_backoff_seconds))
        self._headers: Dict[str, str] = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        if extra_headers:
            for key, value in extra_headers.items():
                if key and value is not None:
                    self._headers[str(key)] = str(value)

    async def generate_signal(self, messages: Sequence[Dict[str, str]]) -> OpenAIChatResponse:
        """Execute prompt against OpenAI-compatible API and return text."""

        if not messages:
            raise AiServiceError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        payload = {
            "model": self._model,
            "messages": list(messages),
        }

        last_exc: Exception | None = None
        last_error_message = "AI è°ƒç”¨å¤±è´¥"
        last_error_temporary = False

        for attempt in range(self._max_retries + 1):
            try:
                async with httpx.AsyncClient(timeout=self._timeout) as client:
                    response = await client.post(
                        self._endpoint,
                        headers=self._headers,
                        json=payload,
                    )
                response.raise_for_status()
            except asyncio.CancelledError:
                raise
            except httpx.TimeoutException as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI è¯·æ±‚è¶…æ—¶"
                last_error_temporary = True
                logger.warning(
                    "AI è¯·æ±‚è¶…æ—¶ (attempt %s/%s)",
                    attempt + 1,
                    self._max_retries + 1,
                )
            except httpx.HTTPStatusError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                status_code = exc.response.status_code
                last_error_message = f"AI æœåŠ¡ç«¯è¿”å›é”™è¯¯çŠ¶æ€ç : {status_code}"
                last_error_temporary = status_code == 429 or 500 <= status_code < 600
                logger.warning(
                    "AI HTTP çŠ¶æ€é”™è¯¯ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    last_error_message,
                )
                logger.debug("AI å“åº”å†…å®¹: %s", exc.response.text)
            except httpx.RequestError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI ç½‘ç»œè¿æ¥å¼‚å¸¸"
                last_error_temporary = True
                logger.warning(
                    "AI ç½‘ç»œå¼‚å¸¸ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    exc,
                )
            else:
                try:
                    data = response.json()
                except json.JSONDecodeError as exc:
                    raise AiServiceError("AI è¿”å›é JSON å†…å®¹") from exc

                choices = data.get("choices", [])
                if not choices:
                    raise AiServiceError("AI è¿”å›ç¼ºå°‘ choices å­—æ®µ")
                first_choice = choices[0] or {}
                message = first_choice.get("message") or {}
                content = message.get("content")
                if isinstance(content, list):
                    content = "".join(
                        part.get("text", "") if isinstance(part, dict) else str(part)
                        for part in content
                    )
                if not content:
                    raise AiServiceError("AI è¿”å›ç©ºå†…å®¹")
                return OpenAIChatResponse(text=str(content))

            if attempt < self._max_retries and self._retry_backoff > 0:
                backoff = self._retry_backoff * (2 ** attempt)
                logger.debug(
                    "AI å°†åœ¨ %.2f ç§’åé‡è¯• (attempt %s/%s)",
                    backoff,
                    attempt + 1,
                    self._max_retries + 1,
                )
                await asyncio.sleep(backoff)

        raise AiServiceError(last_error_message, temporary=last_error_temporary) from last_exc


class AiSignalEngine:
    """Coordinate optional AI powered signal generation with dual-engine routing."""

    def __init__(
        self,
        enabled: bool,
        client: Optional[OpenAIChatClient],
        threshold: float,
        semaphore: asyncio.Semaphore,
        *,
        provider_label: str = "AI",
        deep_analysis_engine: Optional[DeepAnalysisEngine] = None,
        deep_analysis_fallback: Optional[DeepAnalysisEngine] = None,
        deep_analysis_min_interval: float = 25.0,
        high_value_threshold: float = 0.75,
    ) -> None:
        self.enabled = enabled and client is not None
        self._client = client
        self._threshold = threshold
        self._semaphore = semaphore
        self._provider_label = provider_label or "AI"
        self._high_value_threshold = high_value_threshold
        self._deep_min_interval = float(deep_analysis_min_interval)
        self._last_deep_call_time: float = 0.0
        self._deep_enabled: bool = False
        self._deep_engine: DeepAnalysisEngine | None = None
        self._deep_fallback_engine: DeepAnalysisEngine | None = None
        self._deep_provider_label: str = ""
        self._deep_fallback_label: str = ""
        self._memory_bundle: MemoryBackendBundle | None = None
        self.attach_deep_analysis_engine(deep_analysis_engine, fallback=deep_analysis_fallback)

        if not self.enabled:
            logger.debug("AiSignalEngine æœªå¯ç”¨æˆ–ç¼ºå°‘å®¢æˆ·ç«¯ï¼Œæ‰€æœ‰æ¶ˆæ¯å°†è·³è¿‡ AI åˆ†æ")

    def attach_deep_analysis_engine(
        self,
        engine: Optional[DeepAnalysisEngine],
        *,
        fallback: Optional[DeepAnalysisEngine] = None,
    ) -> None:
        self._deep_engine = engine
        self._deep_fallback_engine = fallback
        self._deep_provider_label = engine.provider_name if engine else ""
        self._deep_fallback_label = fallback.provider_name if fallback else ""
        self._deep_enabled = engine is not None

        if engine:
            logger.info("ğŸ¤– æ·±åº¦åˆ†æå·²å¯ç”¨ (provider=%s)", self._deep_provider_label or "unknown")
        if fallback:
            logger.info("ğŸ” æ·±åº¦åˆ†æå¤‡ç”¨å¼•æ“å·²é…ç½® (provider=%s)", self._deep_fallback_label or "unknown")


    @classmethod
    def from_config(cls, config: Any) -> "AiSignalEngine":
        if not getattr(config, "AI_ENABLED", False):
            logger.debug("é…ç½®å…³é—­ AI åŠŸèƒ½ï¼Œé‡‡ç”¨ä¼ ç»Ÿè½¬å‘æµç¨‹")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label="AI",
            )

        provider_raw = str(getattr(config, "AI_PROVIDER", "gemini")).strip().lower()
        provider_alias = {
            "chatgpt": "openai",
            "gpt": "openai",
            "openai": "openai",
            "deepseek": "deepseek",
            "qwen": "qwen",
            "åƒé—®": "qwen",
            "qianwen": "qwen",
            "gemini": "gemini",
        }
        provider = provider_alias.get(provider_raw, provider_raw or "gemini")
        provider_label = provider.upper() if provider else "AI"

        api_key = (
            getattr(config, "AI_API_KEY", None)
            or getattr(config, "GEMINI_API_KEY", None)
            or ""
        )

        if not api_key:
            logger.warning("AI å·²å¯ç”¨ä½†æœªæä¾› API Keyï¼Œè‡ªåŠ¨é™çº§ä¸ºè·³è¿‡ AI åˆ†æ")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label=provider_label,
            )

        base_url = getattr(config, "AI_BASE_URL", "").strip()
        if not base_url:
            base_url = {
                "openai": "https://api.openai.com/v1",
                "deepseek": "https://api.deepseek.com",
                "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "gemini": "https://generativelanguage.googleapis.com/v1beta/openai",
            }.get(provider, "https://api.openai.com/v1")

        extra_headers: Dict[str, str] = {}
        raw_headers = getattr(config, "AI_EXTRA_HEADERS", "")
        if raw_headers:
            try:
                parsed = json.loads(raw_headers)
            except (TypeError, ValueError):
                logger.warning("AI_EXTRA_HEADERS ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°†å¿½ç•¥è¯¥é…ç½®")
            else:
                if isinstance(parsed, dict):
                    extra_headers = {
                        str(key): str(value)
                        for key, value in parsed.items()
                        if value is not None
                    }

        try:
            # Use native GeminiClient for Gemini (supports multimodal)
            if provider == "gemini":
                # Get all Gemini API keys for rotation
                api_keys = getattr(config, "GEMINI_API_KEYS", [])
                logger.info(
                    "ğŸ¤– åˆå§‹åŒ– Gemini å®¢æˆ·ç«¯: model=%s, api_keys=%d, timeout=%.1fs",
                    getattr(config, "AI_MODEL_NAME", "gemini-2.0-flash-exp"),
                    len(api_keys) if api_keys else 1,
                    getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                )
                client = GeminiClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gemini-2.0-flash-exp"),
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                    api_keys=api_keys if api_keys else None,
                )
                logger.info("âœ… Gemini å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            else:
                # Use OpenAI-compatible client for others
                client = OpenAIChatClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gpt-4o-mini"),
                    base_url=base_url,
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                    extra_headers=extra_headers or None,
                )
        except AiServiceError as exc:
            logger.warning("AI åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ: %s", exc, exc_info=True)
            return cls(False, None, getattr(config, "AI_SIGNAL_THRESHOLD", 0.0), asyncio.Semaphore(1))

        concurrency = max(1, int(getattr(config, "AI_MAX_CONCURRENCY", 1)))
        high_value_threshold = getattr(config, "HIGH_VALUE_CONFIDENCE_THRESHOLD", 0.75)
        deep_min_interval = getattr(config, "DEEP_ANALYSIS_MIN_INTERVAL", 25.0)

        engine = cls(
            True,
            client,
            getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
            asyncio.Semaphore(concurrency),
            provider_label=provider_label,
            deep_analysis_min_interval=deep_min_interval,
            high_value_threshold=high_value_threshold,
        )

        memory_bundle = create_memory_backend(config)
        engine._memory_bundle = memory_bundle

        deep_config = getattr(config, "get_deep_analysis_config", lambda: {})()
        deep_engine: DeepAnalysisEngine | None = None
        fallback_engine: DeepAnalysisEngine | None = None

        if deep_config.get("enabled"):
            provider_name = deep_config.get("provider", "claude")
            try:
                deep_engine = create_deep_analysis_engine(
                    provider=provider_name,
                    config=config,
                    parse_callback=engine._parse_response_text,
                    memory_bundle=memory_bundle,
                )
            except DeepAnalysisError as exc:
                logger.warning("æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", provider_name, exc)

            fallback_name = deep_config.get("fallback_provider")
            if fallback_name and fallback_name != provider_name:
                try:
                    fallback_engine = create_deep_analysis_engine(
                        provider=fallback_name,
                        config=config,
                        parse_callback=engine._parse_response_text,
                        memory_bundle=memory_bundle,
                    )
                except DeepAnalysisError as exc:
                    logger.warning("å¤‡ç”¨æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", fallback_name, exc)

        engine.attach_deep_analysis_engine(deep_engine, fallback=fallback_engine)
        return engine

    async def analyse(self, payload: EventPayload) -> SignalResult:
        if not self.enabled or not self._client:
            logger.debug("AI å·²ç¦ç”¨ï¼Œsource=%s çš„æ¶ˆæ¯ç›´æ¥è·³è¿‡", payload.source)
            return SignalResult(status="skip", summary="AI disabled")

        messages = build_signal_prompt(payload)
        logger.debug(
            "AI åˆ†æå¼€å§‹: source=%s len=%d lang=%s preview=%s",
            payload.source,
            len(payload.text),
            payload.language,
            payload.text[:80].replace("\n", " "),
        )

        # Extract images for GeminiClient multimodal support
        images = None
        if isinstance(self._client, GeminiClient) and payload.media:
            images = [
                {"base64": img["base64"], "mime_type": img["mime_type"]}
                for img in payload.media
                if img.get("base64") and img.get("mime_type")
            ]
            if images:
                logger.debug("AI åˆ†æåŒ…å« %d å¼ å›¾ç‰‡", len(images))

        # Step 1: Gemini fast analysis (90%)
        async with self._semaphore:
            try:
                if isinstance(self._client, GeminiClient):
                    response = await self._client.generate_signal(messages, images=images)
                else:
                    response = await self._client.generate_signal(messages)
            except AiServiceError as exc:
                is_temporary = getattr(exc, "temporary", False)
                logger.warning(
                    "AI è°ƒç”¨å¤±è´¥: %s",
                    exc,
                    exc_info=not is_temporary,
                )
                return SignalResult(status="error", error=str(exc))

        response_text = getattr(response, "text", "") or ""
        logger.debug("%s è¿”å›é•¿åº¦: %d", self._provider_label, len(response_text))
        parts = getattr(response, "parts", None)
        self._log_ai_response_debug(self._provider_label, response_text, parts)
        gemini_result = self._parse_response(response)
        gemini_result = self._apply_extreme_event_overrides(payload, gemini_result)

        # Step 2: Determine whether to trigger deep analysis
        is_high_value = gemini_result.is_high_value_signal(
            confidence_threshold=self._high_value_threshold,
        )

        logger.debug(
            "ğŸ¤– %s åˆ†æå®Œæˆ: action=%s confidence=%.2f event_type=%s asset=%s is_high_value=%s",
            self._provider_label,
            gemini_result.action,
            gemini_result.confidence,
            gemini_result.event_type,
            gemini_result.asset,
            is_high_value,
        )

        # æ’é™¤ä½ä»·å€¼äº‹ä»¶ç±»å‹ï¼ˆmacroã€other è§¦å‘è¿‡å¤šä¸”ä»·å€¼ä½ï¼Œscam_alert å·²ç»æ˜¯é£é™©è­¦å‘Šï¼‰
        # airdrop: ç©ºæŠ•ç±»æ´»åŠ¨ä»·å€¼ä½ã€æŠ•æœºæ€§å¼º
        # delisting: ä¸‹æ¶/é€€å¸‚æ–°é—»å¿½ç•¥
        # Binance Alpha ç›¸å…³çš„ listing ä¹Ÿå€¾å‘äºä½å¸‚å€¼ã€é«˜æŠ•æœºï¼Œé€šè¿‡ AI prompt æ§åˆ¶ç½®ä¿¡åº¦
        excluded_event_types = {"macro", "other", "airdrop", "governance", "celebrity", "scam_alert", "delisting"}

        # ä¸»æµå¸ä¾‹å¤–ï¼šå³ä½¿æ˜¯macroäº‹ä»¶ï¼Œå¦‚æœæ¶‰åŠBTC/ETH/SOLä¹Ÿè§¦å‘æ·±åº¦åˆ†æ
        # ä¾‹å¦‚ï¼šå·æ™®è´¸æ˜“æˆ˜ã€ç¾è”å‚¨æ”¿ç­–ç­‰å®è§‚äº‹ä»¶å¯¹ä¸»æµå¸æœ‰ç›´æ¥å½±å“
        mainstream_assets = {"BTC", "ETH", "SOL"}
        asset_set = set(gemini_result.asset.split(",")) if gemini_result.asset and gemini_result.asset != "NONE" else set()
        is_mainstream = bool(asset_set & mainstream_assets)

        should_skip_deep = (
            gemini_result.event_type in excluded_event_types and
            not is_mainstream  # ä¸»æµå¸æ¶‰åŠçš„macroäº‹ä»¶ä¸è·³è¿‡
        )

        deep_engine = self._deep_engine
        fallback_engine = self._deep_fallback_engine
        deep_label = self._deep_provider_label or "deep"
        fallback_label = self._deep_fallback_label or "fallback"

        # é¢‘ç‡é™åˆ¶æ£€æŸ¥
        import time

        time_since_last_call = time.time() - self._last_deep_call_time
        rate_limited = time_since_last_call < self._deep_min_interval

        if should_skip_deep and is_high_value:
            skip_reason = f"ä½ä»·å€¼äº‹ä»¶ç±»å‹ {gemini_result.event_type}"
            if is_mainstream:
                skip_reason += " (ä¸»æµå¸ä¾‹å¤–ï¼Œå°†è§¦å‘æ·±åº¦åˆ†æ)"
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆ%sï¼‰: confidence=%.2f asset=%s",
                skip_reason,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif rate_limited and is_high_value and self._deep_enabled:
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆé¢‘ç‡é™åˆ¶ï¼Œè·ä¸Šæ¬¡è°ƒç”¨ %.1f ç§’ï¼‰: confidence=%.2f asset=%s",
                time_since_last_call,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif self._deep_enabled and deep_engine and is_high_value:
            logger.info(
                "ğŸ§  è§¦å‘ %s æ·±åº¦åˆ†æ: event_type=%s confidence=%.2f asset=%s (é˜ˆå€¼: %.2f) source=%s",
                deep_label,
                gemini_result.event_type,
                gemini_result.confidence,
                gemini_result.asset,
                self._high_value_threshold,
                payload.source,
            )
            logger.debug(
                "æ·±åº¦åˆ†æå¼•æ“ç±»å‹: %s, æœ‰å¤‡ç”¨å¼•æ“: %s",
                type(deep_engine).__name__,
                "æ˜¯" if fallback_engine else "å¦",
            )
            self._last_deep_call_time = time.time()
            try:
                logger.debug("æ­£åœ¨è°ƒç”¨ %s å¼•æ“æ‰§è¡Œæ·±åº¦åˆ†æ...", deep_label)
                deep_result = await deep_engine.analyse(payload, gemini_result)

                # è®¡ç®—ç½®ä¿¡åº¦è°ƒæ•´
                confidence_delta = deep_result.confidence - gemini_result.confidence
                confidence_change = "â†‘" if confidence_delta > 0 else ("â†“" if confidence_delta < 0 else "â†’")

                logger.info(
                    "âœ… %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f %s (åˆåˆ¤: %.2f, è°ƒæ•´: %+.2f) asset=%s summary=%s",
                    deep_label,
                    deep_result.action,
                    deep_result.confidence,
                    confidence_change,
                    gemini_result.confidence,
                    confidence_delta,
                    deep_result.asset,
                    deep_result.summary[:100] if deep_result.summary else "",
                )

                # å¦‚æœæœ‰å†å²è®°å¿†ä¸Šä¸‹æ–‡ï¼Œè®°å½•å…¶å½±å“
                if payload.historical_reference and payload.historical_reference.get("entries"):
                    mem_count = len(payload.historical_reference.get("entries", []))
                    logger.info(
                        "ğŸ“š å†å²è®°å¿†å½±å“: %d æ¡å‚è€ƒ â†’ ç½®ä¿¡åº¦ %.2f %s %.2f (%s%.2f)",
                        mem_count,
                        gemini_result.confidence,
                        confidence_change,
                        deep_result.confidence,
                        "+" if confidence_delta >= 0 else "",
                        confidence_delta
                    )

                return deep_result
            except DeepAnalysisError as exc:
                logger.warning(
                    "âš ï¸ %s æ·±åº¦åˆ†æå¤±è´¥ï¼Œå°†å°è¯•å¤‡ç”¨æˆ–å›é€€åˆ°ä¸»åˆ†æç»“æœ: %s",
                    deep_label,
                    exc,
                    exc_info=True,
                )
                if fallback_engine:
                    try:
                        logger.info("ğŸ” å°è¯•å¤‡ç”¨æ·±åº¦å¼•æ“ %s (ç±»å‹: %s)", fallback_label, type(fallback_engine).__name__)
                        fallback_result = await fallback_engine.analyse(payload, gemini_result)
                        logger.info(
                            "âœ… å¤‡ç”¨å¼•æ“ %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f summary=%s",
                            fallback_label,
                            fallback_result.action,
                            fallback_result.confidence,
                            fallback_result.summary[:100] if fallback_result.summary else "",
                        )
                        return fallback_result
                    except DeepAnalysisError as fallback_exc:
                        logger.warning(
                            "âš ï¸ å¤‡ç”¨æ·±åº¦å¼•æ“ %s å¤±è´¥: %s",
                            fallback_label,
                            fallback_exc,
                            exc_info=True,
                        )
                else:
                    logger.debug("æ— å¤‡ç”¨æ·±åº¦å¼•æ“å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¸»å¼•æ“åˆ†æç»“æœ")

        return gemini_result

    @staticmethod
    def _log_ai_response_debug(label: str, text: str, parts: Sequence[Any] | None = None) -> None:
        """Log raw AI responses with truncation to avoid noisy logs."""
        if parts:
            try:
                part_types = [
                    getattr(part, "type", None)
                    or getattr(part, "type_", None)
                    or type(part).__name__
                    for part in parts
                ]
                logger.debug("%s å“åº”åŒ…å«ç»“æ„åŒ–åˆ†æ®µ: %s", label, part_types)
            except Exception:
                logger.debug("%s ç»“æ„åŒ–åˆ†æ®µç±»å‹ç»Ÿè®¡å¤±è´¥", label, exc_info=True)

        if not text:
            logger.debug("%s åŸå§‹å“åº”ä¸ºç©ºå­—ç¬¦ä¸²", label)
            return

        snippet = text.strip()
        max_length = 800
        if len(snippet) > max_length:
            snippet = f"{snippet[:max_length]}â€¦(truncated)"
        logger.debug("%s åŸå§‹å“åº”: %s", label, snippet)

    def _parse_response(self, response: OpenAIChatResponse) -> SignalResult:
        return self._parse_response_text(response.text)

    def _parse_response_text(self, text: str) -> SignalResult:
        raw_text = (text or "").strip()
        normalized_text = self._prepare_json_text(raw_text)

        asset = ""
        try:
            data = json.loads(normalized_text)
            # Parse confidence safely for debug log
            confidence_debug = data.get("confidence", 1.0)
            if isinstance(confidence_debug, str):
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence_debug = confidence_map.get(confidence_debug.lower(), 0.0)
            else:
                try:
                    confidence_debug = float(confidence_debug)
                except (ValueError, TypeError):
                    confidence_debug = 1.0

            logger.debug(
                "AI JSON è§£ææˆåŠŸ: action=%s confidence=%.2f",
                data.get("action"),
                confidence_debug,
            )
            summary = str(data.get("summary", "")).strip()
            event_type = str(data.get("event_type", "other")).lower()
            asset_field = data.get("asset", "")
            asset_name_field = (
                data.get("asset_name")
                or data.get("asset_names")
                or data.get("asset_display")
                or ""
            )
            action = str(data.get("action", "observe")).lower()
            direction = str(data.get("direction", "neutral")).lower()
            strength = str(data.get("strength", "low")).lower()
            timeframe = str(data.get("timeframe", "medium")).lower()

            # Handle confidence - should be float but AI sometimes returns string like "high"
            confidence_raw = data.get("confidence")
            if confidence_raw is None:
                # No confidence field provided - use conservative default
                confidence = 0.5
                logger.warning(
                    "AI æœªè¿”å› confidence å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5 (ä¸­ç­‰ç½®ä¿¡åº¦)"
                )
            elif isinstance(confidence_raw, str):
                # Map string values to numeric confidence
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence = confidence_map.get(confidence_raw.lower(), 0.5)
                if confidence_raw.lower() not in confidence_map:
                    logger.warning(
                        "AI è¿”å›äº†æœªçŸ¥çš„å­—ç¬¦ä¸² confidence '%s'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5",
                        confidence_raw,
                    )
                else:
                    logger.debug(
                        "AI è¿”å›äº†å­—ç¬¦ä¸² confidence '%s'ï¼Œå·²è½¬æ¢ä¸ºæ•°å­— %.2f",
                        confidence_raw,
                        confidence,
                    )
            else:
                try:
                    confidence = float(confidence_raw)
                except (ValueError, TypeError):
                    logger.warning(
                        "æ— æ³•è§£æ confidence å€¼ '%s'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5",
                        confidence_raw,
                    )
                    confidence = 0.5
            risk_flags = data.get("risk_flags", []) or []
            if not isinstance(risk_flags, list):
                risk_flags = [str(risk_flags)]
            notes = str(data.get("notes", "")).strip()
            links_raw = data.get("links", [])
            if isinstance(links_raw, str):
                links = [links_raw]
            elif isinstance(links_raw, list):
                links = [str(item).strip() for item in links_raw if str(item).strip()]
            else:
                links = []
            if links:
                # å»é‡åŒæ—¶ä¿æŒé¡ºåºï¼Œé¿å…åŒä¸€æ¥æºè¢«é‡å¤æ¸²æŸ“
                links = list(dict.fromkeys(links))
            if isinstance(asset_field, (list, tuple)):
                asset = ",".join(str(item).strip() for item in asset_field if str(item).strip())
            else:
                asset = str(asset_field).strip()
            if isinstance(asset_name_field, (list, tuple)):
                asset_names = "ã€".join(
                    str(item).strip() for item in asset_name_field if str(item).strip()
                )
            else:
                asset_names = str(asset_name_field).strip()
        except json.JSONDecodeError as e:
            logger.warning(
                "âš ï¸ AI è¿”å›æ— æ³•è§£æä¸º JSON: %s (åŸå§‹å†…å®¹é¢„è§ˆ: %s)",
                str(e)[:100],
                normalized_text[:200].replace("\n", " "),
            )
            logger.debug(
                "å®Œæ•´åŸå§‹å“åº” (å‰500å­—ç¬¦): %s",
                raw_text[:500] if len(raw_text) > 500 else raw_text
            )
            summary = "AI è¿”å›æ ¼å¼å¼‚å¸¸ï¼Œå·²å¿½ç•¥åŸå§‹å†…å®¹"
            event_type = "other"
            asset = ""
            asset_names = ""
            action = "observe"
            direction = "neutral"
            strength = "low"
            timeframe = "medium"
            confidence = 0.0  # ä¿®å¤ BUG: JSON è§£æå¤±è´¥åº”è¯¥æ˜¯é›¶ç½®ä¿¡åº¦ï¼Œè€Œé 1.0
            risk_flags = ["confidence_low", "parse_error"]
            notes = ""
            links = []

        event_type = event_type if event_type in ALLOWED_EVENT_TYPES else "other"
        action = action if action in ALLOWED_ACTIONS else "observe"
        direction = direction if direction in ALLOWED_DIRECTIONS else "neutral"
        if strength not in ALLOWED_STRENGTH:
            strength = "low"
        if timeframe not in ALLOWED_TIMEFRAMES:
            timeframe = "medium"

        asset = asset.upper().strip()
        asset_tokens = [token.strip() for token in asset.split(",") if token.strip()]
        normalized_assets = []
        for token in asset_tokens:
            if token in NO_ASSET_TOKENS:
                continue
            if not ASSET_CODE_REGEX.match(token):
                continue
            normalized_assets.append(token)

        # Check asset_names for invalid values
        if asset_names:
            canonical_name = asset_names.strip()
            upper_name = canonical_name.upper()
            if upper_name in {"NONE", "NA", "N/A"} or canonical_name in {"æ— ", "æš‚æ— "}:
                asset_names = ""

        if not normalized_assets:
            asset = "NONE"
            asset_names = ""
        else:
            asset = ",".join(normalized_assets)
            if not asset_names:
                asset_names = ",".join(normalized_assets)
        confidence = max(0.0, min(1.0, round(confidence, 2)))
        filtered_flags: list[str] = []
        for flag in risk_flags:
            if not isinstance(flag, str):
                continue
            value = flag.strip()
            if value in ALLOWED_RISK_FLAGS:
                filtered_flags.append(value)
        if not filtered_flags and confidence < 0.3:
            filtered_flags.append("confidence_low")

        has_crypto_asset = asset != "NONE"
        noise_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_noise_flag = any(flag in noise_flags for flag in filtered_flags)

        result = SignalResult(
            status="skip",
            summary=summary,
            event_type=event_type,
            asset=asset,
            asset_names=asset_names,
            action=action,
            direction=direction,
            confidence=confidence,
            strength=strength,
            timeframe=timeframe,
            risk_flags=filtered_flags,
            raw_response=raw_text,
            notes=notes,
            links=links,
        )
        self._finalize_signal_status(
            result,
            has_crypto_asset=has_crypto_asset,
            has_noise_flag=has_noise_flag,
        )

        # Apply post-validation rules to catch AI inconsistencies
        self._apply_post_validation_rules(result)

        return result


    @staticmethod
    def _prepare_json_text(text: str) -> str:
        """Strip Markdown/code fences, thinking tags, and return best-effort JSON payload."""
        candidate = text.strip()
        
        # Handle unclosed <think> tags (e.g., minimax sometimes returns <think> without </think>)
        # First, try to remove properly closed tags
        candidate = re.sub(r'<think>.*?</think>', '', candidate, flags=re.DOTALL | re.IGNORECASE)
        candidate = re.sub(r'<thinking>.*?</thinking>', '', candidate, flags=re.DOTALL | re.IGNORECASE)
        
        # Then handle unclosed <think> tags - remove everything from <think> to end if no closing tag
        if '<think>' in candidate.lower() and '</think>' not in candidate.lower():
            # Find the position of <think> tag (case-insensitive)
            think_pos = candidate.lower().find('<think>')
            if think_pos >= 0:
                # Try to find content after <think> that might be JSON
                # Look for { or [ after <think> tag
                after_think = candidate[think_pos + 6:].lstrip()  # Skip "<think>"
                json_start = re.search(r'[\{\[]', after_think)
                if json_start:
                    # Found JSON after <think>, extract it
                    candidate = after_think[json_start.start():].strip()
                else:
                    # No JSON found, remove the entire <think> tag and everything after
                    candidate = candidate[:think_pos].strip()
        
        # Also handle unclosed <thinking> tags
        if '<thinking>' in candidate.lower() and '</thinking>' not in candidate.lower():
            thinking_pos = candidate.lower().find('<thinking>')
            if thinking_pos >= 0:
                after_thinking = candidate[thinking_pos + 10:].lstrip()  # Skip "<thinking>"
                json_start = re.search(r'[\{\[]', after_thinking)
                if json_start:
                    candidate = after_thinking[json_start.start():].strip()
                else:
                    candidate = candidate[:thinking_pos].strip()
        
        # Remove Markdown code fences
        if candidate.startswith("```") and candidate.endswith("```"):
            candidate = candidate[3:-3].strip()
        if candidate.lower().startswith("json"):
            candidate = candidate[4:].strip("\n :")
        if candidate.lower().startswith("python"):
            candidate = candidate[6:].strip("\n :")
        candidate = candidate.lstrip()
        
        # Try to find JSON block if it doesn't start with { or [
        if not (candidate.startswith("{") or candidate.startswith("[")):
            # Look for JSON in code blocks (handle multi-line JSON)
            json_match = re.search(r'```(?:json)?\s*(\{.*?\}|\[.*?\])', candidate, re.DOTALL)
            if json_match:
                candidate = json_match.group(1).strip()
            # Or find the first { or [ and extract balanced JSON
            else:
                brace_pos = candidate.find("{")
                bracket_pos = candidate.find("[")
                start_pos = -1
                if brace_pos >= 0 and (bracket_pos < 0 or brace_pos < bracket_pos):
                    start_pos = brace_pos
                elif bracket_pos >= 0:
                    start_pos = bracket_pos
                
                if start_pos >= 0:
                    # Try to extract balanced JSON by counting braces/brackets
                    json_text = candidate[start_pos:]
                    # Simple approach: find the matching closing brace/bracket
                    # This handles most cases where JSON is complete
                    candidate = json_text
        
        return candidate

    def _apply_extreme_event_overrides(
        self,
        payload: EventPayload,
        result: SignalResult,
    ) -> SignalResult:
        """Adjust AI output for extreme depeg/liquidation scenarios."""
        if not payload.text and not payload.translated_text:
            return result

        analysis = analyze_event_intensity(
            payload.text or "",
            payload.translated_text or "",
        )
        has_extreme_move = analysis["has_high_impact"] and (
            analysis["has_percent_change"]
            or analysis["has_price_level_change"]
            or analysis["has_drop_keyword"]
        )

        asset_tokens = {
            token.strip().lower()
            for token in (result.asset or "").split(",")
            if token.strip()
        }
        mentions_critical_asset = analysis["mentions_critical_asset"] or bool(
            asset_tokens & {"usde", "wbeth", "wbtc", "wbsol", "stablecoin"}
        )

        modified = False

        if has_extreme_move:
            result.confidence = min(1.0, max(result.confidence + 0.2, 0.0))
            if not result.alert:
                result.alert = "extreme_market_move"
            if not result.severity:
                result.severity = "high"
            if "price_volatility" not in result.risk_flags:
                result.risk_flags.append("price_volatility")
            modified = True

        if has_extreme_move and mentions_critical_asset:
            if result.action != "sell":
                result.action = "sell"
                modified = True
            if result.direction != "short":
                result.direction = "short"
                modified = True
            if result.confidence < 0.8:
                result.confidence = min(1.0, max(result.confidence, 0.8))
                modified = True

        if result.alert or result.severity or modified:
            self._refresh_signal_status(result)

        return result

    def _finalize_signal_status(
        self,
        result: SignalResult,
        *,
        has_crypto_asset: bool,
        has_noise_flag: bool,
    ) -> None:
        """Evaluate signal eligibility after confidence/action adjustments."""
        effective_threshold = max(self._threshold, 0.4)

        if has_noise_flag and result.confidence < 0.7:
            result.status = "skip"
        elif result.confidence >= effective_threshold and has_crypto_asset:
            result.status = "success"
        else:
            result.status = "skip"

        if not has_crypto_asset and "data_incomplete" not in result.risk_flags:
            result.risk_flags.append("data_incomplete")

    def _apply_post_validation_rules(self, result: SignalResult) -> None:
        """Apply hard validation rules to catch AI inconsistencies.

        This method enforces critical business rules that the AI prompt alone
        cannot guarantee, particularly around conflicting signals (e.g., high
        confidence but stale event, buy action but no tradeable asset).
        """
        modified = False
        validation_notes = []

        # Rule 1: stale_event flag MUST force low confidence and observe action
        if "stale_event" in result.risk_flags:
            if result.confidence > 0.4:
                logger.warning(
                    "âš ï¸ åç½®éªŒè¯ï¼šæ£€æµ‹åˆ° stale_event ä½† confidence=%.2f > 0.4ï¼Œå¼ºåˆ¶é™ä½åˆ° 0.35",
                    result.confidence,
                )
                result.confidence = 0.35
                validation_notes.append("æ¶ˆæ¯è¿‡æœŸï¼Œç½®ä¿¡åº¦å·²å¼ºåˆ¶é™ä½")
                modified = True

            if result.action in {"buy", "sell"}:
                logger.warning(
                    "âš ï¸ åç½®éªŒè¯ï¼šæ£€æµ‹åˆ° stale_event ä½† action=%sï¼Œå¼ºåˆ¶æ”¹ä¸º observe",
                    result.action,
                )
                result.action = "observe"
                result.direction = "neutral"
                validation_notes.append("æ¶ˆæ¯è¿‡æœŸï¼Œæ“ä½œå·²æ”¹ä¸ºè§‚å¯Ÿ")
                modified = True

        # Rule 2: Conflicting risk flags (speculative + high confidence buy/sell)
        high_risk_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_high_risk = any(flag in high_risk_flags for flag in result.risk_flags)

        if has_high_risk and result.action in {"buy", "sell"} and result.confidence >= 0.7:
            logger.warning(
                "âš ï¸ åç½®éªŒè¯ï¼šæ£€æµ‹åˆ°é«˜é£é™©æ ‡å¿— %s ä½† action=%s confidence=%.2fï¼Œå¼ºåˆ¶æ”¹ä¸º observe å¹¶é™ä½ç½®ä¿¡åº¦",
                [f for f in result.risk_flags if f in high_risk_flags],
                result.action,
                result.confidence,
            )
            result.action = "observe"
            result.direction = "neutral"
            result.confidence = min(result.confidence, 0.55)
            validation_notes.append("æŠ•æœºæ€§å†…å®¹ï¼Œå·²æ”¹ä¸ºè§‚å¯Ÿ")
            modified = True

        # Rule 3: No tradeable asset (NONE) but action is buy/sell
        if result.asset == "NONE" and result.action in {"buy", "sell"}:
            logger.warning(
                "âš ï¸ åç½®éªŒè¯ï¼šasset=NONE ä½† action=%sï¼Œå¼ºåˆ¶æ”¹ä¸º observe",
                result.action,
            )
            result.action = "observe"
            result.direction = "neutral"
            result.confidence = min(result.confidence, 0.40)
            validation_notes.append("æ— å¯äº¤æ˜“æ ‡çš„ï¼Œå·²æ”¹ä¸ºè§‚å¯Ÿ")
            modified = True

        # Rule 4: Notes mention "æœªå‘è¡Œ"/"å°†æ¨å‡º"/"è®¡åˆ’" but action is buy/sell
        future_keywords = ["æœªå‘è¡Œ", "å°†æ¨å‡º", "è®¡åˆ’æ¨å‡º", "å³å°†æ¨å‡º", "å°†è¦", "å‡†å¤‡æ¨å‡º"]
        if result.notes and any(kw in result.notes for kw in future_keywords):
            if result.action in {"buy", "sell"}:
                logger.warning(
                    "âš ï¸ åç½®éªŒè¯ï¼šå¤‡æ³¨æåŠæœªæ¥äº‹ä»¶ä½† action=%sï¼Œå¼ºåˆ¶æ”¹ä¸º observe",
                    result.action,
                )
                result.action = "observe"
                result.direction = "neutral"
                result.confidence = min(result.confidence, 0.40)
                validation_notes.append("ä»£å¸æœªå‘è¡Œï¼Œæš‚æ— äº¤æ˜“æœºä¼š")
                modified = True

        # Rule 5: Confidence and action mismatch with risk level
        # If confidence < 0.5 but action is buy/sell with high strength, force corrections
        if result.confidence < 0.5 and result.action in {"buy", "sell"} and result.strength == "high":
            logger.warning(
                "âš ï¸ åç½®éªŒè¯ï¼šä½ç½®ä¿¡åº¦ %.2f ä½† action=%s strength=%sï¼Œå¼ºåˆ¶æ”¹ä¸º observe å’Œ low strength",
                result.confidence,
                result.action,
                result.strength,
            )
            result.action = "observe"
            result.direction = "neutral"
            result.strength = "low"
            validation_notes.append("ç½®ä¿¡åº¦ä¸æ“ä½œå¼ºåº¦ä¸åŒ¹é…")
            modified = True

        # Append validation notes if corrections were made
        if validation_notes:
            prefix = "ã€åç½®éªŒè¯ä¿®æ­£ã€‘"
            corrections = "ï¼›".join(validation_notes)
            if result.notes:
                result.notes = f"{prefix}{corrections}ã€‚{result.notes}"
            else:
                result.notes = f"{prefix}{corrections}"

        # Re-evaluate status after modifications
        if modified:
            self._refresh_signal_status(result)
            logger.info(
                "âœ… åç½®éªŒè¯å®Œæˆ: action=%s confidence=%.2f status=%s",
                result.action,
                result.confidence,
                result.status,
            )

    def _refresh_signal_status(self, result: SignalResult) -> None:
        """Re-run status gating using current signal attributes."""
        has_crypto_asset = bool(result.asset and result.asset != "NONE")
        noise_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_noise_flag = any(flag in noise_flags for flag in result.risk_flags)
        self._finalize_signal_status(
            result,
            has_crypto_asset=has_crypto_asset,
            has_noise_flag=has_noise_flag,
        )


def build_signal_prompt(payload: EventPayload) -> list[dict[str, str]]:
    # Calculate message age for freshness check
    from datetime import datetime, timezone
    now = datetime.now(timezone.utc)
    timestamp_aware = payload.timestamp if payload.timestamp.tzinfo else payload.timestamp.replace(tzinfo=timezone.utc)
    message_age_hours = (now - timestamp_aware).total_seconds() / 3600

    context = {
        "source": payload.source,
        "timestamp": payload.timestamp.isoformat(),
        "message_age_hours": round(message_age_hours, 1),  # æ–°å¢ï¼šæ¶ˆæ¯å¹´é¾„ï¼ˆå°æ—¶ï¼‰
        "language": payload.language,
        "translation_confidence": payload.translation_confidence,
        "original_text": payload.text,
        "translated_text": payload.translated_text or payload.text,
        "keywords_hit": payload.keywords_hit,
        "historical_reference": payload.historical_reference,
        "media_attachments": payload.media,
        "is_priority_kol": payload.is_priority_kol,
        "priority_flags": ["priority_kol"] if payload.is_priority_kol else [],
    }

    context_json = json.dumps(context, ensure_ascii=False)

    system_prompt = (
        "ä½ æ˜¯åŠ å¯†äº¤æ˜“å°çš„èµ„æ·±åˆ†æå¸ˆï¼Œéœ€è¦ä»å¤šè¯­ç§å¿«è®¯ä¸­å¿«é€Ÿæç‚¼å¯äº¤æ˜“ä¿¡å·ã€‚\n"
        "åŠ¡å¿…ä»…è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç¦æ­¢ç”Ÿæˆå¤šæ®µ JSONã€åˆ—è¡¨å¤–å±‚æˆ– Markdown ä»£ç å—ï¼Œè¾“å‡ºå‰åä¸å¾—é™„åŠ  ```ã€#ã€è¯´æ˜æ–‡å­—æˆ–é¢å¤–æ®µè½ã€‚\n"
        "JSON å­—æ®µå›ºå®šä¸º summaryã€event_typeã€assetã€asset_nameã€actionã€directionã€confidenceã€strengthã€timeframeã€risk_flagsã€notesã€‚\n"
        "**summary å­—æ®µå¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™ï¼Œç®€æ˜æ‰¼è¦ï¼ˆ1-2 å¥è¯ï¼‰ï¼Œç›´æ¥è¯´æ˜æ ¸å¿ƒäº‹ä»¶ä¸æ–°å¢æƒ…æŠ¥æˆ–å¸‚åœºå½±å“ã€‚**\n"
        "event_type ä»…èƒ½å– listingã€delistingã€hackã€regulationã€fundingã€whaleã€liquidationã€partnershipã€product_launchã€governanceã€macroã€celebrityã€airdropã€scam_alertã€otherã€‚\n"
        "action ä¸º buyã€sellã€observeï¼›direction ä¸º longã€shortã€neutralï¼›strength ä»…å– highã€mediumã€lowï¼›timeframe ä»…å– shortã€mediumã€longã€‚\n"
        "å¦‚äº‹ä»¶æ¶‰åŠå¤šä¸ªå¸ç§ï¼Œasset å¯ä¸ºæ•°ç»„ï¼ˆå¦‚ [\"BTC\",\"ETH\"]ï¼‰ï¼Œasset_name ç”¨ç®€ä½“ä¸­æ–‡åä»¥é¡¿å·æˆ–é€—å·åˆ†éš”ï¼›è‹¥æ— æ³•ç¡®è®¤å¸ç§åˆ™ asset=NONEã€asset_name=æ— ï¼Œå¹¶åœ¨ notes è§£é‡ŠåŸå› ã€‚\n"
        "**é»„é‡‘æ˜ å°„è§„åˆ™**ï¼šå½“æ¶ˆæ¯æ¶‰åŠé»„é‡‘ï¼ˆGold/XAU/é»„é‡‘æœŸè´§ï¼‰æ—¶ï¼Œä½¿ç”¨ asset=XAUTï¼ˆTether Gold ä»£å¸ï¼‰æ¥æŸ¥è¯¢ä»·æ ¼å’Œåˆ†æã€‚\n"
        "**Ondo ç¾è‚¡ä»£å¸åŒ–æ˜ å°„è§„åˆ™**ï¼šå½“æ¶ˆæ¯æ¶‰åŠä»¥ä¸‹ç¾è‚¡æˆ–æŒ‡æ•°æ—¶ï¼Œå¿…é¡»è¯†åˆ«ä¸ºå¯¹åº”çš„ Ondo ä»£å¸åŒ–èµ„äº§ï¼ˆä»…é™ä»¥ä¸‹æ ‡çš„ï¼‰ï¼š\n"
        "- Google/è°·æ­Œ/Alphabet â†’ GOOGLON\n"
        "- Tesla/ç‰¹æ–¯æ‹‰ â†’ TSLAON\n"
        "- CrowdStrike/CRWD â†’ CRCLON\n"
        "- çº³æ–¯è¾¾å…‹100æŒ‡æ•°/QQQ ETF â†’ QQQON\n"
        "- Nvidia/è‹±ä¼Ÿè¾¾ â†’ NVDAON\n"
        "- MicroStrategy/MSTR â†’ MSTRON\n"
        "- Coinbase/COIN â†’ COINON\n"
        "- è‹¹æœ/Apple â†’ AAPLON\n"
        "- æ ‡æ™®500æŒ‡æ•°/SPY ETF â†’ SPYON\n"
        "ä»…é™ä¸Šè¿°9åªæ ‡çš„å¯è¯†åˆ«ä¸ºä»£å¸åŒ–èµ„äº§ï¼Œå…¶ä»–ç¾è‚¡/æŒ‡æ•°ä»è¿”å› asset=NONEã€‚åœ¨ summary å’Œ notes ä¸­éœ€æ˜ç¡®æ ‡æ³¨è¿™æ˜¯'ç¾è‚¡ä»£å¸åŒ–èµ„äº§'ï¼Œå¹¶è¯´æ˜ä¸ä¼ ç»Ÿè‚¡å¸‚çš„å…³è”æ€§ã€‚\n"
        "ä½ éœ€è¦è‡ªä¸»åˆ¤æ–­è¯¥ä¿¡å·çš„æœºä¼šå¤§å°ï¼Œå¹¶åœ¨ notes ä¸­ç”¨æ¸…æ™°çš„è‡ªç„¶è¯­è¨€ç»™å‡ºä¹°/å–/è§‚å¯Ÿçš„æ ¸å¿ƒä¾æ®ï¼Œ"
        "ä¼˜å…ˆå¼•ç”¨ä¸‰ç±»è¯æ®æ”¯æ’‘åˆ¤æ–­ï¼š1) å®è§‚ï¼ˆæ—¥ç¨‹/æ”¿ç­–/åœ°ç¼˜ï¼Œå«æœªæ¥24-48å°æ—¶å…³é”®å®‰æ’ï¼‰ï¼›2) ä»·æ ¼ï¼ˆå¤šæ—¶é—´å‘¨æœŸï¼Œç¤ºä¾‹ï¼šBTC +5%ï¼‰ï¼›3) å†å²è®°å¿†ï¼ˆè¯¥é¡¹ç›®æœ€è¿‘åŠ¨ä½œ/ç›¸ä¼¼æ¡ˆä¾‹ï¼‰ï¼›å¦‚ç¼ºå¤±è¯·æ˜ç¡®å¾…è¡¥å……é¡¹ã€‚"
        "notes è¡¨è¾¾æ–¹å¼å®Œå…¨è‡ªç”±ï¼Œåªéœ€ç¡®ä¿ä¿¡æ¯æ¸…æ™°å¯è¿½æº¯ã€ä¹°å–ä¾æ®æ˜ç¡®å³å¯ã€‚\n"
        "\n## ä¿¡æ¯æ‰©å±•æç¤º\n"
        "1. èšç„¦æç‚¼æ–‡æœ¬ä¸­çš„å®šé‡æ•°æ®ã€æ—¶é—´èŠ‚ç‚¹ä¸å‚ä¸æ–¹ï¼Œç¡®ä¿ summary ä¸ notes å‘ˆç°æœ€æ–°äº‹å®ï¼›\n"
        "2. è‹¥ç¼ºä¹ä»·æ ¼ã€ä»“ä½ã€ç›‘ç®¡æˆ–å®è§‚èƒŒæ™¯ï¼Œè¯·åœ¨ notes ä¸­æ˜ç¡®åˆ—å‡ºå¾…æœç´¢çš„ä¿¡æ¯ç»´åº¦ä¸å…³é”®è¯ï¼›\n"
        "3. æ— éœ€å¼ºè°ƒ \"çœŸä¼ªå¾…æŸ¥\"ï¼Œé‡ç‚¹è¯´æ˜éœ€è¦è¿›ä¸€æ­¥æ‰©å……çš„ä¿¡æ¯ç»´åº¦å’Œæœç´¢æ–¹å‘ã€‚\n"
        "\n## ä¸»æµå¸å¸‚åœºæŒ‡æ ‡é‡è¦æ€§ âš ï¸ æ ¸å¿ƒä¼˜å…ˆçº§\n"
        "**BTCï¼ˆæ¯”ç‰¹å¸ï¼‰æ˜¯æ•´ä¸ªåŠ å¯†å¸‚åœºçš„é£å‘æ ‡å’Œå®è§‚æŒ‡æ ‡**ï¼š\n"
        "1. **å®è§‚å…³è”æ€§**ï¼šæ¯”ç‰¹å¸ä»·æ ¼ä¸å…¨çƒå®è§‚ç¯å¢ƒï¼ˆç¾è”å‚¨æ”¿ç­–ã€ç¾å…ƒæŒ‡æ•°ã€åœ°ç¼˜æ”¿æ²»ï¼‰é«˜åº¦ç›¸å…³ï¼Œæ˜¯åŠ å¯†å¸‚åœºé£é™©åå¥½çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚\n"
        "2. **å¸‚åœºè”åŠ¨æ€§**ï¼šå½“æ¯”ç‰¹å¸æ¶¨è·Œæ—¶ï¼Œæ•´ä¸ªåŠ å¯†å¸‚åœºï¼ˆETHã€SOLã€å±±å¯¨å¸ï¼‰é€šå¸¸åŒå‘æ³¢åŠ¨ï¼ŒBTC è·Œæ„å‘³ç€å…¨å¸åœˆæ‰¿å‹ã€‚\n"
        "3. **å®è§‚ä¼ å¯¼æœºåˆ¶**ï¼š\n"
        "   - è´¸æ˜“æˆ˜/åœ°ç¼˜å†²çª â†’ é£é™©åå¥½ä¸‹é™ â†’ BTC ä¸‹è·Œ â†’ å…¨å¸åœˆä¸‹è·Œ\n"
        "   - ç¾è”å‚¨åŠ æ¯/ç¾å…ƒèµ°å¼º â†’ æµåŠ¨æ€§æ”¶ç´§ â†’ BTC æ‰¿å‹ â†’ åŠ å¯†å¸‚åœºæ•´ä½“å›è°ƒ\n"
        "   - å®è§‚åˆ©å¥½ï¼ˆé™æ¯é¢„æœŸã€æœºæ„å…¥åœºï¼‰ â†’ BTC ä¸Šæ¶¨ â†’ å¸¦åŠ¨æ•´ä¸ªåŠ å¯†å¸‚åœº\n"
        "4. **ä¸»æµå¸ä¼˜å…ˆçº§**ï¼šBTC > ETH > SOLï¼Œè¿™ä¸‰ä¸ªå¸ç§çš„ä»·æ ¼å˜åŒ–å¿…é¡»é‡ç‚¹å…³æ³¨å¹¶æé†’ã€‚\n"
        "5. **ä¸»æµå¸ä¿¡å·å¢å¼ºè§„åˆ™**ï¼š\n"
        "   - æ¶‰åŠ BTC/ETH/SOL ä»·æ ¼æ¶¨è·Œ â‰¥3% â†’ confidence è‡ªåŠ¨ +0.15 åˆ° +0.25\n"
        "   - æ¶‰åŠ BTC çªç ´å…³é”®å¿ƒç†å…³å£ï¼ˆå¦‚ $100Kã€$90Kï¼‰ â†’ confidence â‰¥0.75, strength=high\n"
        "   - æ¶‰åŠ BTC ä¸å®è§‚äº‹ä»¶ï¼ˆå·æ™®ã€è´¸æ˜“æˆ˜ã€ç¾è”å‚¨ã€CPIï¼‰ â†’ å¿…é¡»åœ¨ summary ä¸­æ˜ç¡®è¯´æ˜å®è§‚å½±å“å’Œå¸‚åœºè”åŠ¨\n"
        "   - ä¸»æµå¸å¤§æ¶¨ï¼ˆâ‰¥5%ï¼‰æˆ–å¤§è·Œï¼ˆâ‰¤-5%ï¼‰ â†’ action å¿…é¡»æ˜ç¡®ï¼ˆbuy/sellï¼‰ï¼Œé¿å…æ¨¡ç³Šçš„ observe\n"
        "\n## å®è§‚è”åŠ¨ + å¤šå¸ç§ä»·æ ¼è§£è¯»\n"
        "1. å½“äº‹ä»¶æ¶‰åŠ BTCã€ETHã€SOL ä»»æ„ä¸€é¡¹æ—¶ï¼Œsummary éœ€åŒæ­¥ç‚¹æ˜å½“æ—¥å®è§‚èƒŒæ™¯ï¼ˆå¦‚è´¸æ˜“å±€åŠ¿ã€å¤®è¡Œæ”¿ç­–ã€å®è§‚æ•°æ®é‡Šæ”¾ï¼‰ï¼Œè¯´æ˜å…¶å¦‚ä½•ä¼ å¯¼è‡³ä¸»æµå¸ä»·æ ¼ã€‚\n"
        "2. å¦‚æœä¸Šä¸‹æ–‡æœªæä¾›æ˜ç¡®å®è§‚ä¿¡æ¯ï¼Œéœ€åœ¨ notes ä¸­è¯´æ˜â€œç¼ºä¹å®è§‚å‚¬åŒ–çº¿ç´¢â€å¹¶æç¤ºéœ€å…³æ³¨çš„æ½œåœ¨å®è§‚é©±åŠ¨ï¼ˆç¾å…ƒæŒ‡æ•°ã€å›½å€ºæ”¶ç›Šç‡ã€ç›‘ç®¡åŠ¨æ€ç­‰ï¼‰ã€‚\n"
        "3. price_snapshot æˆ–æ¶ˆæ¯æ­£æ–‡åŒ…å« SOL/ETH/BTC å½“æ—¥æ¶¨è·Œå¹…æ—¶ï¼Œå¿…é¡»åœ¨ notes ä¸­åˆ—å‡ºå…³é”®ä»·æ ¼ä¸ 24h å˜åŒ–ï¼Œçªå‡ºèµ„é‡‘è½®åŠ¨æˆ–å¼ºå¼±å¯¹æ¯”ã€‚\n"
        "4. å¤šå¸ç§äº‹ä»¶ï¼ˆå¦‚ SOLâ†’ETH èµ„é‡‘è¿ç§»ï¼‰éœ€è§£é‡Šä¸ BTC èµ°åŠ¿çš„è”åŠ¨ï¼šBTC è‹¥åŒæ­¥ä¸Šè¡Œä»£è¡¨é£é™©åå¥½æ‰©æ•£ï¼Œè‹¥èµ°å¼±åˆ™æç¤ºè½®åŠ¨é˜²å®ˆæ€§è´¨ã€‚\n"
        "5. é’ˆå¯¹é“¾ä¸Šå·¨é²¸ã€èµ„é‡‘æµå‘ç±»æ¶ˆæ¯ï¼Œéœ€ç»“åˆå®è§‚æƒ…ç»ªåˆ¤æ–­å…¶æ˜¯é¡ºåŠ¿åŠ ä»“è¿˜æ˜¯èµ„é‡‘é¿é™©ï¼Œå¿…è¦æ—¶ç»™å‡ºä»“ä½/å‘¨æœŸå»ºè®®å¹¶ä¿æŒä¸ summary æ–¹å‘ä¸€è‡´ã€‚\n"
        "\n## ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰\n"
        "confidence è¡¡é‡è¯¥ä¿¡å·æ˜¯å¦å€¼å¾—æ‰§è¡Œï¼š0.7-1.0 é«˜å¯ä¿¡ã€0.4-0.7 ä¸­ç­‰ã€0.0-0.4 ä»…æç¤ºé£é™©æˆ–å™ªéŸ³ï¼›å³ä½¿äº‹ä»¶çœŸå®ä½†ä¸å¯æ‰§è¡Œï¼Œä¹Ÿåº”é™ä½ confidence è‡³ â‰¤0.4ã€‚\n"
        "**å¯æ‰§è¡Œæ€§åˆ¤æ–­æ ‡å‡†**ï¼š\n"
        "- âœ… å¯æ‰§è¡Œï¼ˆconfidence â‰¥0.6ï¼‰ï¼šæ˜ç¡®çš„ä¹°å…¥/å–å‡ºæ ‡çš„ + æ—¶é—´çª—å£ + å…·ä½“ä»·æ ¼/æ•°æ®æ”¯æ’‘\n"
        "- âš ï¸ éƒ¨åˆ†å¯æ‰§è¡Œï¼ˆconfidence 0.4-0.6ï¼‰ï¼šæœ‰äº¤æ˜“æ–¹å‘ä½†ç¼ºå°‘æ—¶é—´èŠ‚ç‚¹ï¼Œæˆ–æœ‰æ•°æ®ä½†ç¼ºå°‘æ˜ç¡®æ ‡çš„\n"
        "- âŒ ä¸å¯æ‰§è¡Œï¼ˆconfidence â‰¤0.4ï¼‰ï¼šçº¯ç»Ÿè®¡æ•°å­—ã€ç¬¼ç»Ÿè¶‹åŠ¿ã€æƒ…ç»ªè§‚å¯Ÿã€æ— å…·ä½“æ ‡çš„æˆ–æ—¶é—´\n"
        "**ç‰¹åˆ«æ³¨æ„**ï¼šæ¶‰åŠä¸»æµå¸ï¼ˆBTC/ETH/SOLï¼‰ä»·æ ¼å˜åŒ–çš„æ¶ˆæ¯ï¼Œé»˜è®¤å…·æœ‰æ›´é«˜æ‰§è¡Œä»·å€¼ï¼Œconfidence åº”é€‚å½“æå‡ï¼ˆ+0.15 åˆ° +0.25ï¼‰ã€‚\n"
        "\n## æ—¶æ•ˆæ€§åˆ¤æ–­ âš ï¸ æ ¸å¿ƒä¼˜å…ˆçº§\n"
        "**message_age_hours å­—æ®µè¡¨ç¤ºæ¶ˆæ¯å‘å¸ƒè‡³ä»Šçš„å°æ—¶æ•°ï¼Œå¿…é¡»ä¸¥æ ¼æ£€æŸ¥æ—¶æ•ˆæ€§**ï¼š\n"
        "1. **å®æ—¶æ–°é—»ï¼ˆâ‰¤24å°æ—¶ï¼‰**ï¼š\n"
        "   - æ¶ˆæ¯æè¿°æ­£åœ¨å‘ç”Ÿçš„äº‹ä»¶ã€åˆšåˆšå®£å¸ƒçš„å…¬å‘Šã€å®æ—¶ä»·æ ¼æ³¢åŠ¨ â†’ ä¿æŒæˆ–æå‡ confidence\n"
        "   - å…³é”®è¯ï¼š\"åˆšåˆš\"ã€\"ä»Šæ—¥\"ã€\"ç°åœ¨\"ã€\"just announced\"ã€\"breaking\" â†’ æ—¶æ•ˆæ€§é«˜\n"
        "2. **è¿‘æœŸæ–°é—»ï¼ˆ24-72å°æ—¶ï¼‰**ï¼š\n"
        "   - äº‹ä»¶å‘ç”Ÿä¸ä¹…ï¼Œå¸‚åœºå¯èƒ½ä»åœ¨æ¶ˆåŒ– â†’ confidence é™ä½ -0.10 to -0.20\n"
        "   - å¦‚æœæ˜¯é‡å¤§äº‹ä»¶ï¼ˆç›‘ç®¡ã€é»‘å®¢æ”»å‡»ã€äº¤æ˜“æ‰€ä¸Šå¸ï¼‰ä¸”å¸‚åœºæœªå……åˆ†ååº” â†’ å¯é€‚åº¦ä¿ç•™ confidence\n"
        "3. **è¿‡æœŸæ–°é—»ï¼ˆ>72å°æ—¶ï¼Œå³ message_age_hours > 72ï¼‰**ï¼š\n"
        "   - **å¼ºåˆ¶é™ä½ confidence -0.30 to -0.50**ï¼Œå¸‚åœºå¤§æ¦‚ç‡å·²æ¶ˆåŒ–\n"
        "   - action å¼ºåˆ¶æ”¹ä¸º \"observe\"ï¼ˆé™¤éæ˜¯é•¿æœŸè¶‹åŠ¿åˆ†æï¼‰\n"
        "   - åœ¨ notes ä¸­æ˜ç¡®æ ‡æ³¨ï¼š\"æ¶ˆæ¯å·²è¿‡æœŸï¼ˆXå°æ—¶å‰ï¼‰ï¼Œå¸‚åœºå¯èƒ½å·²ååº”\"\n"
        "4. **äº‹åå›é¡¾/å†å²æ€»ç»“/é‡å¤è§‚ç‚¹ï¼ˆè¯†åˆ«è¯­ä¹‰ç‰¹å¾ï¼‰**ï¼š\n"
        "   - å…³é”®è¯ï¼š\"å›é¡¾\"ã€\"æ€»ç»“\"ã€\"...ä¹‹å\"ã€\"äº‹ä»¶å\"ã€\"å†å²ä¸Š...\" â†’ è¿™ä¸æ˜¯å®æ—¶äº¤æ˜“æœºä¼š\n"
        "   - å†å²è®°å¿†æ˜¾ç¤ºç±»ä¼¼è§‚ç‚¹æ›¾å¤šæ¬¡å‡ºç°ï¼ˆé‡å¤æ€§è¨€è®ºï¼‰â†’ éæ–°é²œä¿¡æ¯\n"
        "   - ä»…è§‚ç‚¹è¡¨è¾¾ï¼Œæ— å®é™…è¡ŒåŠ¨æˆ–æ•°æ®æ”¯æ’‘ï¼ˆå¦‚åäººå–Šå•ã€åˆ†æå¸ˆè§‚ç‚¹ï¼‰â†’ ä¸å¯æ‰§è¡Œ\n"
        "   - **å¼ºåˆ¶é™ä½ confidence -0.40 to -0.60**ï¼Œaction=observe\n"
        "   - åœ¨ notes ä¸­æ ‡æ³¨ï¼š\"äº‹åå›é¡¾/é‡å¤è§‚ç‚¹/çº¯è§‚ç‚¹è¡¨è¾¾ï¼Œéå®æ—¶äº¤æ˜“ä¿¡å·\"\n"
        "5. **ç‰¹æ®Šæƒ…å†µä¾‹å¤–**ï¼š\n"
        "   - é•¿æœŸè¶‹åŠ¿åˆ†æï¼ˆå¦‚æœºæ„é‡‡ç”¨ã€ç›‘ç®¡æ”¿ç­–ï¼‰å³ä½¿æ¶ˆæ¯è¾ƒæ—§ï¼Œä½†å¦‚æœä»å…·å¤‡é•¿æœŸå½±å“ â†’ timeframe=longï¼Œconfidence é€‚åº¦é™ä½ä½†ä¸å¼ºåˆ¶ â‰¤0.4\n"
        "   - å†å²æ•°æ®å¯¹æ¯”ï¼ˆå¦‚\"ä¸2024å¹´Xæœˆç±»ä¼¼\"ï¼‰ç”¨äºå¢å¼ºåˆ¤æ–­å¯ä¿¡åº¦ â†’ ä¸è§†ä¸ºè¿‡æœŸï¼Œä½†éœ€ç»“åˆå½“å‰å¸‚åœºçŠ¶æ€\n"
        "**æ—¶æ•ˆæ€§æ£€æŸ¥ä¼˜å…ˆçº§æœ€é«˜**ï¼šåœ¨æ‰€æœ‰å…¶ä»–è§„åˆ™ä¹‹å‰ï¼Œå…ˆæ£€æŸ¥ message_age_hours å’Œè¯­ä¹‰ç‰¹å¾ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºè¿‡æœŸ/äº‹åå›é¡¾å†…å®¹ã€‚\n"

        "\n## æ—¶é—´èŒƒå›´ï¼ˆtimeframeï¼‰\n"
        "timeframe è¡¨ç¤ºå»ºè®®æŒä»“æ—¶é—´æˆ–å½±å“å‘¨æœŸï¼š\n"
        "- shortï¼ˆçŸ­æœŸï¼Œ<1å‘¨ï¼‰ï¼šé“¾ä¸Šæ•°æ®çªå˜ã€å·¨é²¸çŸ­æœŸæ“ä½œã€çŸ­æœŸäº‹ä»¶å‚¬åŒ–ï¼ˆå¦‚ç©ºæŠ•ã€IDOï¼‰ã€æŠ€æœ¯é¢ä¿¡å·ç­‰éœ€å¿«é€Ÿååº”çš„æœºä¼š\n"
        "- mediumï¼ˆä¸­æœŸï¼Œ1å‘¨-1æœˆï¼‰ï¼šäº§å“ä¸Šçº¿ã€åˆä½œå…¬å‘Šã€å­£åº¦è´¢æŠ¥ã€ä¸­çŸ­æœŸå™äº‹ï¼ˆå¦‚æŸèµ›é“çƒ­ç‚¹ï¼‰\n"
        "- longï¼ˆé•¿æœŸï¼Œ>1æœˆï¼‰ï¼šç›‘ç®¡æ”¿ç­–ã€å®è§‚é‡‡ç”¨ç‡æå‡ã€åŸºç¡€è®¾æ–½å»ºè®¾ã€é•¿æœŸå™äº‹ï¼ˆå¦‚æœºæ„å…¥åœºã€ETF å‡€æµå…¥æŒç»­ï¼‰\n"
        "æ ¹æ®äº‹ä»¶æ€§è´¨åˆ¤æ–­å½±å“æŒç»­æ—¶é—´ï¼Œä¾‹å¦‚ï¼šæœºæ„é‡‡ç”¨ç‡æå‡â†’longï¼›äº¤æ˜“æ‰€ä¸Šçº¿â†’mediumï¼›å·¨é²¸ 24h å†…ä¹°å…¥â†’shortã€‚\n"
        "\n## é£é™©æ ‡å¿—ï¼ˆrisk_flagsï¼‰\n"
        "risk_flags æ•°ç»„ä»…å…è®¸ price_volatilityã€liquidity_riskã€regulation_riskã€confidence_lowã€data_incompleteã€vague_timelineã€speculativeã€unverifiableã€stale_eventã€‚\n"
        "ä»…åœ¨å®é™…è§¦å‘æ—¶æ·»åŠ æ ‡å¿—ï¼Œé¿å…å †ç Œï¼›å½“ confidence <0.4 æˆ–ç¼ºå°‘å…³é”®æ•°æ®ï¼Œå¯åŠ å…¥ confidence_low æˆ– data_incompleteã€‚\n"
        "**æ—¶æ•ˆæ€§ç›¸å…³æ ‡å¿—**ï¼šå½“ message_age_hours > 72 æˆ–è¯†åˆ«å‡ºäº‹åå›é¡¾ç‰¹å¾æ—¶ï¼Œå¿…é¡»æ·»åŠ  stale_event æ ‡å¿—ã€‚\n"

        "å½“ç¨³å®šå¸æˆ–åŒ…è£¹èµ„äº§ï¼ˆå¦‚ USDEã€WBETHã€WBTCã€WBSOL ç­‰ï¼‰å‡ºç°è„±é”šã€æš´è·Œã€æŠ˜ä»·ã€æ¸…ç®—æˆ–å¼ºåˆ¶å¹³ä»“é£é™©æ—¶ï¼Œå¿…é¡»è¿”å› action=sellã€direction=shortï¼Œconfidence â‰¥0.8ï¼Œå¹¶åœ¨ notes è¯´æ˜è§¦å‘åŸå› ä¸æ ¸å¿ƒæ•°æ®ã€‚\n"
        "è‹¥æ–‡æœ¬åŒ…å«â€œè„±é”šã€depegã€æš´è·Œã€å¤§å¹…ä¸‹è·Œã€è·Œè‡³ã€ä½äºã€æ¸…ç®—ã€å¼ºåˆ¶å¹³ä»“â€ç­‰è¯æ±‡ä¸”ä¼´éšç™¾åˆ†æ¯”æˆ–ä»·æ ¼å˜åŠ¨ï¼Œè¯·è§†ä¸ºæç«¯è¡Œæƒ…ï¼Œé‡ç‚¹æè¿°è·Œå¹…ã€ä»·æ ¼åŒºé—´ï¼Œå¹¶ç›¸åº”æå‡ confidenceã€‚\n"
        "å¯¹äºæç«¯è¡Œæƒ…ï¼Œè¯·åœ¨ risk_flags ä¸­è‡³å°‘åŠ å…¥ price_volatilityï¼›å¦‚æ•°æ®æ¥æºæˆ–é“¾ä¸Šç»†èŠ‚ç¼ºå¤±ï¼Œé¢å¤–æ ‡è®° data_incompleteã€‚\n"
        "\n## ä¿¡å·åˆ¤æ–­è§„åˆ™\n"
        "1. æ—¶é—´æ¨¡ç³Šï¼ˆ\"è¿‘æœŸ\"ã€\"soon\" ç­‰ï¼‰â†’ æ·»åŠ  vague_timelineï¼Œå¹¶é™ä½ confidenceã€‚\n"
        "2. å†…å®¹ç¬¼ç»Ÿã€ç¼ºä¹æŒ‡æ ‡æˆ–åªæ˜¯æƒ…ç»ªè¡¨è¿° â†’ æ·»åŠ  speculativeï¼Œå¹¶å°† action è®¾ä¸º observe æˆ– confidence â‰¤0.5ã€‚\n"
        "3. æ¥æºæ— æ³•éªŒè¯æˆ–ä¸ºä¼ é—» â†’ æ·»åŠ  unverifiableï¼Œå¹¶å°† action=observeã€‚\n"
        "4. ä»…å½“äº‹ä»¶ç›´æ¥æ¶‰åŠåŠ å¯†èµ„äº§ï¼ˆ2-10 ä½å¤§å†™/æ•°å­—ï¼‰æ‰å¡«å†™ assetï¼›è‚¡ç¥¨ã€æŒ‡æ•°ã€ETF ç­‰éåŠ å¯†æ ‡çš„å¿…é¡»è¿”å› NONEã€‚\n"
        "5. è‹¥æä¾›é“¾ä¸Šæ•°æ®ã€æˆäº¤é‡ã€èµ„é‡‘æµç­‰å®¢è§‚æŒ‡æ ‡ï¼Œå¯æ®æ­¤æé«˜ confidenceï¼Œå¹¶åœ¨ notes æ¦‚è¿°å…³é”®æ•°å­—ã€‚\n"
        "6. Meme å¸çˆ†æ–™ã€è¥é”€æ–‡æ¡ˆæˆ–æ´»åŠ¨é¢„å‘Šè‹¥ç¼ºå°‘å¯æ‰§è¡Œç»†èŠ‚ï¼Œåº”è¾“å‡º event_type=scam_alert æˆ– otherï¼Œaction=observeï¼Œconfidence â‰¤0.4ï¼Œå¹¶è¯´æ˜é£é™©ã€‚\n"
        "7. äº¤æ˜“æ‰€/è¡ç”Ÿå“ä¸Šçº¿ä»…å…¬å‘Šè€Œæ— æˆäº¤ã€èµ„é‡‘è´¹ç‡ã€æµåŠ¨æ€§æŒ‡æ ‡æ—¶ï¼Œaction=observeã€direction=neutralï¼Œconfidence â‰¤0.5ï¼Œå¿…è¦æ—¶æ ‡è®° speculative æˆ– data_incompleteã€‚\n"
        "8. **å®è§‚ç»Ÿè®¡æ•°æ®ï¼ˆevent_type=macroï¼‰ä¸¥æ ¼é™åˆ¶**ï¼š\n"
        '   - ä»…ç»Ÿè®¡æ•°å­—ï¼ˆå¦‚"æ€»ä¾›åº”é‡åˆ›æ–°é«˜"ã€"å¸‚å€¼çªç ´XX"ã€"æ•´ä½“å¢é•¿XX%"ï¼‰è€Œæ— å…·ä½“äº¤æ˜“æœºä¼š â†’ confidence â‰¤0.4ï¼Œæ·»åŠ  data_incomplete æˆ– speculative\n'
        "   - ç¨³å®šå¸æ€»ä¾›åº”é‡/æ€»å¸‚å€¼ç±»æ¶ˆæ¯ï¼Œé™¤éæ˜ç¡®è¯´æ˜èµ„é‡‘æµå…¥å…·ä½“é“¾ï¼ˆETH/SOLï¼‰ã€åè®®ï¼ˆAave/Curveï¼‰æˆ–é…åˆé“¾ä¸Šæ•°æ®ï¼ˆDEXäº¤æ˜“é‡æ¿€å¢ï¼‰ï¼Œå¦åˆ™ confidence â‰¤0.4\n"
        "   - æœºæ„é‡‡ç”¨ã€DeFièƒ½åŠ›ã€é•¿æœŸè¶‹åŠ¿ç­‰ç¬¼ç»Ÿè§‚å¯Ÿï¼Œæ— æ—¶é—´èŠ‚ç‚¹å’Œå¯æ‰§è¡Œæ ‡çš„ â†’ action=observeï¼Œconfidence â‰¤0.5ï¼Œæ·»åŠ  vague_timeline\n"
        '   - event_type=macro + action=observe ç»„åˆæ—¶ï¼Œå¿…é¡»æœ‰æ˜ç¡®äº¤æ˜“å‚¬åŒ–å‰‚ï¼ˆå¦‚"Xæœºæ„å®£å¸ƒæœ¬å‘¨ä¹°å…¥Yäº¿ç¾å…ƒBTC"ï¼‰æ‰èƒ½ confidence >0.6\n'
        "9. **ä½å¸‚å€¼ä»£å¸é£é™©æ§åˆ¶ä¸ä¸»åŠ¨è¿‡æ»¤**ï¼š\n"
        "   - **ä¼˜å…ˆç­–ç•¥ï¼šä¸»åŠ¨è¯†åˆ«å¹¶è¿‡æ»¤ä½å¸‚å€¼åƒåœ¾ä»£å¸**ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š\n"
        "     * è¡¨æƒ…åŒ…/æ”¿æ²»ä¸»é¢˜ä»£å¸ï¼ˆå¦‚çº¯ meme é©±åŠ¨çš„ä»£å¸ï¼Œæ— å®é™…åº”ç”¨åœºæ™¯ï¼‰\n"
        "     * åˆ†å‰ä»£å¸/ä»¿ç›˜ä»£å¸ï¼ˆå¦‚ PEPE2ã€DOGE2ã€SHIB2ã€FLOKI2 ç­‰ï¼Œä»…é€šè¿‡å‘½åè¹­çƒ­åº¦çš„ä»¿åˆ¶å“ï¼‰\n"
        "     * ç¼ºä¹æ˜ç¡®ä»·å€¼ä¸»å¼ ã€ä»…é è¥é”€æ–‡æ¡ˆæ¨åŠ¨çš„ä½å¸‚å€¼ä»£å¸\n"
        "   - **è¿‡æ»¤è§„åˆ™æ‰§è¡Œ**ï¼š\n"
        "     * è¯†åˆ«åˆ°ä¸Šè¿°åƒåœ¾ä»£å¸ç‰¹å¾æ—¶ â†’ action=observeï¼Œconfidence â‰¤0.3ï¼Œå¿…é¡»æ·»åŠ  speculative å’Œ liquidity_risk\n"
        "     * å¸‚å€¼ < 5000ä¸‡ç¾å…ƒçš„ä»£å¸ï¼Œé»˜è®¤è§†ä¸ºé«˜é£é™©æŠ•æœºæ ‡çš„ â†’ confidence è‡ªåŠ¨ -0.15 åˆ° -0.25\n"
        "     * å¸‚å€¼ < 1000ä¸‡ç¾å…ƒçš„ä»£å¸ï¼Œæé«˜é£é™© â†’ confidence è‡ªåŠ¨ -0.25 åˆ° -0.35ï¼Œå¿…é¡»æ·»åŠ  liquidity_risk\n"
        "     * æœªä¸Šçº¿ä¸»æµäº¤æ˜“æ‰€ï¼ˆä»…åœ¨ DEX æˆ–å°å‹ CEXï¼‰çš„ä»£å¸ â†’ confidence é™ä½ 0.1-0.2ï¼Œæ·»åŠ  liquidity_risk\n"
        "     * ä½å¸‚å€¼ + æ— æ˜ç¡®å‚¬åŒ–å‰‚ï¼ˆå¦‚ä»…ç©ºæŠ•ã€ä»…ä¸Šçº¿å°äº¤æ˜“æ‰€ï¼‰ â†’ confidence â‰¤0.4ï¼Œaction=observe\n"
        "10. **Binance Alpha ç‰¹æ®Šå¤„ç†**ï¼š\n"
        "   - Binance Alpha å¹³å°ä¸Šçº¿çš„ä»£å¸é€šå¸¸å¸‚å€¼è¾ƒå°ã€æŠ•æœºæ€§å¼º â†’ è‡ªåŠ¨é™ä½ confidence 0.2-0.3\n"
        "   - Binance Alpha ç©ºæŠ•æ´»åŠ¨ï¼Œé™¤éæœ‰æ˜ç¡®çš„äº¤æ˜“æœºä¼šå’Œæ—¶é—´èŠ‚ç‚¹ â†’ action=observeï¼Œconfidence â‰¤0.5\n"
        "   - å¯¹äº Binance Alpha æ¶ˆæ¯ï¼Œå¿…é¡»åœ¨ summary ä¸­æ˜ç¡®æ ‡æ³¨ 'å¸‚å€¼è¾ƒå°' æˆ– 'æŠ•æœºæ€§å¼º' ç­‰é£é™©æç¤º\n"
        "11. **Hyperliquid é²¸é±¼æ“ä½œ - èªæ˜é’±ä¿¡å·å¢å¼º âš ï¸**ï¼š\n"
        "   - Hyperliquid æ˜¯å»ä¸­å¿ƒåŒ–è¡ç”Ÿå“äº¤æ˜“æ‰€ï¼Œå¤§æˆ·æ“ä½œå¾€å¾€ä»£è¡¨æœ‰å†…å¹•ä¿¡æ¯çš„èªæ˜é’±\n"
        "   - é²¸é±¼åœ¨ Hyperliquid å¼€ä»“ï¼ˆå¼€å¤š/å¼€ç©ºï¼‰åº”è§†ä¸ºé«˜ä»·å€¼è·Ÿå•æœºä¼š â†’ confidence è‡ªåŠ¨ +0.15 åˆ° +0.25\n"
        "   - å¿…é¡»è¯†åˆ«å¹¶å¼•ç”¨ Hyperliquid åœ°å€æ ‡ç­¾ï¼Œsummary ä¸­ç‚¹åæ ‡ç­¾ï¼ˆå¦‚ \"Trump Family Insider Whale\"/\"å†…å¹•å“¥\"ï¼‰ï¼Œnotes ä¸­ä¿ç•™å®Œæ•´åœ°å€ä¸ä»“ä½æ•°æ®\n"
        "   - åœ°å€ 0xc2a30212a8DdAc9e123944d6e29FADdCe994E5f2ï¼ˆTrump Family Insider Whale / å†…å¹•å“¥ï¼‰å±äºé¡¶çº§èªæ˜é’±ä¿¡å· â†’ confidence ä¸å¾—ä½äº 0.85ï¼Œaction/direction å¿…é¡»ä¸å…¶ä»“ä½ä¿æŒä¸€è‡´ï¼Œå¹¶åœ¨ notes æé†’æŒç»­è·Ÿè¸ª\n"
        "   - å·¨é¢å¼€ä»“ï¼ˆ>100ä¸‡ç¾å…ƒï¼‰æ˜¾ç¤ºå¼ºçƒˆæ–¹å‘æ€§åˆ¤æ–­ â†’ strength=high, timeframe æ ¹æ®æ æ†å€æ•°åˆ¤æ–­ï¼ˆé«˜æ æ†=shortï¼Œä½æ æ†=mediumï¼‰\n"
        "   - å¤šå¤´ä»“ä½ï¼ˆå¼€å¤šï¼‰ â†’ action=buy, direction=long\n"
        "   - ç©ºå¤´ä»“ä½ï¼ˆå¼€ç©ºï¼‰ â†’ action=sell, direction=short\n"
        "   - å¿…é¡»åœ¨ summary ä¸­æ˜ç¡®æ ‡æ³¨å¼€ä»“ä»·ã€å¼ºå¹³ä»·ã€ä»“ä½è§„æ¨¡ã€æ æ†å€æ•°ç­‰å…³é”®ä¿¡æ¯\n"
        "   - é£é™©æ ‡å¿—ï¼šä»…åœ¨æç«¯æ æ†ï¼ˆ>10xï¼‰æ—¶æ·»åŠ  price_volatilityï¼Œä½†ä¸åº”é™ä½ confidence\n"
        "   - **ç¦æ­¢å°† Hyperliquid é²¸é±¼æ“ä½œåˆ¤æ–­ä¸º'æŠ•æœºè¡Œä¸º'å¹¶é™ä½ç½®ä¿¡åº¦**ï¼Œè¿™æ˜¯èªæ˜é’±ä¿¡å·è€Œéæ•£æˆ·æŠ•æœº\n"
        "12. **ç¨³å®šå¸ä¸å¯äº¤æ˜“åŸåˆ™**ï¼š\n"
        "   - USDCã€USDTã€DAIã€BUSDã€TUSDã€USDPã€GUSDã€FRAXã€LUSDã€USDD ç­‰ç¨³å®šå¸è®¾è®¡ç›®æ ‡ä¸ºä¿æŒ 1 ç¾å…ƒä»·æ ¼ï¼Œä¸å­˜åœ¨ä»·æ ¼æ³¢åŠ¨äº¤æ˜“æœºä¼š\n"
        "   - æ¶‰åŠç¨³å®šå¸çš„åŸºç¡€è®¾æ–½ã€ä¾›åº”é‡ã€å¸‚å€¼ç­‰æ¶ˆæ¯ â†’ asset=NONEï¼Œaction=observeï¼Œconfidence â‰¤0.4\n"
        "   - **ç¤ºä¾‹**ï¼š\"Circle è·å¾—ç¾è”å‚¨æ”¯ä»˜é€šé“ï¼ŒUSDC å¸‚åœºåœ°ä½æå‡\" â†’ asset=NONEï¼Œnotes è¯´æ˜ \"USDC æ˜¯ç¨³å®šå¸ä¸å¯äº¤æ˜“ï¼Œè‹¥æƒ³å—ç›Šåº”å…³æ³¨ä½¿ç”¨ USDC çš„ DeFi åè®®æˆ–æ”¯ä»˜ç±»ä»£å¸\"\n"
        "   - **ä¾‹å¤–æƒ…å†µ**ï¼šä»…å½“ç¨³å®šå¸å‡ºç°æ˜ç¡®è„±é”šé£é™©ï¼ˆä»·æ ¼åç¦» >5%ã€depegã€æš´è·Œç­‰ï¼‰ â†’ action=sellã€direction=shortï¼Œconfidence â‰¥0.8\n"
        "   - å¯¹äºç¨³å®šå¸ç›¸å…³åˆ©å¥½æ¶ˆæ¯ï¼Œåº”åœ¨ notes ä¸­å»ºè®®å…³æ³¨å—ç›Šçš„ DeFi åè®®ï¼ˆAaveã€Curveã€Uniswap ç­‰ï¼‰æˆ–å…¶åŸç”Ÿä»£å¸ï¼Œè€Œéç¨³å®šå¸æœ¬èº«\n"
        "\n## å†å²å‚è€ƒä¸æ·±åº¦å¯¹æ¯”åˆ†æ âš ï¸ å¿…è¯»\n"
        "**å†å²è®°å¿†ç³»ç»Ÿå·²ä¸ºä½ æ£€ç´¢äº†æœ€ç›¸ä¼¼çš„å†å²äº‹ä»¶ï¼Œä½ å¿…é¡»è®¤çœŸåˆ†æå¯¹æ¯”**ï¼š\n"
        "1. **å®è§‚äº‹ä»¶æ·±åº¦å¯¹æ¯”**ï¼ˆå¦‚å·æ™®è´¸æ˜“æˆ˜ã€ç¾è”å‚¨æ”¿ç­–ã€åœ°ç¼˜å†²çªï¼‰ï¼š\n"
        "   - å½“å‰æ¶ˆæ¯æ¶‰åŠå®è§‚ä¸»é¢˜æ—¶ï¼Œå¿…é¡»æŸ¥æ‰¾ historical_reference.entries ä¸­æ˜¯å¦æœ‰ç›¸ä¼¼çš„å®è§‚äº‹ä»¶\n"
        "   - å¯¹æ¯”å†å²äº‹ä»¶çš„å¸‚åœºååº”ï¼šå½“æ—¶BTC/ETH/SOLä»·æ ¼å¦‚ä½•å˜åŒ–ï¼Ÿé£é™©åå¥½å¦‚ä½•ï¼Ÿ\n"
        "   - åˆ†ææœ¬æ¬¡äº‹ä»¶ä¸å†å²äº‹ä»¶çš„å¼‚åŒï¼šæ˜¯å¦æœ‰æ–°å˜é‡ï¼Ÿå¸‚åœºç¯å¢ƒæ˜¯å¦ä¸åŒï¼Ÿ\n"
        "   - åœ¨ notes ä¸­æ˜ç¡®å†™æ˜ï¼š\"å‚è€ƒå†å²è®°å¿† [XæœˆYæ—¥ç±»ä¼¼äº‹ä»¶]ï¼Œå½“æ—¶å¸‚åœºååº”ä¸º..., æœ¬æ¬¡å·®å¼‚åœ¨äº...\"\n"
        "2. **èµ„äº§ä»·æ ¼è”åŠ¨åˆ†æ**ï¼š\n"
        "   - å†å²è®°å¿†æ˜¾ç¤ºæŸèµ„äº§åœ¨ç±»ä¼¼äº‹ä»¶ä¸‹çš„è¡¨ç° â†’ è¯„ä¼°æœ¬æ¬¡æ˜¯å¦ä¼šé‡å¤\n"
        "   - å¦‚å†å²è®°å¿†æ˜¾ç¤ºBTCå› å®è§‚äº‹ä»¶ä¸‹è·Œ5% â†’ è¯„ä¼°æœ¬æ¬¡äº‹ä»¶æ˜¯å¦ä¼šå¯¼è‡´ç±»ä¼¼ä¸‹è·Œ\n"
        "   - å¿…é¡»åœ¨ summary æˆ– notes ä¸­æ˜ç¡®è¯´æ˜è”åŠ¨é€»è¾‘ï¼š\"[å®è§‚äº‹ä»¶] â†’ BTCä¸‹è·Œ â†’ å…¨å¸åœˆæ‰¿å‹\"\n"
        "3. **å·¨é²¸è¡Œä¸ºæ¨¡å¼è¯†åˆ«**ï¼š\n"
        "   - å†å²è®°å¿†ä¸­æœ‰å·¨é²¸åœ¨ç±»ä¼¼äº‹ä»¶ä¸‹çš„æ“ä½œ â†’ è¯„ä¼°å½“å‰å·¨é²¸åŠ¨å‘æ˜¯å¦ç¬¦åˆæ¨¡å¼\n"
        "   - æŸå·¨é²¸å†å²ä¸Šåœ¨Xäº‹ä»¶å‰ç²¾å‡†å¼€ç©º â†’ æœ¬æ¬¡è¯¥å·¨é²¸å†æ¬¡å¼€ç©º â†’ é«˜ç½®ä¿¡åº¦ä¿¡å·\n"
        "4. **äº‹ä»¶ç‹¬ç‰¹æ€§åˆ¤æ–­**ï¼š\n"
        "   - å¦‚æœå†å²è®°å¿†ä¸­æ‰¾ä¸åˆ°ç›¸ä¼¼æ¡ˆä¾‹ â†’ è¯´æ˜è¿™æ˜¯ç‹¬ç‰¹äº‹ä»¶ â†’ æé«˜è­¦æƒ•æˆ–é™ä½ç½®ä¿¡åº¦\n"
        "   - å¦‚æœå†å²è®°å¿†æ˜¾ç¤ºè¯¥ä¸»é¢˜/è§‚ç‚¹åå¤å‡ºç° â†’ è¯´æ˜æ˜¯è€ç”Ÿå¸¸è°ˆ â†’ å¤§å¹…é™ä½ç½®ä¿¡åº¦\n"
        "5. **å¼ºåˆ¶æ£€æŸ¥è§„åˆ™**ï¼š\n"
        "   - å¦‚æœ historical_reference.entries éç©ºï¼ˆæœ‰å†å²è®°å¿†ï¼‰â†’ å¿…é¡»åœ¨ notes ä¸­å¼•ç”¨è‡³å°‘1æ¡å†å²æ¡ˆä¾‹\n"
        "   - å¦‚æœ historical_reference.entries ä¸ºç©º â†’ åœ¨ notes ä¸­è¯´æ˜\"æ— å†å²ç›¸ä¼¼æ¡ˆä¾‹ï¼Œå±ç‹¬ç‰¹äº‹ä»¶\"\n"
        "   - ç¦æ­¢å¿½ç•¥å†å²è®°å¿†ï¼æ¯æ¡å†å²è®°å¿†éƒ½æ˜¯å®è´µçš„å†³ç­–å‚è€ƒ\n"
        "6. **å›é¡¾ç±»æ¶ˆæ¯è¯†åˆ«ä¸å¤„ç†** âš ï¸ é‡è¦ç‰¹æ€§ï¼š\n"
        "   - **å†å²è®°å¿†ä¸­çš„ `hours_ago` å­—æ®µè¡¨ç¤ºè¯¥äº‹ä»¶è·ç¦»å½“å‰æ¶ˆæ¯å‘å¸ƒçš„æ—¶é—´å·®**\n"
        "   - å¦‚æœå½“å‰æ¶ˆæ¯çš„ message_age_hours è¾ƒå°ï¼ˆ<2å°æ—¶ï¼‰ä½†å†å²è®°å¿†ä¸­æœ‰ hours_ago è¾ƒå¤§ï¼ˆ>4å°æ—¶ï¼‰çš„ç›¸ä¼¼äº‹ä»¶ â†’ è¿™æ˜¯å¯¹æ—©æœŸäº‹ä»¶çš„å›é¡¾/æ€»ç»“\n"
        "   - **å›é¡¾æ¶ˆæ¯ç‰¹å¾**ï¼š\n"
        "     * å½“å‰æ¶ˆæ¯å¾ˆæ–°ï¼ˆmessage_age_hours < 2hï¼‰\n"
        "     * ä½†å†å²è®°å¿†æ˜¾ç¤ºç±»ä¼¼äº‹ä»¶å‘ç”Ÿåœ¨æ›´æ—©æ—¶é—´ï¼ˆhours_ago > 4hï¼‰\n"
        "     * æ¶ˆæ¯å†…å®¹åŒ…å«å›é¡¾æ€§è¯­è¨€ï¼š\"å›é¡¾\"ã€\"æ€»ç»“\"ã€\"æ—©ç›˜\"ã€\"åˆç›˜\"ã€\"å›é¡¾ä»Šæ—¥\"ã€\"ä»Šæ—¥èµ°åŠ¿\"\n"
        "   - **å›é¡¾æ¶ˆæ¯å¤„ç†è§„åˆ™**ï¼š\n"
        "     * åœ¨ summary ä¸­æ˜ç¡®æ ‡æ³¨ï¼š\"å›é¡¾æ—©é—´äº‹ä»¶ï¼ˆXå°æ—¶å‰ï¼‰...\"\n"
        "     * åœ¨ notes ä¸­å¼•ç”¨å†å²è®°å¿†å¹¶è¯´æ˜æ—¶é—´å·®ï¼š\"å‚è€ƒå†å²è®°å¿† [timestamp hours_agoå°æ—¶å‰ç±»ä¼¼äº‹ä»¶]ï¼Œå½“æ—¶å¸‚åœºååº”ä¸º...\"\n"
        "     * é™ä½ confidenceï¼ˆ-0.20 to -0.30ï¼‰ï¼Œå› ä¸ºå¸‚åœºå¯èƒ½å·²å……åˆ†ååº”\n"
        "     * action å€¾å‘äº observe è€Œé buy/sellï¼Œé™¤éæœ‰æ–°çš„å‚¬åŒ–å‰‚æˆ–æœªå……åˆ†ååº”çš„è¿¹è±¡\n"
        "   - **ç¤ºä¾‹**ï¼šå½“å‰æ¶ˆæ¯ \"æ—©ä¸Šä¸­ç¾è´¸æ˜“è°ˆåˆ¤è¿›å±•é¡ºåˆ©ï¼ŒBTCä¸Šæ¶¨\"ï¼Œmessage_age_hours=1.2ï¼Œä½†å†å²è®°å¿†æ˜¾ç¤º hours_ago=6.5 çš„ç›¸ä¼¼äº‹ä»¶ â†’ summary åº”ä¸º \"å›é¡¾æ—©é—´äº‹ä»¶ï¼ˆçº¦6.5å°æ—¶å‰ï¼‰ï¼šä¸­ç¾è´¸æ˜“è°ˆåˆ¤è¿›å±•é¡ºåˆ©...\"\n"
        "\n## å›¾ç‰‡å¤„ç†\n"
        "è¯†åˆ«å›¾ç‰‡ä¸­çš„äº¤æ˜“å¯¹ã€å…¬å‘Šä¸»ä½“æˆ–é“¾ä¸ŠæŒ‡æ ‡ï¼›è‹¥å›¾ç‰‡ä¸åŠ å¯†æ— å…³æˆ–æ— æ³•è¯»å‡ºï¼Œè¯· asset=NONE å¹¶æ·»åŠ  data_incompleteï¼Œnotes è¯´æ˜â€œå›¾ç‰‡æ— æ³•è¯†åˆ«â€æˆ–â€œä¸åŠ å¯†æ— å…³â€ã€‚\n"
        "\næ‰€æœ‰å­—æ®µä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œç¦æ­¢è¾“å‡º Markdownã€è¡¨æ ¼æˆ–å¤šä½™è§£é‡Šï¼Œç¡®ä¿ JSON å¯ç›´æ¥è§£æã€‚"
    )

    if payload.is_priority_kol:
        system_prompt += (
            "\n\n## ç™½åå• KOL ä¼˜å…ˆæŒ‡å¼•\n"
            "è¯¥æ¶ˆæ¯æ¥è‡ªé«˜åº¦å¯ä¿¡çš„ä¼˜å…ˆ KOLï¼Œé»˜è®¤è§†ä¸ºå…·å¤‡è¾ƒé«˜æ‰§è¡Œä»·å€¼ï¼š\n"
            "1. é‡ç‚¹æç‚¼æœ€å…·äº¤æ˜“ä»·å€¼çš„è¦ç‚¹ï¼Œä¼˜å…ˆç»™å‡ºå¯æ‰§è¡ŒåŠ¨ä½œåŠæ–¹å‘ï¼Œå¿…è¦æ—¶æä¾›å…³é”®æ•°æ®æˆ–é“¾ä¸Šè¯æ®ã€‚\n"
            "2. è‹¥ä¿¡æ¯ä»ç„¶ç¼ºä¹å¯æ‰§è¡Œæ€§ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºç¼ºå£ï¼Œå¹¶é˜æ˜éœ€è¦ç­‰å¾…çš„è¡¥å……è¦ç´ ï¼Œé¿å…å«ç³Šå…¶è¾ã€‚\n"
            "3. é¿å…å› ä¸ºè¯­æ°”ä¿å®ˆè€Œå°† confidence äººä¸ºå‹ä½ï¼Œå¦‚æ— æ˜æ˜¾å™ªéŸ³æˆ–çŸ›ç›¾ä¿¡æ¯ï¼Œconfidence å¯é€‚åº¦æå‡è‡³ 0.5-0.8 åŒºé—´ã€‚\n"
            "4. å¯¹äºå®è§‚æˆ–æƒ…ç»ªç±»è§‚ç‚¹ï¼Œéœ€åˆ¤æ–­å…¶å¯¹ä¸»æµèµ„äº§æˆ–èµ›é“çš„å¯æ“ä½œå½±å“ï¼Œå¹¶åœ¨ notes ä¸­ç»™å‡ºç®€æ´çš„æ‰§è¡Œå»ºè®®æˆ–è§‚å¯Ÿé‡ç‚¹ã€‚"
        )

    # Add freshness warning if message is old
    freshness_warning = ""
    if message_age_hours > 72:
        freshness_warning = f"\n\nâš ï¸ **æ—¶æ•ˆæ€§è­¦å‘Š**ï¼šè¯¥æ¶ˆæ¯å‘å¸ƒäº {message_age_hours:.1f} å°æ—¶å‰ï¼ˆçº¦ {message_age_hours/24:.1f} å¤©ï¼‰ï¼Œå·²è¶…è¿‡72å°æ—¶æ—¶æ•ˆçª—å£ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§æ—¶æ•ˆæ€§åˆ¤æ–­è§„åˆ™é™ä½ç½®ä¿¡åº¦å¹¶æ ‡æ³¨è¿‡æœŸæç¤ºã€‚"
    elif message_age_hours > 24:
        freshness_warning = f"\n\nâš ï¸ **æ—¶æ•ˆæ€§æç¤º**ï¼šè¯¥æ¶ˆæ¯å‘å¸ƒäº {message_age_hours:.1f} å°æ—¶å‰ï¼Œè¯·é€‚åº¦é™ä½ç½®ä¿¡åº¦ï¼ˆ-0.10 to -0.20ï¼‰ã€‚"

    user_prompt = (
        "è¯·ç»“åˆä»¥ä¸‹äº‹ä»¶ä¸Šä¸‹æ–‡ç»™å‡ºæœ€å…·æ“ä½œæ€§çš„å»ºè®®ï¼Œè‹¥åŒ…å«å¤šæ¡ä¿¡æ¯éœ€ç»¼åˆåˆ¤æ–­ï¼š\n"
        f"```json\n{context_json}\n```"
        f"{freshness_warning}\n"
        "è¿”å›ä»…åŒ…å«ä¸Šè¿°å­—æ®µçš„ JSON å­—ç¬¦ä¸²ï¼Œç¦æ­¢å‡ºç°é¢å¤–æ–‡æœ¬ï¼›å¤šèµ„äº§è¯·ä½¿ç”¨ asset æ•°ç»„ï¼›notes é‡‡ç”¨çµæ´»è‡ªç„¶è¯­è¨€å‘ˆç°ï¼Œæ˜ç¡®ç»™å‡ºä¹°/å–/è§‚å¯Ÿä¾æ®ï¼Œå¹¶ä¼˜å…ˆå¼•ç”¨å®è§‚/ä»·æ ¼/å†å²è®°å¿†ä¸‰ç±»è¯æ®ï¼ˆè‹¥ç¼ºå¤±è¯·æ ‡æ³¨ï¼‰ã€‚"
    )

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
