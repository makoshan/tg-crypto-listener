"""AI Signal Engine orchestrating OpenAI-compatible inference."""

from __future__ import annotations

import asyncio
import json
import logging
import re
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, Optional, Sequence

from ..utils import analyze_event_intensity, setup_logger
from ..memory import MemoryBackendBundle, create_memory_backend
from .gemini_client import AiServiceError, GeminiClient
from .deep_analysis import (
    DeepAnalysisEngine,
    DeepAnalysisError,
    create_deep_analysis_engine,
)

try:  # pragma: no cover - optional dependency
    import httpx
except ImportError:  # pragma: no cover - runtime fallback
    httpx = None  # type: ignore

logger = setup_logger(__name__)

ALLOWED_ACTIONS = {"buy", "sell", "observe"}
ALLOWED_DIRECTIONS = {"long", "short", "neutral"}
ALLOWED_STRENGTH = {"low", "medium", "high"}
ALLOWED_TIMEFRAMES = {"short", "medium", "long"}  # çŸ­æœŸï¼ˆ<1å‘¨ï¼‰ã€ä¸­æœŸï¼ˆ1å‘¨-1æœˆï¼‰ã€é•¿æœŸï¼ˆ>1æœˆï¼‰
NO_ASSET_TOKENS = {
    "",
    "NONE",
    "æ— ",
    "NA",
    "N/A",
    "GENERAL",
    "GENERAL_CRYPTO",
    "CRYPTO",
    "MARKET",
    "MACRO",
}
FORBIDDEN_ASSET_PREFIXES = {"SP", "DJ", "ND", "HSI", "CSI", "FTSE"}
FORBIDDEN_ASSET_CODES = {
    "SPX",
    "SP500",
    "S&P500",
    "TSLA",
    "AAPL",
    "MSFT",
    "META",
    "AMZN",
    "NVDA",
    "BABA",
}
ASSET_CODE_REGEX = re.compile(r"^[A-Z0-9]{2,10}$")
ALLOWED_EVENT_TYPES = {
    "listing",
    "delisting",
    "hack",
    "regulation",
    "funding",
    "whale",
    "liquidation",
    "partnership",
    "product_launch",
    "governance",
    "macro",
    "celebrity",
    "airdrop",
    "scam_alert",      # ç–‘ä¼¼éª—å±€æˆ–é«˜é£é™©æŠ•æœºï¼ˆrug pullã€pump & dump ç­‰ï¼‰
    "other",
}
ALLOWED_RISK_FLAGS = {
    "price_volatility",
    "liquidity_risk",
    "regulation_risk",
    "confidence_low",
    "data_incomplete",
    "vague_timeline",      # æ—¶é—´çº¿æ¨¡ç³Šï¼ˆ"å³å°†"ã€"è¿‘æœŸ"ã€"ä¸ä¹…"ç­‰ï¼‰
    "speculative",         # æŠ•æœºæ€§/æ— å®è´¨å†…å®¹ï¼ˆ"å¤§äº‹ä»¶"ã€"é‡è¦æ›´æ–°"ç­‰ï¼‰
    "unverifiable",        # æ— æ³•éªŒè¯çš„å£°æ˜æˆ–é¢„æœŸ
}


@dataclass
class EventPayload:
    """Normalized data sent to the AI layer."""

    text: str
    source: str
    timestamp: datetime
    translated_text: Optional[str] = None
    language: str = "unknown"
    translation_confidence: float = 0.0
    keywords_hit: list[str] = field(default_factory=list)
    historical_reference: Dict[str, Any] = field(default_factory=dict)
    media: list[Dict[str, Any]] = field(default_factory=list)
    is_priority_kol: bool = False


@dataclass
class SignalResult:
    """AI decision packaged for downstream consumers."""

    status: str
    summary: str = ""
    event_type: str = "other"
    asset: str = ""
    asset_names: str = ""
    action: str = "observe"
    direction: str = "neutral"
    confidence: float = 0.0
    strength: str = "low"
    timeframe: str = "medium"  # short/medium/long - å»ºè®®æŒä»“æ—¶é—´èŒƒå›´
    risk_flags: list[str] = field(default_factory=list)
    raw_response: str = ""
    notes: str = ""
    error: Optional[str] = None
    links: list[str] = field(default_factory=list)
    alert: str = ""
    severity: str = ""

    @property
    def should_execute_hot_path(self) -> bool:
        return (
            self.status == "success"
            and self.action in {"buy", "sell"}
        )

    def is_high_value_signal(
        self,
        *,
        confidence_threshold: float = 0.75,
    ) -> bool:
        """Determine if signal qualifies for Claude deep analysis.

        Args:
            confidence_threshold: Minimum confidence for high-value classification

        Returns:
            True if signal meets high-value criteria
        """
        if self.status != "success":
            return False

        # Only trigger Claude for high confidence signals
        return self.confidence >= confidence_threshold


@dataclass
class OpenAIChatResponse:
    """Structured response returned by OpenAI-compatible models."""

    text: str


class OpenAIChatClient:
    """Generic client for OpenAI-compatible chat completion APIs."""

    def __init__(
        self,
        api_key: str,
        model_name: str,
        *,
        base_url: str,
        timeout: float,
        max_retries: int,
        retry_backoff_seconds: float,
        extra_headers: Optional[Dict[str, str]] = None,
    ) -> None:
        if not api_key:
            raise AiServiceError("AI API key is required")
        if httpx is None:
            raise AiServiceError("httpx æœªå®‰è£…ï¼Œè¯·å…ˆåœ¨ç¯å¢ƒä¸­å®‰è£…è¯¥ä¾èµ–")

        normalized_base = (base_url or "").strip()
        if not normalized_base:
            normalized_base = "https://api.openai.com/v1"
        self._endpoint = normalized_base.rstrip("/") + "/chat/completions"
        self._api_key = api_key
        self._model = model_name
        self._timeout = float(timeout)
        self._max_retries = max(0, int(max_retries))
        self._retry_backoff = max(0.0, float(retry_backoff_seconds))
        self._headers: Dict[str, str] = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        if extra_headers:
            for key, value in extra_headers.items():
                if key and value is not None:
                    self._headers[str(key)] = str(value)

    async def generate_signal(self, messages: Sequence[Dict[str, str]]) -> OpenAIChatResponse:
        """Execute prompt against OpenAI-compatible API and return text."""

        if not messages:
            raise AiServiceError("æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        payload = {
            "model": self._model,
            "messages": list(messages),
        }

        last_exc: Exception | None = None
        last_error_message = "AI è°ƒç”¨å¤±è´¥"
        last_error_temporary = False

        for attempt in range(self._max_retries + 1):
            try:
                async with httpx.AsyncClient(timeout=self._timeout) as client:
                    response = await client.post(
                        self._endpoint,
                        headers=self._headers,
                        json=payload,
                    )
                response.raise_for_status()
            except asyncio.CancelledError:
                raise
            except httpx.TimeoutException as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI è¯·æ±‚è¶…æ—¶"
                last_error_temporary = True
                logger.warning(
                    "AI è¯·æ±‚è¶…æ—¶ (attempt %s/%s)",
                    attempt + 1,
                    self._max_retries + 1,
                )
            except httpx.HTTPStatusError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                status_code = exc.response.status_code
                last_error_message = f"AI æœåŠ¡ç«¯è¿”å›é”™è¯¯çŠ¶æ€ç : {status_code}"
                last_error_temporary = status_code == 429 or 500 <= status_code < 600
                logger.warning(
                    "AI HTTP çŠ¶æ€é”™è¯¯ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    last_error_message,
                )
                logger.debug("AI å“åº”å†…å®¹: %s", exc.response.text)
            except httpx.RequestError as exc:  # type: ignore[attr-defined]
                last_exc = exc
                last_error_message = "AI ç½‘ç»œè¿æ¥å¼‚å¸¸"
                last_error_temporary = True
                logger.warning(
                    "AI ç½‘ç»œå¼‚å¸¸ (attempt %s/%s): %s",
                    attempt + 1,
                    self._max_retries + 1,
                    exc,
                )
            else:
                try:
                    data = response.json()
                except json.JSONDecodeError as exc:
                    raise AiServiceError("AI è¿”å›é JSON å†…å®¹") from exc

                choices = data.get("choices", [])
                if not choices:
                    raise AiServiceError("AI è¿”å›ç¼ºå°‘ choices å­—æ®µ")
                first_choice = choices[0] or {}
                message = first_choice.get("message") or {}
                content = message.get("content")
                if isinstance(content, list):
                    content = "".join(
                        part.get("text", "") if isinstance(part, dict) else str(part)
                        for part in content
                    )
                if not content:
                    raise AiServiceError("AI è¿”å›ç©ºå†…å®¹")
                return OpenAIChatResponse(text=str(content))

            if attempt < self._max_retries and self._retry_backoff > 0:
                backoff = self._retry_backoff * (2 ** attempt)
                logger.debug(
                    "AI å°†åœ¨ %.2f ç§’åé‡è¯• (attempt %s/%s)",
                    backoff,
                    attempt + 1,
                    self._max_retries + 1,
                )
                await asyncio.sleep(backoff)

        raise AiServiceError(last_error_message, temporary=last_error_temporary) from last_exc


class AiSignalEngine:
    """Coordinate optional AI powered signal generation with dual-engine routing."""

    def __init__(
        self,
        enabled: bool,
        client: Optional[OpenAIChatClient],
        threshold: float,
        semaphore: asyncio.Semaphore,
        *,
        provider_label: str = "AI",
        deep_analysis_engine: Optional[DeepAnalysisEngine] = None,
        deep_analysis_fallback: Optional[DeepAnalysisEngine] = None,
        deep_analysis_min_interval: float = 25.0,
        high_value_threshold: float = 0.75,
    ) -> None:
        self.enabled = enabled and client is not None
        self._client = client
        self._threshold = threshold
        self._semaphore = semaphore
        self._provider_label = provider_label or "AI"
        self._high_value_threshold = high_value_threshold
        self._deep_min_interval = float(deep_analysis_min_interval)
        self._last_deep_call_time: float = 0.0
        self._deep_enabled: bool = False
        self._deep_engine: DeepAnalysisEngine | None = None
        self._deep_fallback_engine: DeepAnalysisEngine | None = None
        self._deep_provider_label: str = ""
        self._deep_fallback_label: str = ""
        self._memory_bundle: MemoryBackendBundle | None = None
        self.attach_deep_analysis_engine(deep_analysis_engine, fallback=deep_analysis_fallback)

        if not self.enabled:
            logger.debug("AiSignalEngine æœªå¯ç”¨æˆ–ç¼ºå°‘å®¢æˆ·ç«¯ï¼Œæ‰€æœ‰æ¶ˆæ¯å°†è·³è¿‡ AI åˆ†æ")

    def attach_deep_analysis_engine(
        self,
        engine: Optional[DeepAnalysisEngine],
        *,
        fallback: Optional[DeepAnalysisEngine] = None,
    ) -> None:
        self._deep_engine = engine
        self._deep_fallback_engine = fallback
        self._deep_provider_label = engine.provider_name if engine else ""
        self._deep_fallback_label = fallback.provider_name if fallback else ""
        self._deep_enabled = engine is not None

        if engine:
            logger.info("ğŸ¤– æ·±åº¦åˆ†æå·²å¯ç”¨ (provider=%s)", self._deep_provider_label or "unknown")
        if fallback:
            logger.info("ğŸ” æ·±åº¦åˆ†æå¤‡ç”¨å¼•æ“å·²é…ç½® (provider=%s)", self._deep_fallback_label or "unknown")


    @classmethod
    def from_config(cls, config: Any) -> "AiSignalEngine":
        if not getattr(config, "AI_ENABLED", False):
            logger.debug("é…ç½®å…³é—­ AI åŠŸèƒ½ï¼Œé‡‡ç”¨ä¼ ç»Ÿè½¬å‘æµç¨‹")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label="AI",
            )

        provider_raw = str(getattr(config, "AI_PROVIDER", "gemini")).strip().lower()
        provider_alias = {
            "chatgpt": "openai",
            "gpt": "openai",
            "openai": "openai",
            "deepseek": "deepseek",
            "qwen": "qwen",
            "åƒé—®": "qwen",
            "qianwen": "qwen",
            "gemini": "gemini",
        }
        provider = provider_alias.get(provider_raw, provider_raw or "gemini")
        provider_label = provider.upper() if provider else "AI"

        api_key = (
            getattr(config, "AI_API_KEY", None)
            or getattr(config, "GEMINI_API_KEY", None)
            or ""
        )

        if not api_key:
            logger.warning("AI å·²å¯ç”¨ä½†æœªæä¾› API Keyï¼Œè‡ªåŠ¨é™çº§ä¸ºè·³è¿‡ AI åˆ†æ")
            return cls(
                False,
                None,
                getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
                asyncio.Semaphore(1),
                provider_label=provider_label,
            )

        base_url = getattr(config, "AI_BASE_URL", "").strip()
        if not base_url:
            base_url = {
                "openai": "https://api.openai.com/v1",
                "deepseek": "https://api.deepseek.com",
                "qwen": "https://dashscope.aliyuncs.com/compatible-mode/v1",
                "gemini": "https://generativelanguage.googleapis.com/v1beta/openai",
            }.get(provider, "https://api.openai.com/v1")

        extra_headers: Dict[str, str] = {}
        raw_headers = getattr(config, "AI_EXTRA_HEADERS", "")
        if raw_headers:
            try:
                parsed = json.loads(raw_headers)
            except (TypeError, ValueError):
                logger.warning("AI_EXTRA_HEADERS ä¸æ˜¯æœ‰æ•ˆçš„ JSONï¼Œå°†å¿½ç•¥è¯¥é…ç½®")
            else:
                if isinstance(parsed, dict):
                    extra_headers = {
                        str(key): str(value)
                        for key, value in parsed.items()
                        if value is not None
                    }

        try:
            # Use native GeminiClient for Gemini (supports multimodal)
            if provider == "gemini":
                # Get all Gemini API keys for rotation
                api_keys = getattr(config, "GEMINI_API_KEYS", [])
                client = GeminiClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gemini-2.0-flash-exp"),
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                    api_keys=api_keys if api_keys else None,
                )
            else:
                # Use OpenAI-compatible client for others
                client = OpenAIChatClient(
                    api_key=str(api_key),
                    model_name=getattr(config, "AI_MODEL_NAME", "gpt-4o-mini"),
                    base_url=base_url,
                    timeout=getattr(config, "AI_TIMEOUT_SECONDS", 8.0),
                    max_retries=getattr(config, "AI_RETRY_ATTEMPTS", 1),
                    retry_backoff_seconds=getattr(config, "AI_RETRY_BACKOFF_SECONDS", 1.5),
                    extra_headers=extra_headers or None,
                )
        except AiServiceError as exc:
            logger.warning("AI åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä»¥é™çº§æ¨¡å¼è¿è¡Œ: %s", exc, exc_info=True)
            return cls(False, None, getattr(config, "AI_SIGNAL_THRESHOLD", 0.0), asyncio.Semaphore(1))

        concurrency = max(1, int(getattr(config, "AI_MAX_CONCURRENCY", 1)))
        high_value_threshold = getattr(config, "HIGH_VALUE_CONFIDENCE_THRESHOLD", 0.75)
        deep_min_interval = getattr(config, "DEEP_ANALYSIS_MIN_INTERVAL", 25.0)

        engine = cls(
            True,
            client,
            getattr(config, "AI_SIGNAL_THRESHOLD", 0.0),
            asyncio.Semaphore(concurrency),
            provider_label=provider_label,
            deep_analysis_min_interval=deep_min_interval,
            high_value_threshold=high_value_threshold,
        )

        memory_bundle = create_memory_backend(config)
        engine._memory_bundle = memory_bundle

        deep_config = getattr(config, "get_deep_analysis_config", lambda: {})()
        deep_engine: DeepAnalysisEngine | None = None
        fallback_engine: DeepAnalysisEngine | None = None

        if deep_config.get("enabled"):
            provider_name = deep_config.get("provider", "claude")
            try:
                deep_engine = create_deep_analysis_engine(
                    provider=provider_name,
                    config=config,
                    parse_callback=engine._parse_response_text,
                    memory_bundle=memory_bundle,
                )
            except DeepAnalysisError as exc:
                logger.warning("æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", provider_name, exc)

            fallback_name = deep_config.get("fallback_provider")
            if fallback_name and fallback_name != provider_name:
                try:
                    fallback_engine = create_deep_analysis_engine(
                        provider=fallback_name,
                        config=config,
                        parse_callback=engine._parse_response_text,
                        memory_bundle=memory_bundle,
                    )
                except DeepAnalysisError as exc:
                    logger.warning("å¤‡ç”¨æ·±åº¦åˆ†æå¼•æ“ %s åˆå§‹åŒ–å¤±è´¥: %s", fallback_name, exc)

        engine.attach_deep_analysis_engine(deep_engine, fallback=fallback_engine)
        return engine

    async def analyse(self, payload: EventPayload) -> SignalResult:
        if not self.enabled or not self._client:
            logger.debug("AI å·²ç¦ç”¨ï¼Œsource=%s çš„æ¶ˆæ¯ç›´æ¥è·³è¿‡", payload.source)
            return SignalResult(status="skip", summary="AI disabled")

        messages = build_signal_prompt(payload)
        logger.debug(
            "AI åˆ†æå¼€å§‹: source=%s len=%d lang=%s preview=%s",
            payload.source,
            len(payload.text),
            payload.language,
            payload.text[:80].replace("\n", " "),
        )

        # Extract images for GeminiClient multimodal support
        images = None
        if isinstance(self._client, GeminiClient) and payload.media:
            images = [
                {"base64": img["base64"], "mime_type": img["mime_type"]}
                for img in payload.media
                if img.get("base64") and img.get("mime_type")
            ]
            if images:
                logger.debug("AI åˆ†æåŒ…å« %d å¼ å›¾ç‰‡", len(images))

        # Step 1: Gemini fast analysis (90%)
        async with self._semaphore:
            try:
                if isinstance(self._client, GeminiClient):
                    response = await self._client.generate_signal(messages, images=images)
                else:
                    response = await self._client.generate_signal(messages)
            except AiServiceError as exc:
                is_temporary = getattr(exc, "temporary", False)
                logger.warning(
                    "AI è°ƒç”¨å¤±è´¥: %s",
                    exc,
                    exc_info=not is_temporary,
                )
                return SignalResult(status="error", error=str(exc))

        response_text = getattr(response, "text", "") or ""
        logger.debug("%s è¿”å›é•¿åº¦: %d", self._provider_label, len(response_text))
        parts = getattr(response, "parts", None)
        self._log_ai_response_debug(self._provider_label, response_text, parts)
        gemini_result = self._parse_response(response)
        gemini_result = self._apply_extreme_event_overrides(payload, gemini_result)

        # Step 2: Determine whether to trigger deep analysis
        is_high_value = gemini_result.is_high_value_signal(
            confidence_threshold=self._high_value_threshold,
        )

        logger.debug(
            "ğŸ¤– %s åˆ†æå®Œæˆ: action=%s confidence=%.2f event_type=%s asset=%s is_high_value=%s",
            self._provider_label,
            gemini_result.action,
            gemini_result.confidence,
            gemini_result.event_type,
            gemini_result.asset,
            is_high_value,
        )

        # æ’é™¤ä½ä»·å€¼äº‹ä»¶ç±»å‹ï¼ˆmacroã€other è§¦å‘è¿‡å¤šä¸”ä»·å€¼ä½ï¼Œscam_alert å·²ç»æ˜¯é£é™©è­¦å‘Šï¼‰
        # airdrop: ç©ºæŠ•ç±»æ´»åŠ¨ä»·å€¼ä½ã€æŠ•æœºæ€§å¼º
        # Binance Alpha ç›¸å…³çš„ listing ä¹Ÿå€¾å‘äºä½å¸‚å€¼ã€é«˜æŠ•æœºï¼Œé€šè¿‡ AI prompt æ§åˆ¶ç½®ä¿¡åº¦
        excluded_event_types = {"macro", "other", "airdrop", "governance", "celebrity", "scam_alert"}
        should_skip_deep = gemini_result.event_type in excluded_event_types

        deep_engine = self._deep_engine
        fallback_engine = self._deep_fallback_engine
        deep_label = self._deep_provider_label or "deep"
        fallback_label = self._deep_fallback_label or "fallback"

        # é¢‘ç‡é™åˆ¶æ£€æŸ¥
        import time

        time_since_last_call = time.time() - self._last_deep_call_time
        rate_limited = time_since_last_call < self._deep_min_interval

        if should_skip_deep and is_high_value:
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆä½ä»·å€¼äº‹ä»¶ç±»å‹ %sï¼‰: confidence=%.2f asset=%s",
                gemini_result.event_type,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif rate_limited and is_high_value and self._deep_enabled:
            logger.debug(
                "â­ï¸  è·³è¿‡æ·±åº¦åˆ†æï¼ˆé¢‘ç‡é™åˆ¶ï¼Œè·ä¸Šæ¬¡è°ƒç”¨ %.1f ç§’ï¼‰: confidence=%.2f asset=%s",
                time_since_last_call,
                gemini_result.confidence,
                gemini_result.asset,
            )
        elif self._deep_enabled and deep_engine and is_high_value:
            logger.info(
                "ğŸ§  è§¦å‘ %s æ·±åº¦åˆ†æ: event_type=%s confidence=%.2f asset=%s (é˜ˆå€¼: %.2f) source=%s",
                deep_label,
                gemini_result.event_type,
                gemini_result.confidence,
                gemini_result.asset,
                self._high_value_threshold,
                payload.source,
            )
            logger.debug(
                "æ·±åº¦åˆ†æå¼•æ“ç±»å‹: %s, æœ‰å¤‡ç”¨å¼•æ“: %s",
                type(deep_engine).__name__,
                "æ˜¯" if fallback_engine else "å¦",
            )
            self._last_deep_call_time = time.time()
            try:
                logger.debug("æ­£åœ¨è°ƒç”¨ %s å¼•æ“æ‰§è¡Œæ·±åº¦åˆ†æ...", deep_label)
                deep_result = await deep_engine.analyse(payload, gemini_result)
                logger.info(
                    "âœ… %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f (%s åˆåˆ¤: %.2f) asset=%s summary=%s",
                    deep_label,
                    deep_result.action,
                    deep_result.confidence,
                    self._provider_label,
                    gemini_result.confidence,
                    deep_result.asset,
                    deep_result.summary[:100] if deep_result.summary else "",
                )
                return deep_result
            except DeepAnalysisError as exc:
                logger.warning(
                    "âš ï¸ %s æ·±åº¦åˆ†æå¤±è´¥ï¼Œå°†å°è¯•å¤‡ç”¨æˆ–å›é€€åˆ°ä¸»åˆ†æç»“æœ: %s",
                    deep_label,
                    exc,
                    exc_info=True,
                )
                if fallback_engine:
                    try:
                        logger.info("ğŸ” å°è¯•å¤‡ç”¨æ·±åº¦å¼•æ“ %s (ç±»å‹: %s)", fallback_label, type(fallback_engine).__name__)
                        fallback_result = await fallback_engine.analyse(payload, gemini_result)
                        logger.info(
                            "âœ… å¤‡ç”¨å¼•æ“ %s æ·±åº¦åˆ†æå®Œæˆ: action=%s confidence=%.2f summary=%s",
                            fallback_label,
                            fallback_result.action,
                            fallback_result.confidence,
                            fallback_result.summary[:100] if fallback_result.summary else "",
                        )
                        return fallback_result
                    except DeepAnalysisError as fallback_exc:
                        logger.warning(
                            "âš ï¸ å¤‡ç”¨æ·±åº¦å¼•æ“ %s å¤±è´¥: %s",
                            fallback_label,
                            fallback_exc,
                            exc_info=True,
                        )
                else:
                    logger.debug("æ— å¤‡ç”¨æ·±åº¦å¼•æ“å¯ç”¨ï¼Œå°†ä½¿ç”¨ä¸»å¼•æ“åˆ†æç»“æœ")

        return gemini_result

    @staticmethod
    def _log_ai_response_debug(label: str, text: str, parts: Sequence[Any] | None = None) -> None:
        """Log raw AI responses with truncation to avoid noisy logs."""
        if parts:
            try:
                part_types = [
                    getattr(part, "type", None)
                    or getattr(part, "type_", None)
                    or type(part).__name__
                    for part in parts
                ]
                logger.debug("%s å“åº”åŒ…å«ç»“æ„åŒ–åˆ†æ®µ: %s", label, part_types)
            except Exception:
                logger.debug("%s ç»“æ„åŒ–åˆ†æ®µç±»å‹ç»Ÿè®¡å¤±è´¥", label, exc_info=True)

        if not text:
            logger.debug("%s åŸå§‹å“åº”ä¸ºç©ºå­—ç¬¦ä¸²", label)
            return

        snippet = text.strip()
        max_length = 800
        if len(snippet) > max_length:
            snippet = f"{snippet[:max_length]}â€¦(truncated)"
        logger.debug("%s åŸå§‹å“åº”: %s", label, snippet)

    def _parse_response(self, response: OpenAIChatResponse) -> SignalResult:
        return self._parse_response_text(response.text)

    def _parse_response_text(self, text: str) -> SignalResult:
        raw_text = (text or "").strip()
        normalized_text = self._prepare_json_text(raw_text)

        asset = ""
        try:
            data = json.loads(normalized_text)
            # Parse confidence safely for debug log
            confidence_debug = data.get("confidence", 1.0)
            if isinstance(confidence_debug, str):
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence_debug = confidence_map.get(confidence_debug.lower(), 0.0)
            else:
                try:
                    confidence_debug = float(confidence_debug)
                except (ValueError, TypeError):
                    confidence_debug = 1.0

            logger.debug(
                "AI JSON è§£ææˆåŠŸ: action=%s confidence=%.2f",
                data.get("action"),
                confidence_debug,
            )
            summary = str(data.get("summary", "")).strip()
            event_type = str(data.get("event_type", "other")).lower()
            asset_field = data.get("asset", "")
            asset_name_field = (
                data.get("asset_name")
                or data.get("asset_names")
                or data.get("asset_display")
                or ""
            )
            action = str(data.get("action", "observe")).lower()
            direction = str(data.get("direction", "neutral")).lower()
            strength = str(data.get("strength", "low")).lower()
            timeframe = str(data.get("timeframe", "medium")).lower()

            # Handle confidence - should be float but AI sometimes returns string like "high"
            confidence_raw = data.get("confidence", 1.0)
            if isinstance(confidence_raw, str):
                # Map string values to numeric confidence
                confidence_map = {"high": 0.8, "medium": 0.5, "low": 0.3}
                confidence = confidence_map.get(confidence_raw.lower(), 0.0)
                logger.warning(
                    "AI è¿”å›äº†å­—ç¬¦ä¸² confidence '%s'ï¼Œå·²è½¬æ¢ä¸ºæ•°å­— %.2f",
                    confidence_raw,
                    confidence,
                )
            else:
                try:
                    confidence = float(confidence_raw)
                except (ValueError, TypeError):
                    logger.warning(
                        "æ— æ³•è§£æ confidence å€¼ '%s'ï¼Œä½¿ç”¨é»˜è®¤å€¼ 1.0",
                        confidence_raw,
                    )
                    confidence = 1.0
            risk_flags = data.get("risk_flags", []) or []
            if not isinstance(risk_flags, list):
                risk_flags = [str(risk_flags)]
            notes = str(data.get("notes", "")).strip()
            links_raw = data.get("links", [])
            if isinstance(links_raw, str):
                links = [links_raw]
            elif isinstance(links_raw, list):
                links = [str(item).strip() for item in links_raw if str(item).strip()]
            else:
                links = []
            if links:
                # å»é‡åŒæ—¶ä¿æŒé¡ºåºï¼Œé¿å…åŒä¸€æ¥æºè¢«é‡å¤æ¸²æŸ“
                links = list(dict.fromkeys(links))
            if isinstance(asset_field, (list, tuple)):
                asset = ",".join(str(item).strip() for item in asset_field if str(item).strip())
            else:
                asset = str(asset_field).strip()
            if isinstance(asset_name_field, (list, tuple)):
                asset_names = "ã€".join(
                    str(item).strip() for item in asset_name_field if str(item).strip()
                )
            else:
                asset_names = str(asset_name_field).strip()
        except json.JSONDecodeError:
            logger.debug(
                "AI è¿”å›æ— æ³•è§£æä¸º JSONï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ‘˜è¦: %s",
                normalized_text[:120].replace("\n", " "),
            )
            summary = "AI è¿”å›æ ¼å¼å¼‚å¸¸ï¼Œå·²å¿½ç•¥åŸå§‹å†…å®¹"
            event_type = "other"
            asset = ""
            asset_names = ""
            action = "observe"
            direction = "neutral"
            strength = "low"
            timeframe = "medium"
            confidence = 1.0
            risk_flags = ["confidence_low"]
            notes = ""
            links = []

        event_type = event_type if event_type in ALLOWED_EVENT_TYPES else "other"
        action = action if action in ALLOWED_ACTIONS else "observe"
        direction = direction if direction in ALLOWED_DIRECTIONS else "neutral"
        if strength not in ALLOWED_STRENGTH:
            strength = "low"
        if timeframe not in ALLOWED_TIMEFRAMES:
            timeframe = "medium"

        asset = asset.upper().strip()
        asset_tokens = [token.strip() for token in asset.split(",") if token.strip()]
        normalized_assets = []
        for token in asset_tokens:
            if token in NO_ASSET_TOKENS:
                continue
            if not ASSET_CODE_REGEX.match(token):
                continue
            if any(token.startswith(prefix) for prefix in FORBIDDEN_ASSET_PREFIXES):
                continue
            if token in FORBIDDEN_ASSET_CODES:
                continue
            normalized_assets.append(token)
        if asset_names:
            canonical_name = asset_names.strip()
            upper_name = canonical_name.upper()
            if upper_name in {"NONE", "NA", "N/A"} or canonical_name in {"æ— ", "æš‚æ— "}:
                asset_names = ""

        if not normalized_assets:
            asset = "NONE"
            asset_names = ""
        else:
            asset = ",".join(normalized_assets)
            if not asset_names:
                asset_names = ",".join(normalized_assets)
        confidence = max(0.0, min(1.0, round(confidence, 2)))
        filtered_flags: list[str] = []
        for flag in risk_flags:
            if not isinstance(flag, str):
                continue
            value = flag.strip()
            if value in ALLOWED_RISK_FLAGS:
                filtered_flags.append(value)
        if not filtered_flags and confidence < 0.3:
            filtered_flags.append("confidence_low")

        has_crypto_asset = asset != "NONE"
        noise_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_noise_flag = any(flag in noise_flags for flag in filtered_flags)

        result = SignalResult(
            status="skip",
            summary=summary,
            event_type=event_type,
            asset=asset,
            asset_names=asset_names,
            action=action,
            direction=direction,
            confidence=confidence,
            strength=strength,
            timeframe=timeframe,
            risk_flags=filtered_flags,
            raw_response=raw_text,
            notes=notes,
            links=links,
        )
        self._finalize_signal_status(
            result,
            has_crypto_asset=has_crypto_asset,
            has_noise_flag=has_noise_flag,
        )
        return result


    @staticmethod
    def _prepare_json_text(text: str) -> str:
        """Strip Markdown/code fences and return best-effort JSON payload."""
        candidate = text.strip()
        if candidate.startswith("```") and candidate.endswith("```"):
            candidate = candidate[3:-3].strip()
        if candidate.lower().startswith("json"):
            candidate = candidate[4:].strip("\n :")
        if candidate.lower().startswith("python"):
            candidate = candidate[6:].strip("\n :")
        candidate = candidate.lstrip()
        if candidate.startswith("{") or candidate.startswith("["):
            return candidate
        return candidate

    def _apply_extreme_event_overrides(
        self,
        payload: EventPayload,
        result: SignalResult,
    ) -> SignalResult:
        """Adjust AI output for extreme depeg/liquidation scenarios."""
        if not payload.text and not payload.translated_text:
            return result

        analysis = analyze_event_intensity(
            payload.text or "",
            payload.translated_text or "",
        )
        has_extreme_move = analysis["has_high_impact"] and (
            analysis["has_percent_change"]
            or analysis["has_price_level_change"]
            or analysis["has_drop_keyword"]
        )

        asset_tokens = {
            token.strip().lower()
            for token in (result.asset or "").split(",")
            if token.strip()
        }
        mentions_critical_asset = analysis["mentions_critical_asset"] or bool(
            asset_tokens & {"usde", "wbeth", "wbtc", "wbsol", "stablecoin"}
        )

        modified = False

        if has_extreme_move:
            result.confidence = min(1.0, max(result.confidence + 0.2, 0.0))
            if not result.alert:
                result.alert = "extreme_market_move"
            if not result.severity:
                result.severity = "high"
            if "price_volatility" not in result.risk_flags:
                result.risk_flags.append("price_volatility")
            modified = True

        if has_extreme_move and mentions_critical_asset:
            if result.action != "sell":
                result.action = "sell"
                modified = True
            if result.direction != "short":
                result.direction = "short"
                modified = True
            if result.confidence < 0.8:
                result.confidence = min(1.0, max(result.confidence, 0.8))
                modified = True

        if result.alert or result.severity or modified:
            self._refresh_signal_status(result)

        return result

    def _finalize_signal_status(
        self,
        result: SignalResult,
        *,
        has_crypto_asset: bool,
        has_noise_flag: bool,
    ) -> None:
        """Evaluate signal eligibility after confidence/action adjustments."""
        effective_threshold = max(self._threshold, 0.4)

        if has_noise_flag and result.confidence < 0.7:
            result.status = "skip"
        elif result.confidence >= effective_threshold and has_crypto_asset:
            result.status = "success"
        else:
            result.status = "skip"

        if not has_crypto_asset and "data_incomplete" not in result.risk_flags:
            result.risk_flags.append("data_incomplete")

    def _refresh_signal_status(self, result: SignalResult) -> None:
        """Re-run status gating using current signal attributes."""
        has_crypto_asset = bool(result.asset and result.asset != "NONE")
        noise_flags = {"speculative", "vague_timeline", "unverifiable"}
        has_noise_flag = any(flag in noise_flags for flag in result.risk_flags)
        self._finalize_signal_status(
            result,
            has_crypto_asset=has_crypto_asset,
            has_noise_flag=has_noise_flag,
        )


def build_signal_prompt(payload: EventPayload) -> list[dict[str, str]]:
    context = {
        "source": payload.source,
        "timestamp": payload.timestamp.isoformat(),
        "language": payload.language,
        "translation_confidence": payload.translation_confidence,
        "original_text": payload.text,
        "translated_text": payload.translated_text or payload.text,
        "keywords_hit": payload.keywords_hit,
        "historical_reference": payload.historical_reference,
        "media_attachments": payload.media,
        "is_priority_kol": payload.is_priority_kol,
        "priority_flags": ["priority_kol"] if payload.is_priority_kol else [],
    }

    context_json = json.dumps(context, ensure_ascii=False)

    system_prompt = (
        "ä½ æ˜¯åŠ å¯†äº¤æ˜“å°çš„èµ„æ·±åˆ†æå¸ˆï¼Œéœ€è¦ä»å¤šè¯­ç§å¿«è®¯ä¸­å¿«é€Ÿæç‚¼å¯äº¤æ˜“ä¿¡å·ã€‚\n"
        "åŠ¡å¿…ä»…è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ï¼Œç¦æ­¢ç”Ÿæˆå¤šæ®µ JSONã€åˆ—è¡¨å¤–å±‚æˆ– Markdown ä»£ç å—ï¼Œè¾“å‡ºå‰åä¸å¾—é™„åŠ  ```ã€#ã€è¯´æ˜æ–‡å­—æˆ–é¢å¤–æ®µè½ã€‚\n"
        "JSON å­—æ®µå›ºå®šä¸º summaryã€event_typeã€assetã€asset_nameã€actionã€directionã€confidenceã€strengthã€timeframeã€risk_flagsã€notesã€‚\n"
        "**summary å­—æ®µå¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡æ’°å†™ï¼Œç®€æ˜æ‰¼è¦ï¼ˆ1-2 å¥è¯ï¼‰ï¼Œç›´æ¥è¯´æ˜æ ¸å¿ƒäº‹ä»¶å’Œå½±å“ã€‚**\n"
        "event_type ä»…èƒ½å– listingã€delistingã€hackã€regulationã€fundingã€whaleã€liquidationã€partnershipã€product_launchã€governanceã€macroã€celebrityã€airdropã€scam_alertã€otherã€‚\n"
        "action ä¸º buyã€sellã€observeï¼›direction ä¸º longã€shortã€neutralï¼›strength ä»…å– highã€mediumã€lowï¼›timeframe ä»…å– shortã€mediumã€longã€‚\n"
        "å¦‚äº‹ä»¶æ¶‰åŠå¤šä¸ªå¸ç§ï¼Œasset å¯ä¸ºæ•°ç»„ï¼ˆå¦‚ [\"BTC\",\"ETH\"]ï¼‰ï¼Œasset_name ç”¨ç®€ä½“ä¸­æ–‡åä»¥é¡¿å·æˆ–é€—å·åˆ†éš”ï¼›è‹¥æ— æ³•ç¡®è®¤å¸ç§åˆ™ asset=NONEã€asset_name=æ— ï¼Œå¹¶åœ¨ notes è§£é‡ŠåŸå› ã€‚\n"
        "**é»„é‡‘æ˜ å°„è§„åˆ™**ï¼šå½“æ¶ˆæ¯æ¶‰åŠé»„é‡‘ï¼ˆGold/XAU/é»„é‡‘æœŸè´§ï¼‰æ—¶ï¼Œä½¿ç”¨ asset=XAUTï¼ˆTether Gold ä»£å¸ï¼‰æ¥æŸ¥è¯¢ä»·æ ¼å’Œåˆ†æã€‚\n"
        "\n## ä¸»æµå¸å¸‚åœºæŒ‡æ ‡é‡è¦æ€§ âš ï¸ æ ¸å¿ƒä¼˜å…ˆçº§\n"
        "**BTCï¼ˆæ¯”ç‰¹å¸ï¼‰æ˜¯æ•´ä¸ªåŠ å¯†å¸‚åœºçš„é£å‘æ ‡å’Œå®è§‚æŒ‡æ ‡**ï¼š\n"
        "1. **å®è§‚å…³è”æ€§**ï¼šæ¯”ç‰¹å¸ä»·æ ¼ä¸å…¨çƒå®è§‚ç¯å¢ƒï¼ˆç¾è”å‚¨æ”¿ç­–ã€ç¾å…ƒæŒ‡æ•°ã€åœ°ç¼˜æ”¿æ²»ï¼‰é«˜åº¦ç›¸å…³ï¼Œæ˜¯åŠ å¯†å¸‚åœºé£é™©åå¥½çš„æ ¸å¿ƒæŒ‡æ ‡ã€‚\n"
        "2. **å¸‚åœºè”åŠ¨æ€§**ï¼šå½“æ¯”ç‰¹å¸æ¶¨è·Œæ—¶ï¼Œæ•´ä¸ªåŠ å¯†å¸‚åœºï¼ˆETHã€SOLã€å±±å¯¨å¸ï¼‰é€šå¸¸åŒå‘æ³¢åŠ¨ï¼ŒBTC è·Œæ„å‘³ç€å…¨å¸åœˆæ‰¿å‹ã€‚\n"
        "3. **å®è§‚ä¼ å¯¼æœºåˆ¶**ï¼š\n"
        "   - è´¸æ˜“æˆ˜/åœ°ç¼˜å†²çª â†’ é£é™©åå¥½ä¸‹é™ â†’ BTC ä¸‹è·Œ â†’ å…¨å¸åœˆä¸‹è·Œ\n"
        "   - ç¾è”å‚¨åŠ æ¯/ç¾å…ƒèµ°å¼º â†’ æµåŠ¨æ€§æ”¶ç´§ â†’ BTC æ‰¿å‹ â†’ åŠ å¯†å¸‚åœºæ•´ä½“å›è°ƒ\n"
        "   - å®è§‚åˆ©å¥½ï¼ˆé™æ¯é¢„æœŸã€æœºæ„å…¥åœºï¼‰ â†’ BTC ä¸Šæ¶¨ â†’ å¸¦åŠ¨æ•´ä¸ªåŠ å¯†å¸‚åœº\n"
        "4. **ä¸»æµå¸ä¼˜å…ˆçº§**ï¼šBTC > ETH > SOLï¼Œè¿™ä¸‰ä¸ªå¸ç§çš„ä»·æ ¼å˜åŒ–å¿…é¡»é‡ç‚¹å…³æ³¨å¹¶æé†’ã€‚\n"
        "5. **ä¸»æµå¸ä¿¡å·å¢å¼ºè§„åˆ™**ï¼š\n"
        "   - æ¶‰åŠ BTC/ETH/SOL ä»·æ ¼æ¶¨è·Œ â‰¥3% â†’ confidence è‡ªåŠ¨ +0.15 åˆ° +0.25\n"
        "   - æ¶‰åŠ BTC çªç ´å…³é”®å¿ƒç†å…³å£ï¼ˆå¦‚ $100Kã€$90Kï¼‰ â†’ confidence â‰¥0.75, strength=high\n"
        "   - æ¶‰åŠ BTC ä¸å®è§‚äº‹ä»¶ï¼ˆå·æ™®ã€è´¸æ˜“æˆ˜ã€ç¾è”å‚¨ã€CPIï¼‰ â†’ å¿…é¡»åœ¨ summary ä¸­æ˜ç¡®è¯´æ˜å®è§‚å½±å“å’Œå¸‚åœºè”åŠ¨\n"
        "   - ä¸»æµå¸å¤§æ¶¨ï¼ˆâ‰¥5%ï¼‰æˆ–å¤§è·Œï¼ˆâ‰¤-5%ï¼‰ â†’ action å¿…é¡»æ˜ç¡®ï¼ˆbuy/sellï¼‰ï¼Œé¿å…æ¨¡ç³Šçš„ observe\n"
        "\n## ç½®ä¿¡åº¦ï¼ˆconfidenceï¼‰\n"
        "confidence è¡¡é‡è¯¥ä¿¡å·æ˜¯å¦å€¼å¾—æ‰§è¡Œï¼š0.7-1.0 é«˜å¯ä¿¡ã€0.4-0.7 ä¸­ç­‰ã€0.0-0.4 ä»…æç¤ºé£é™©æˆ–å™ªéŸ³ï¼›å³ä½¿äº‹ä»¶çœŸå®ä½†ä¸å¯æ‰§è¡Œï¼Œä¹Ÿåº”é™ä½ confidence è‡³ â‰¤0.4ã€‚\n"
        "**å¯æ‰§è¡Œæ€§åˆ¤æ–­æ ‡å‡†**ï¼š\n"
        "- âœ… å¯æ‰§è¡Œï¼ˆconfidence â‰¥0.6ï¼‰ï¼šæ˜ç¡®çš„ä¹°å…¥/å–å‡ºæ ‡çš„ + æ—¶é—´çª—å£ + å…·ä½“ä»·æ ¼/æ•°æ®æ”¯æ’‘\n"
        "- âš ï¸ éƒ¨åˆ†å¯æ‰§è¡Œï¼ˆconfidence 0.4-0.6ï¼‰ï¼šæœ‰äº¤æ˜“æ–¹å‘ä½†ç¼ºå°‘æ—¶é—´èŠ‚ç‚¹ï¼Œæˆ–æœ‰æ•°æ®ä½†ç¼ºå°‘æ˜ç¡®æ ‡çš„\n"
        "- âŒ ä¸å¯æ‰§è¡Œï¼ˆconfidence â‰¤0.4ï¼‰ï¼šçº¯ç»Ÿè®¡æ•°å­—ã€ç¬¼ç»Ÿè¶‹åŠ¿ã€æƒ…ç»ªè§‚å¯Ÿã€æ— å…·ä½“æ ‡çš„æˆ–æ—¶é—´\n"
        "**ç‰¹åˆ«æ³¨æ„**ï¼šæ¶‰åŠä¸»æµå¸ï¼ˆBTC/ETH/SOLï¼‰ä»·æ ¼å˜åŒ–çš„æ¶ˆæ¯ï¼Œé»˜è®¤å…·æœ‰æ›´é«˜æ‰§è¡Œä»·å€¼ï¼Œconfidence åº”é€‚å½“æå‡ï¼ˆ+0.15 åˆ° +0.25ï¼‰ã€‚\n"
        "\n## æ—¶é—´èŒƒå›´ï¼ˆtimeframeï¼‰\n"
        "timeframe è¡¨ç¤ºå»ºè®®æŒä»“æ—¶é—´æˆ–å½±å“å‘¨æœŸï¼š\n"
        "- shortï¼ˆçŸ­æœŸï¼Œ<1å‘¨ï¼‰ï¼šé“¾ä¸Šæ•°æ®çªå˜ã€å·¨é²¸çŸ­æœŸæ“ä½œã€çŸ­æœŸäº‹ä»¶å‚¬åŒ–ï¼ˆå¦‚ç©ºæŠ•ã€IDOï¼‰ã€æŠ€æœ¯é¢ä¿¡å·ç­‰éœ€å¿«é€Ÿååº”çš„æœºä¼š\n"
        "- mediumï¼ˆä¸­æœŸï¼Œ1å‘¨-1æœˆï¼‰ï¼šäº§å“ä¸Šçº¿ã€åˆä½œå…¬å‘Šã€å­£åº¦è´¢æŠ¥ã€ä¸­çŸ­æœŸå™äº‹ï¼ˆå¦‚æŸèµ›é“çƒ­ç‚¹ï¼‰\n"
        "- longï¼ˆé•¿æœŸï¼Œ>1æœˆï¼‰ï¼šç›‘ç®¡æ”¿ç­–ã€å®è§‚é‡‡ç”¨ç‡æå‡ã€åŸºç¡€è®¾æ–½å»ºè®¾ã€é•¿æœŸå™äº‹ï¼ˆå¦‚æœºæ„å…¥åœºã€ETF å‡€æµå…¥æŒç»­ï¼‰\n"
        "æ ¹æ®äº‹ä»¶æ€§è´¨åˆ¤æ–­å½±å“æŒç»­æ—¶é—´ï¼Œä¾‹å¦‚ï¼šæœºæ„é‡‡ç”¨ç‡æå‡â†’longï¼›äº¤æ˜“æ‰€ä¸Šçº¿â†’mediumï¼›å·¨é²¸ 24h å†…ä¹°å…¥â†’shortã€‚\n"
        "\n## é£é™©æ ‡å¿—ï¼ˆrisk_flagsï¼‰\n"
        "risk_flags æ•°ç»„ä»…å…è®¸ price_volatilityã€liquidity_riskã€regulation_riskã€confidence_lowã€data_incompleteã€vague_timelineã€speculativeã€unverifiableã€‚\n"
        "ä»…åœ¨å®é™…è§¦å‘æ—¶æ·»åŠ æ ‡å¿—ï¼Œé¿å…å †ç Œï¼›å½“ confidence <0.4 æˆ–ç¼ºå°‘å…³é”®æ•°æ®ï¼Œå¯åŠ å…¥ confidence_low æˆ– data_incompleteã€‚\n"
        "å½“ç¨³å®šå¸æˆ–åŒ…è£¹èµ„äº§ï¼ˆå¦‚ USDEã€WBETHã€WBTCã€WBSOL ç­‰ï¼‰å‡ºç°è„±é”šã€æš´è·Œã€æŠ˜ä»·ã€æ¸…ç®—æˆ–å¼ºåˆ¶å¹³ä»“é£é™©æ—¶ï¼Œå¿…é¡»è¿”å› action=sellã€direction=shortï¼Œconfidence â‰¥0.8ï¼Œå¹¶åœ¨ notes è¯´æ˜è§¦å‘åŸå› ä¸æ ¸å¿ƒæ•°æ®ã€‚\n"
        "è‹¥æ–‡æœ¬åŒ…å«â€œè„±é”šã€depegã€æš´è·Œã€å¤§å¹…ä¸‹è·Œã€è·Œè‡³ã€ä½äºã€æ¸…ç®—ã€å¼ºåˆ¶å¹³ä»“â€ç­‰è¯æ±‡ä¸”ä¼´éšç™¾åˆ†æ¯”æˆ–ä»·æ ¼å˜åŠ¨ï¼Œè¯·è§†ä¸ºæç«¯è¡Œæƒ…ï¼Œé‡ç‚¹æè¿°è·Œå¹…ã€ä»·æ ¼åŒºé—´ï¼Œå¹¶ç›¸åº”æå‡ confidenceã€‚\n"
        "å¯¹äºæç«¯è¡Œæƒ…ï¼Œè¯·åœ¨ risk_flags ä¸­è‡³å°‘åŠ å…¥ price_volatilityï¼›å¦‚æ•°æ®æ¥æºæˆ–é“¾ä¸Šç»†èŠ‚ç¼ºå¤±ï¼Œé¢å¤–æ ‡è®° data_incompleteã€‚\n"
        "\n## ä¿¡å·åˆ¤æ–­è§„åˆ™\n"
        "1. æ—¶é—´æ¨¡ç³Šï¼ˆ\"è¿‘æœŸ\"ã€\"soon\" ç­‰ï¼‰â†’ æ·»åŠ  vague_timelineï¼Œå¹¶é™ä½ confidenceã€‚\n"
        "2. å†…å®¹ç¬¼ç»Ÿã€ç¼ºä¹æŒ‡æ ‡æˆ–åªæ˜¯æƒ…ç»ªè¡¨è¿° â†’ æ·»åŠ  speculativeï¼Œå¹¶å°† action è®¾ä¸º observe æˆ– confidence â‰¤0.5ã€‚\n"
        "3. æ¥æºæ— æ³•éªŒè¯æˆ–ä¸ºä¼ é—» â†’ æ·»åŠ  unverifiableï¼Œå¹¶å°† action=observeã€‚\n"
        "4. ä»…å½“äº‹ä»¶ç›´æ¥æ¶‰åŠåŠ å¯†èµ„äº§ï¼ˆ2-10 ä½å¤§å†™/æ•°å­—ï¼‰æ‰å¡«å†™ assetï¼›è‚¡ç¥¨ã€æŒ‡æ•°ã€ETF ç­‰éåŠ å¯†æ ‡çš„å¿…é¡»è¿”å› NONEã€‚\n"
        "5. è‹¥æä¾›é“¾ä¸Šæ•°æ®ã€æˆäº¤é‡ã€èµ„é‡‘æµç­‰å®¢è§‚æŒ‡æ ‡ï¼Œå¯æ®æ­¤æé«˜ confidenceï¼Œå¹¶åœ¨ notes æ¦‚è¿°å…³é”®æ•°å­—ã€‚\n"
        "6. Meme å¸çˆ†æ–™ã€è¥é”€æ–‡æ¡ˆæˆ–æ´»åŠ¨é¢„å‘Šè‹¥ç¼ºå°‘å¯æ‰§è¡Œç»†èŠ‚ï¼Œåº”è¾“å‡º event_type=scam_alert æˆ– otherï¼Œaction=observeï¼Œconfidence â‰¤0.4ï¼Œå¹¶è¯´æ˜é£é™©ã€‚\n"
        "7. äº¤æ˜“æ‰€/è¡ç”Ÿå“ä¸Šçº¿ä»…å…¬å‘Šè€Œæ— æˆäº¤ã€èµ„é‡‘è´¹ç‡ã€æµåŠ¨æ€§æŒ‡æ ‡æ—¶ï¼Œaction=observeã€direction=neutralï¼Œconfidence â‰¤0.5ï¼Œå¿…è¦æ—¶æ ‡è®° speculative æˆ– data_incompleteã€‚\n"
        "8. **å®è§‚ç»Ÿè®¡æ•°æ®ï¼ˆevent_type=macroï¼‰ä¸¥æ ¼é™åˆ¶**ï¼š\n"
        '   - ä»…ç»Ÿè®¡æ•°å­—ï¼ˆå¦‚"æ€»ä¾›åº”é‡åˆ›æ–°é«˜"ã€"å¸‚å€¼çªç ´XX"ã€"æ•´ä½“å¢é•¿XX%"ï¼‰è€Œæ— å…·ä½“äº¤æ˜“æœºä¼š â†’ confidence â‰¤0.4ï¼Œæ·»åŠ  data_incomplete æˆ– speculative\n'
        "   - ç¨³å®šå¸æ€»ä¾›åº”é‡/æ€»å¸‚å€¼ç±»æ¶ˆæ¯ï¼Œé™¤éæ˜ç¡®è¯´æ˜èµ„é‡‘æµå…¥å…·ä½“é“¾ï¼ˆETH/SOLï¼‰ã€åè®®ï¼ˆAave/Curveï¼‰æˆ–é…åˆé“¾ä¸Šæ•°æ®ï¼ˆDEXäº¤æ˜“é‡æ¿€å¢ï¼‰ï¼Œå¦åˆ™ confidence â‰¤0.4\n"
        "   - æœºæ„é‡‡ç”¨ã€DeFièƒ½åŠ›ã€é•¿æœŸè¶‹åŠ¿ç­‰ç¬¼ç»Ÿè§‚å¯Ÿï¼Œæ— æ—¶é—´èŠ‚ç‚¹å’Œå¯æ‰§è¡Œæ ‡çš„ â†’ action=observeï¼Œconfidence â‰¤0.5ï¼Œæ·»åŠ  vague_timeline\n"
        '   - event_type=macro + action=observe ç»„åˆæ—¶ï¼Œå¿…é¡»æœ‰æ˜ç¡®äº¤æ˜“å‚¬åŒ–å‰‚ï¼ˆå¦‚"Xæœºæ„å®£å¸ƒæœ¬å‘¨ä¹°å…¥Yäº¿ç¾å…ƒBTC"ï¼‰æ‰èƒ½ confidence >0.6\n'
        "9. **ä½å¸‚å€¼ä»£å¸é£é™©æ§åˆ¶**ï¼š\n"
        "   - å¸‚å€¼ < 5000ä¸‡ç¾å…ƒçš„ä»£å¸ï¼Œé»˜è®¤è§†ä¸ºé«˜é£é™©æŠ•æœºæ ‡çš„ â†’ confidence è‡ªåŠ¨ -0.15 åˆ° -0.25\n"
        "   - å¸‚å€¼ < 1000ä¸‡ç¾å…ƒçš„ä»£å¸ï¼Œæé«˜é£é™© â†’ confidence è‡ªåŠ¨ -0.25 åˆ° -0.35ï¼Œå¿…é¡»æ·»åŠ  liquidity_risk\n"
        "   - æœªä¸Šçº¿ä¸»æµäº¤æ˜“æ‰€ï¼ˆä»…åœ¨ DEX æˆ–å°å‹ CEXï¼‰çš„ä»£å¸ â†’ confidence é™ä½ 0.1-0.2ï¼Œæ·»åŠ  liquidity_risk\n"
        "   - ä½å¸‚å€¼ + æ— æ˜ç¡®å‚¬åŒ–å‰‚ï¼ˆå¦‚ä»…ç©ºæŠ•ã€ä»…ä¸Šçº¿å°äº¤æ˜“æ‰€ï¼‰ â†’ confidence â‰¤0.4ï¼Œaction=observe\n"
        "10. **Binance Alpha ç‰¹æ®Šå¤„ç†**ï¼š\n"
        "   - Binance Alpha å¹³å°ä¸Šçº¿çš„ä»£å¸é€šå¸¸å¸‚å€¼è¾ƒå°ã€æŠ•æœºæ€§å¼º â†’ è‡ªåŠ¨é™ä½ confidence 0.2-0.3\n"
        "   - Binance Alpha ç©ºæŠ•æ´»åŠ¨ï¼Œé™¤éæœ‰æ˜ç¡®çš„äº¤æ˜“æœºä¼šå’Œæ—¶é—´èŠ‚ç‚¹ â†’ action=observeï¼Œconfidence â‰¤0.5\n"
        "   - å¯¹äº Binance Alpha æ¶ˆæ¯ï¼Œå¿…é¡»åœ¨ summary ä¸­æ˜ç¡®æ ‡æ³¨ 'å¸‚å€¼è¾ƒå°' æˆ– 'æŠ•æœºæ€§å¼º' ç­‰é£é™©æç¤º\n"
        "11. **ç¨³å®šå¸ä¸å¯äº¤æ˜“åŸåˆ™**ï¼š\n"
        "   - USDCã€USDTã€DAIã€BUSDã€TUSDã€USDPã€GUSDã€FRAXã€LUSDã€USDD ç­‰ç¨³å®šå¸è®¾è®¡ç›®æ ‡ä¸ºä¿æŒ 1 ç¾å…ƒä»·æ ¼ï¼Œä¸å­˜åœ¨ä»·æ ¼æ³¢åŠ¨äº¤æ˜“æœºä¼š\n"
        "   - æ¶‰åŠç¨³å®šå¸çš„åŸºç¡€è®¾æ–½ã€ä¾›åº”é‡ã€å¸‚å€¼ç­‰æ¶ˆæ¯ â†’ asset=NONEï¼Œaction=observeï¼Œconfidence â‰¤0.4\n"
        "   - **ç¤ºä¾‹**ï¼š\"Circle è·å¾—ç¾è”å‚¨æ”¯ä»˜é€šé“ï¼ŒUSDC å¸‚åœºåœ°ä½æå‡\" â†’ asset=NONEï¼Œnotes è¯´æ˜ \"USDC æ˜¯ç¨³å®šå¸ä¸å¯äº¤æ˜“ï¼Œè‹¥æƒ³å—ç›Šåº”å…³æ³¨ä½¿ç”¨ USDC çš„ DeFi åè®®æˆ–æ”¯ä»˜ç±»ä»£å¸\"\n"
        "   - **ä¾‹å¤–æƒ…å†µ**ï¼šä»…å½“ç¨³å®šå¸å‡ºç°æ˜ç¡®è„±é”šé£é™©ï¼ˆä»·æ ¼åç¦» >5%ã€depegã€æš´è·Œç­‰ï¼‰ â†’ action=sellã€direction=shortï¼Œconfidence â‰¥0.8\n"
        "   - å¯¹äºç¨³å®šå¸ç›¸å…³åˆ©å¥½æ¶ˆæ¯ï¼Œåº”åœ¨ notes ä¸­å»ºè®®å…³æ³¨å—ç›Šçš„ DeFi åè®®ï¼ˆAaveã€Curveã€Uniswap ç­‰ï¼‰æˆ–å…¶åŸç”Ÿä»£å¸ï¼Œè€Œéç¨³å®šå¸æœ¬èº«\n"
        "\n## å†å²å‚è€ƒ\n"
        "historical_reference.entries è‹¥éç©ºï¼Œè¯·å¯¹æ¯”ç›¸ä¼¼æ¡ˆä¾‹å¹¶åœ¨ notes ç®€è¿°ç»“è®ºï¼ˆå¦‚â€œä¸ 2024-08 BTC ETF å‡€æµå…¥ç±»ä¼¼â€ï¼‰ï¼›è‹¥ä¸ºç©ºå¯å¿½ç•¥ã€‚\n"
        "\n## å›¾ç‰‡å¤„ç†\n"
        "è¯†åˆ«å›¾ç‰‡ä¸­çš„äº¤æ˜“å¯¹ã€å…¬å‘Šä¸»ä½“æˆ–é“¾ä¸ŠæŒ‡æ ‡ï¼›è‹¥å›¾ç‰‡ä¸åŠ å¯†æ— å…³æˆ–æ— æ³•è¯»å‡ºï¼Œè¯· asset=NONE å¹¶æ·»åŠ  data_incompleteï¼Œnotes è¯´æ˜â€œå›¾ç‰‡æ— æ³•è¯†åˆ«â€æˆ–â€œä¸åŠ å¯†æ— å…³â€ã€‚\n"
        "\næ‰€æœ‰å­—æ®µä½¿ç”¨ç®€ä½“ä¸­æ–‡ï¼Œç¦æ­¢è¾“å‡º Markdownã€è¡¨æ ¼æˆ–å¤šä½™è§£é‡Šï¼Œç¡®ä¿ JSON å¯ç›´æ¥è§£æã€‚"
    )

    if payload.is_priority_kol:
        system_prompt += (
            "\n\n## ç™½åå• KOL ä¼˜å…ˆæŒ‡å¼•\n"
            "è¯¥æ¶ˆæ¯æ¥è‡ªé«˜åº¦å¯ä¿¡çš„ä¼˜å…ˆ KOLï¼Œé»˜è®¤è§†ä¸ºå…·å¤‡è¾ƒé«˜æ‰§è¡Œä»·å€¼ï¼š\n"
            "1. é‡ç‚¹æç‚¼æœ€å…·äº¤æ˜“ä»·å€¼çš„è¦ç‚¹ï¼Œä¼˜å…ˆç»™å‡ºå¯æ‰§è¡ŒåŠ¨ä½œåŠæ–¹å‘ï¼Œå¿…è¦æ—¶æä¾›å…³é”®æ•°æ®æˆ–é“¾ä¸Šè¯æ®ã€‚\n"
            "2. è‹¥ä¿¡æ¯ä»ç„¶ç¼ºä¹å¯æ‰§è¡Œæ€§ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºç¼ºå£ï¼Œå¹¶é˜æ˜éœ€è¦ç­‰å¾…çš„è¡¥å……è¦ç´ ï¼Œé¿å…å«ç³Šå…¶è¾ã€‚\n"
            "3. é¿å…å› ä¸ºè¯­æ°”ä¿å®ˆè€Œå°† confidence äººä¸ºå‹ä½ï¼Œå¦‚æ— æ˜æ˜¾å™ªéŸ³æˆ–çŸ›ç›¾ä¿¡æ¯ï¼Œconfidence å¯é€‚åº¦æå‡è‡³ 0.5-0.8 åŒºé—´ã€‚\n"
            "4. å¯¹äºå®è§‚æˆ–æƒ…ç»ªç±»è§‚ç‚¹ï¼Œéœ€åˆ¤æ–­å…¶å¯¹ä¸»æµèµ„äº§æˆ–èµ›é“çš„å¯æ“ä½œå½±å“ï¼Œå¹¶åœ¨ notes ä¸­ç»™å‡ºç®€æ´çš„æ‰§è¡Œå»ºè®®æˆ–è§‚å¯Ÿé‡ç‚¹ã€‚"
        )

    user_prompt = (
        "è¯·ç»“åˆä»¥ä¸‹äº‹ä»¶ä¸Šä¸‹æ–‡ç»™å‡ºæœ€å…·æ“ä½œæ€§çš„å»ºè®®ï¼Œè‹¥åŒ…å«å¤šæ¡ä¿¡æ¯éœ€ç»¼åˆåˆ¤æ–­ï¼š\n"
        f"```json\n{context_json}\n```\n"
        "è¿”å›ä»…åŒ…å«ä¸Šè¿°å­—æ®µçš„ JSON å­—ç¬¦ä¸²ï¼Œç¦æ­¢å‡ºç°é¢å¤–æ–‡æœ¬ï¼›å¤šèµ„äº§è¯·ä½¿ç”¨ asset æ•°ç»„ï¼Œnotes ç®€æ´è¯´æ˜å…³é”®è¦ç‚¹æˆ–é£é™©ã€‚"
    )

    return [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt},
    ]
