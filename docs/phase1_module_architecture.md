# Phase 1 æ¨¡å—åŒ–æ¶æ„è®¾è®¡

**æ—¥æœŸ**: 2025-10-11
**é—®é¢˜**: LangGraph èŠ‚ç‚¹æ–¹æ³•ä»£ç é‡å¤§ï¼ˆ573è¡Œï¼‰ï¼Œæ˜¯å¦éœ€è¦æ‹†åˆ†æ¨¡å—ï¼Ÿ
**ç»“è®º**: âœ… **å»ºè®®æ‹†åˆ†** - æé«˜å¯ç»´æŠ¤æ€§å’Œå¯æµ‹è¯•æ€§

---

## ğŸ¤” ä¸ºä»€ä¹ˆéœ€è¦æ‹†åˆ†ï¼Ÿ

### å½“å‰é—®é¢˜

1. **gemini.py æ–‡ä»¶è¿‡å¤§**:
   - ç°æœ‰ä»£ç : ~271 è¡Œ
   - LangGraph èŠ‚ç‚¹: +573 è¡Œ
   - **æ€»è®¡**: ~844 è¡Œï¼ˆå•ä¸ªç±»ï¼‰

2. **èŒè´£æ··æ‚**:
   - Function Calling æ·±åº¦åˆ†æï¼ˆç°æœ‰ï¼‰
   - LangGraph å·¥å…·ç¼–æ’ï¼ˆæ–°å¢ï¼‰
   - è®°å¿†æ£€ç´¢é€»è¾‘
   - Prompt æ„å»º
   - å·¥å…·æ‰§è¡Œ

3. **æµ‹è¯•å›°éš¾**:
   - èŠ‚ç‚¹æ–¹æ³•éš¾ä»¥ç‹¬ç«‹æµ‹è¯•
   - Mock ä¾èµ–å¤æ‚

4. **å¯è¯»æ€§ä¸‹é™**:
   - ç±»å®šä¹‰è¿‡é•¿
   - é€»è¾‘è·³è·ƒé¢‘ç¹

---

## âœ… æ¨èæ–¹æ¡ˆï¼šæ¨¡å—åŒ–æ‹†åˆ†

### æ¶æ„è®¾è®¡

```
src/ai/deep_analysis/
â”œâ”€â”€ gemini.py                    # ä¸»å¼•æ“ï¼ˆä¿æŒç®€æ´ï¼‰
â”œâ”€â”€ base.py                      # ç°æœ‰åŸºç±»
â”œâ”€â”€ factory.py                   # ç°æœ‰å·¥å‚
â”œâ”€â”€ nodes/                       # ğŸ†• LangGraph èŠ‚ç‚¹æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                  # èŠ‚ç‚¹åŸºç±»
â”‚   â”œâ”€â”€ context_gather.py        # Context Gather èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tool_planner.py          # Tool Planner èŠ‚ç‚¹
â”‚   â”œâ”€â”€ tool_executor.py         # Tool Executor èŠ‚ç‚¹
â”‚   â””â”€â”€ synthesis.py             # Synthesis èŠ‚ç‚¹
â”œâ”€â”€ helpers/                     # ğŸ†• è¾…åŠ©æ–¹æ³•æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ memory.py                # è®°å¿†æ£€ç´¢é€»è¾‘
â”‚   â”œâ”€â”€ prompts.py               # Prompt æ„å»º
â”‚   â””â”€â”€ formatters.py            # æ ¼å¼åŒ–å·¥å…·
â””â”€â”€ graph.py                     # ğŸ†• LangGraph å›¾æ„å»º
```

### ä¼˜åŠ¿

âœ… **èŒè´£åˆ†ç¦»**: æ¯ä¸ªæ¨¡å—èŒè´£å•ä¸€
âœ… **å¯æµ‹è¯•æ€§**: èŠ‚ç‚¹å¯ç‹¬ç«‹æµ‹è¯•
âœ… **å¯ç»´æŠ¤æ€§**: ä¿®æ”¹æŸä¸ªèŠ‚ç‚¹ä¸å½±å“å…¶ä»–éƒ¨åˆ†
âœ… **å¯å¤ç”¨æ€§**: Helper æ–¹æ³•å¯åœ¨å¤šå¤„å¤ç”¨
âœ… **å¯æ‰©å±•æ€§**: æ·»åŠ æ–°èŠ‚ç‚¹ï¼ˆPhase 2ï¼‰æ›´å®¹æ˜“

---

## ğŸ“¦ è¯¦ç»†æ¨¡å—è®¾è®¡

### 1. `src/ai/deep_analysis/nodes/base.py`

**èŒè´£**: èŠ‚ç‚¹åŸºç±»ï¼Œå®šä¹‰é€šç”¨æ¥å£

```python
"""Base class for LangGraph nodes."""

from abc import ABC, abstractmethod
from typing import Any, Dict


class BaseNode(ABC):
    """Abstract base class for LangGraph nodes."""

    def __init__(self, engine):
        """
        Args:
            engine: GeminiDeepAnalysisEngine instance for accessing shared resources
        """
        self._engine = engine
        self._client = engine._client
        self._memory = engine._memory
        self._config = engine._config

    @abstractmethod
    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Execute node logic and return state updates."""
        pass
```

---

### 2. `src/ai/deep_analysis/nodes/context_gather.py`

**èŒè´£**: è®°å¿†æ”¶é›†èŠ‚ç‚¹ï¼ˆ~50 è¡Œï¼‰

```python
"""Context Gather node for retrieving historical memory."""

import logging
from typing import Any, Dict

from .base import BaseNode
from ..helpers.memory import fetch_memory_entries, format_memory_evidence

logger = logging.getLogger(__name__)


class ContextGatherNode(BaseNode):
    """Node for gathering historical memory context."""

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Gather memory context from historical events."""
        logger.info("ğŸ§  Context Gather: è·å–å†å²è®°å¿†")

        entries = await fetch_memory_entries(
            engine=self._engine,
            payload=state["payload"],
            preliminary=state["preliminary"],
        )

        memory_text = format_memory_evidence(entries)
        logger.info("ğŸ§  Context Gather: æ‰¾åˆ° %d æ¡å†å²äº‹ä»¶", len(entries))

        return {
            "memory_evidence": {
                "entries": entries,
                "formatted": memory_text,
                "count": len(entries),
            }
        }
```

---

### 3. `src/ai/deep_analysis/nodes/tool_planner.py`

**èŒè´£**: AI å·¥å…·å†³ç­– + å…³é”®è¯ç”Ÿæˆï¼ˆ~120 è¡Œï¼‰

```python
"""Tool Planner node for deciding which tools to call."""

import logging
from typing import Any, Dict

from .base import BaseNode
from ..helpers.prompts import build_planner_prompt

logger = logging.getLogger(__name__)

# Event type filters
NEVER_SEARCH_EVENT_TYPES = {"macro", "governance", "airdrop", "celebrity"}
FORCE_SEARCH_EVENT_TYPES = {"hack", "regulation", "partnership"}


class ToolPlannerNode(BaseNode):
    """Node for AI-powered tool planning and keyword generation."""

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Decide which tools to call and generate search keywords."""
        logger.info("ğŸ¤– Tool Planner: å†³ç­–ä¸‹ä¸€æ­¥å·¥å…·")

        preliminary = state["preliminary"]

        # Blacklist check
        if preliminary.event_type in NEVER_SEARCH_EVENT_TYPES:
            logger.info("ğŸ¤– Tool Planner: äº‹ä»¶ç±»å‹ '%s' åœ¨é»‘åå•", preliminary.event_type)
            return {"next_tools": []}

        # Whitelist check (first turn only)
        if preliminary.event_type in FORCE_SEARCH_EVENT_TYPES and state["tool_call_count"] == 0:
            logger.info("ğŸ¤– Tool Planner: äº‹ä»¶ç±»å‹ '%s' åœ¨ç™½åå•ï¼Œå¼ºåˆ¶æœç´¢", preliminary.event_type)
            keyword = await self._generate_keywords_ai(state)
            return {"next_tools": ["search"], "search_keywords": keyword}

        # Already have search results
        if state.get("search_evidence"):
            logger.info("ğŸ¤– Tool Planner: å·²æœ‰æœç´¢ç»“æœ")
            return {"next_tools": []}

        # AI decision using Function Calling
        return await self._decide_with_function_calling(state)

    async def _decide_with_function_calling(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Use Gemini Function Calling for structured decision."""
        prompt = build_planner_prompt(state, self._engine)

        tool_definition = {
            "name": "decide_next_tools",
            "description": "æ ¹æ®å·²æœ‰è¯æ®å†³å®šä¸‹ä¸€æ­¥éœ€è¦è°ƒç”¨çš„å·¥å…·ï¼Œå¹¶ä¸ºæœç´¢ç”Ÿæˆæœ€ä¼˜å…³é”®è¯",
            "parameters": {
                "type": "OBJECT",
                "properties": {
                    "tools": {
                        "type": "ARRAY",
                        "items": {"type": "STRING"},
                        "description": "éœ€è¦è°ƒç”¨çš„å·¥å…·åˆ—è¡¨,å¯é€‰å€¼: search",
                    },
                    "search_keywords": {
                        "type": "STRING",
                        "description": "æœç´¢å…³é”®è¯ï¼ˆä¸­è‹±æ–‡æ··åˆï¼‰",
                    },
                    "reason": {"type": "STRING", "description": "å†³ç­–ç†ç”±"},
                },
                "required": ["tools", "reason"],
            },
        }

        try:
            response = await self._client.generate_content_with_tools(
                messages=[{"role": "user", "content": prompt}],
                tools=[tool_definition],
            )

            if response and response.function_calls:
                decision = response.function_calls[0].args
                tools = decision.get("tools", [])
                keywords = decision.get("search_keywords", "")
                reason = decision.get("reason", "")

                logger.info(
                    "ğŸ¤– Tool Planner å†³ç­–: tools=%s, keywords='%s', ç†ç”±: %s",
                    tools,
                    keywords,
                    reason,
                )

                return {"next_tools": tools, "search_keywords": keywords}

            logger.warning("Tool Planner æœªè¿”å›å·¥å…·è°ƒç”¨")
            return {"next_tools": []}

        except Exception as exc:
            logger.error("Tool Planner æ‰§è¡Œå¤±è´¥: %s", exc)
            return {"next_tools": []}

    async def _generate_keywords_ai(self, state: Dict[str, Any]) -> str:
        """Generate keywords using AI for whitelist events."""
        # ... (keyword generation logic)
        pass
```

---

### 4. `src/ai/deep_analysis/nodes/tool_executor.py`

**èŒè´£**: å·¥å…·æ‰§è¡Œ + é…é¢æ£€æŸ¥ï¼ˆ~80 è¡Œï¼‰

```python
"""Tool Executor node for executing planned tools."""

import logging
from typing import Any, Dict, Optional

from .base import BaseNode

logger = logging.getLogger(__name__)


class ToolExecutorNode(BaseNode):
    """Node for executing tools decided by planner."""

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Execute planned tools with quota checking."""
        tools_to_call = state.get("next_tools", [])
        logger.info("ğŸ”§ Tool Executor: è°ƒç”¨å·¥å…·: %s", tools_to_call)

        # Check daily quota
        if not self._check_quota():
            logger.warning("âš ï¸ è¶…å‡ºæ¯æ—¥é…é¢")
            return {"tool_call_count": state["tool_call_count"] + 1}

        updates = {"tool_call_count": state["tool_call_count"] + 1}

        for tool_name in tools_to_call:
            if tool_name == "search":
                result = await self._execute_search(state)
                if result:
                    updates["search_evidence"] = result
            else:
                logger.warning("æœªçŸ¥å·¥å…·: %s", tool_name)

        return updates

    async def _execute_search(self, state: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Execute search tool with domain whitelisting."""
        if not self._engine._search_tool:
            logger.warning("æœç´¢å·¥å…·æœªåˆå§‹åŒ–")
            return None

        preliminary = state["preliminary"]
        keyword = state.get("search_keywords", "").strip()

        # Fallback to hardcoded keywords
        if not keyword:
            keyword = f"{preliminary.asset} {preliminary.event_type}"
            logger.info("ä½¿ç”¨ç¡¬ç¼–ç å…³é”®è¯: '%s'", keyword)
        else:
            logger.info("ä½¿ç”¨ AI ç”Ÿæˆå…³é”®è¯: '%s'", keyword)

        # Get domain whitelist
        include_domains = None
        if hasattr(self._config, "HIGH_PRIORITY_EVENT_DOMAINS"):
            include_domains = self._config.HIGH_PRIORITY_EVENT_DOMAINS.get(
                preliminary.event_type
            )

        try:
            result = await self._engine._search_tool.fetch(
                keyword=keyword,
                max_results=5,
                include_domains=include_domains,
            )

            if result.success:
                logger.info(
                    "ğŸ”§ æœç´¢è¿”å› %d æ¡ç»“æœ (multi_source=%s)",
                    result.data.get("source_count", 0),
                    result.data.get("multi_source"),
                )
                return {
                    "success": True,
                    "data": result.data,
                    "triggered": result.triggered,
                    "confidence": result.confidence,
                }

            logger.warning("æœç´¢å¤±è´¥: %s", result.error)
            return None

        except Exception as exc:
            logger.error("æœç´¢å·¥å…·å¼‚å¸¸: %s", exc)
            return None

    def _check_quota(self) -> bool:
        """Check if daily quota is exceeded."""
        from datetime import datetime, timezone

        today = datetime.now(timezone.utc).date()

        if today != self._engine._tool_call_reset_date:
            self._engine._tool_call_count_today = 0
            self._engine._tool_call_reset_date = today

        if self._engine._tool_call_count_today >= self._engine._tool_call_daily_limit:
            return False

        self._engine._tool_call_count_today += 1
        return True
```

---

### 5. `src/ai/deep_analysis/nodes/synthesis.py`

**èŒè´£**: è¯æ®ç»¼åˆï¼ˆ~60 è¡Œï¼‰

```python
"""Synthesis node for generating final signal."""

import json
import logging
from typing import Any, Dict

from .base import BaseNode
from ..helpers.prompts import build_synthesis_prompt

logger = logging.getLogger(__name__)


class SynthesisNode(BaseNode):
    """Node for synthesizing all evidence into final signal."""

    async def execute(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Synthesize evidence and generate final signal."""
        logger.info("ğŸ“Š Synthesis: ç”Ÿæˆæœ€ç»ˆåˆ†æ")

        prompt = build_synthesis_prompt(state, self._engine)
        final_json = await self._invoke_text_model(prompt)

        try:
            parsed = json.loads(final_json)
            final_conf = parsed.get("confidence", 0.0)
            prelim_conf = state["preliminary"].confidence
            logger.info("ğŸ“Š Synthesis: æœ€ç»ˆç½®ä¿¡åº¦ %.2f (åˆæ­¥ %.2f)", final_conf, prelim_conf)
        except Exception:
            logger.warning("ğŸ“Š Synthesis: æ— æ³•è§£ææœ€ç»ˆ JSON")

        return {"final_response": final_json}

    async def _invoke_text_model(self, prompt: str) -> str:
        """Invoke Gemini for text generation."""
        messages = [{"role": "user", "content": prompt}]
        response = await self._client.generate_content_with_tools(messages, tools=None)

        if not response or not response.text:
            raise Exception("Gemini è¿”å›ç©ºå“åº”")

        return response.text.strip()
```

---

### 6. `src/ai/deep_analysis/helpers/memory.py`

**èŒè´£**: è®°å¿†æ£€ç´¢é€»è¾‘ï¼ˆ~80 è¡Œï¼‰

```python
"""Memory retrieval helpers."""

import inspect
import logging
from typing import Any, Dict, List

logger = logging.getLogger(__name__)


async def fetch_memory_entries(
    *,
    engine,
    payload: Any,
    preliminary: Any,
    limit: int = None,
) -> List[Dict[str, Any]]:
    """Independent memory retrieval helper.

    Reused in both:
    1. Context Gather node (LangGraph)
    2. _tool_fetch_memories (Function Calling)
    """
    if not engine._memory or not engine._memory.enabled:
        return []

    limit = limit or engine._memory_limit
    keywords = list(payload.keywords_hit or [])

    # Import helper functions
    from ...deep_analysis.gemini import _normalise_asset_codes, _memory_entries_to_prompt
    from src.memory.types import MemoryContext

    asset_codes = _normalise_asset_codes(preliminary.asset)

    repo = engine._memory.repository
    if repo is None:
        return []

    entries = []

    # Async repository
    if hasattr(repo, "fetch_memories") and inspect.iscoroutinefunction(repo.fetch_memories):
        kwargs = {"embedding": None, "asset_codes": asset_codes}
        parameters = inspect.signature(repo.fetch_memories).parameters
        if "keywords" in parameters:
            kwargs["keywords"] = keywords
        try:
            context = await repo.fetch_memories(**kwargs)
        except Exception as exc:
            logger.warning("è®°å¿†æ£€ç´¢å¤±è´¥: %s", exc)
            return []

        if isinstance(context, MemoryContext):
            entries = list(context.entries)
        else:
            entries = list(context) if context else []

    # Sync repository
    elif hasattr(repo, "load_entries"):
        try:
            entries = repo.load_entries(
                keywords=keywords,
                limit=limit,
                min_confidence=engine._memory_min_confidence,
            )
        except Exception as exc:
            logger.warning("æœ¬åœ°è®°å¿†æ£€ç´¢å¤±è´¥: %s", exc)
            return []

    prompt_entries = _memory_entries_to_prompt(entries)[:limit] if entries else []
    return prompt_entries


def format_memory_evidence(entries: List[Dict[str, Any]]) -> str:
    """Format memory entries for AI consumption."""
    if not entries:
        return "æ— å†å²ç›¸ä¼¼äº‹ä»¶"

    lines = []
    for i, entry in enumerate(entries, 1):
        confidence = entry.get("confidence", "N/A")
        similarity = entry.get("similarity", "N/A")
        summary = entry.get("summary", "N/A")
        lines.append(f"{i}. {summary} (ç½®ä¿¡åº¦: {confidence}, ç›¸ä¼¼åº¦: {similarity})")

    return "\n".join(lines)
```

---

### 7. `src/ai/deep_analysis/helpers/prompts.py`

**èŒè´£**: Prompt æ„å»ºï¼ˆ~200 è¡Œï¼‰

```python
"""Prompt builders for nodes."""

from typing import Any, Dict


def build_planner_prompt(state: Dict[str, Any], engine: Any) -> str:
    """Build prompt for Tool Planner node."""
    payload = state["payload"]
    preliminary = state["preliminary"]
    memory_ev = state.get("memory_evidence", {})
    search_ev = state.get("search_evidence", {})

    return f"""ä½ æ˜¯å·¥å…·è°ƒåº¦ä¸“å®¶,åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢æ–°é—»éªŒè¯,å¹¶ç”Ÿæˆæœ€ä¼˜æœç´¢å…³é”®è¯ã€‚

ã€æ¶ˆæ¯å†…å®¹ã€‘{payload.text}
ã€æ¶ˆæ¯è¯­è¨€ã€‘{getattr(payload, 'language', 'æœªçŸ¥')}
ã€äº‹ä»¶ç±»å‹ã€‘{preliminary.event_type}
ã€èµ„äº§ã€‘{preliminary.asset}
ã€åˆæ­¥ç½®ä¿¡åº¦ã€‘{preliminary.confidence}

ã€å·²æœ‰è¯æ®ã€‘
- å†å²è®°å¿†: {memory_ev.get('formatted', 'æ— ')}
- æœç´¢ç»“æœ: {_format_search_evidence(search_ev)}

ã€å†³ç­–è§„åˆ™ã€‘
0. âš ï¸ æˆæœ¬æ„è¯†ï¼šæ¯æ¬¡æœç´¢æ¶ˆè€—é…é¢ï¼Œè¯·è°¨æ…å†³ç­–
1. å¦‚æœå·²æœ‰æœç´¢ç»“æœä¸” multi_source=true â†’ è¯æ®å……åˆ†,æ— éœ€å†æœç´¢
2. å¦‚æœäº‹ä»¶ç±»å‹æ˜¯ hack/regulation/partnership â†’ éœ€è¦æœç´¢éªŒè¯
3. å¦‚æœ tool_call_count >= 2 â†’ è¯æ®å……åˆ†,æ— éœ€å†æœç´¢
4. å¦‚æœè®°å¿†ä¸­å·²æœ‰é«˜ç›¸ä¼¼åº¦æ¡ˆä¾‹ (similarity > 0.8) â†’ ä¼˜å…ˆä½¿ç”¨è®°å¿†ï¼Œå‡å°‘æœç´¢

ã€å…³é”®è¯ç”Ÿæˆè§„åˆ™ã€‘ï¼ˆä»…å½“å†³å®šæœç´¢æ—¶ï¼‰
1. **ä¸­è‹±æ–‡æ··åˆ**: å¦‚æœæ¶ˆæ¯æ˜¯ä¸­æ–‡,ç”Ÿæˆä¸­è‹±æ–‡æ··åˆå…³é”®è¯
2. **åŒ…å«å…³é”®å®ä½“**: æå–å…·ä½“å…¬å¸åã€åè®®åã€é‡‘é¢ç­‰
3. **å®˜æ–¹æ¥æºæ ‡è¯†**: æ·»åŠ  "official statement å®˜æ–¹å£°æ˜"
4. **äº‹ä»¶ç±»å‹å…³é”®è¯**:
   - hack â†’ "é»‘å®¢æ”»å‡» hack exploit breach"
   - regulation â†’ "ç›‘ç®¡æ”¿ç­– regulation SEC CFTC"
   - listing â†’ "ä¸Šçº¿ listing announce"
5. **é¿å…æ³›åŒ–è¯**: ä¸è¦ä½¿ç”¨ "æ–°é—»" "æ¶ˆæ¯" ç­‰

ã€å½“å‰çŠ¶æ€ã€‘
- å·²è°ƒç”¨å·¥å…·æ¬¡æ•°: {state['tool_call_count']}
- æœ€å¤§è°ƒç”¨æ¬¡æ•°: {state['max_tool_calls']}

è¯·è°ƒç”¨ decide_next_tools å‡½æ•°è¿”å›å†³ç­–å’Œå…³é”®è¯ã€‚"""


def build_synthesis_prompt(state: Dict[str, Any], engine: Any) -> str:
    """Build prompt for Synthesis node."""
    payload = state["payload"]
    preliminary = state["preliminary"]
    memory_ev = state.get("memory_evidence", {})
    search_ev = state.get("search_evidence", {})

    return f"""ä½ æ˜¯åŠ å¯†äº¤æ˜“å°èµ„æ·±åˆ†æå¸ˆ,å·²æŒæ¡å®Œæ•´è¯æ®,è¯·ç»™å‡ºæœ€ç»ˆåˆ¤æ–­ã€‚

ã€åŸå§‹æ¶ˆæ¯ã€‘
{payload.text}

ã€Gemini Flash åˆæ­¥åˆ¤æ–­ã€‘
- äº‹ä»¶ç±»å‹: {preliminary.event_type}
- èµ„äº§: {preliminary.asset}
- æ“ä½œ: {preliminary.action}
- ç½®ä¿¡åº¦: {preliminary.confidence}
- æ‘˜è¦: {preliminary.summary}

ã€å†å²è®°å¿†ã€‘
{memory_ev.get('formatted', 'æ— å†å²ç›¸ä¼¼äº‹ä»¶')}

ã€æœç´¢éªŒè¯ã€‘
{_format_search_detail(search_ev)}

ã€ç½®ä¿¡åº¦è°ƒæ•´è§„åˆ™ã€‘
- åŸºå‡†: Gemini Flash åˆåˆ¤ç½®ä¿¡åº¦ = {preliminary.confidence}
- æœç´¢å¤šæºç¡®è®¤ (multi_source=true) AND å®˜æ–¹ç¡®è®¤ (official_confirmed=true):
  â†’ æå‡ +0.15 to +0.20
- æœç´¢å¤šæºç¡®è®¤ä½†æ— å®˜æ–¹ç¡®è®¤:
  â†’ æå‡ +0.05 to +0.10
- æœç´¢ç»“æœ < 3 æ¡æˆ–æ— å®˜æ–¹ç¡®è®¤:
  â†’ é™ä½ -0.10 to -0.20
- å†å²è®°å¿†å­˜åœ¨é«˜ç›¸ä¼¼åº¦æ¡ˆä¾‹ (similarity > 0.8):
  â†’ å‚è€ƒå†å²æ¡ˆä¾‹æœ€ç»ˆç½®ä¿¡åº¦,è°ƒæ•´ Â±0.10

è¿”å› JSONï¼ˆä¸ SignalResult æ ¼å¼ä¸€è‡´ï¼‰:
{{
  "summary": "ä¸­æ–‡æ‘˜è¦",
  "event_type": "{preliminary.event_type}",
  "asset": "{preliminary.asset}",
  "action": "buy|sell|observe",
  "confidence": 0.0-1.0,
  "notes": "æ¨ç†ä¾æ®,å¼•ç”¨æœç´¢æ¥æºå’Œå…³é”®è¯æ®",
  "links": []
}}

åªè¿”å› JSON,ä¸è¦å…¶ä»–æ–‡å­—ã€‚"""


def _format_search_evidence(search_ev: Dict[str, Any]) -> str:
    """Format search evidence briefly."""
    if not search_ev:
        return "æ— "
    data = search_ev.get("data", {})
    return f"æ‰¾åˆ° {data.get('source_count', 0)} æ¡ç»“æœ, å¤šæºç¡®è®¤={data.get('multi_source', False)}"


def _format_search_detail(search_ev: Dict[str, Any]) -> str:
    """Format search evidence in detail."""
    if not search_ev or not search_ev.get("success"):
        return "æ— æœç´¢ç»“æœæˆ–æœç´¢å¤±è´¥"

    data = search_ev.get("data", {})
    results = data.get("results", [])

    lines = [
        f"å…³é”®è¯: {data.get('keyword', 'N/A')}",
        f"ç»“æœæ•°: {data.get('source_count', 0)}",
        f"å¤šæºç¡®è®¤: {data.get('multi_source', False)}",
        f"å®˜æ–¹ç¡®è®¤: {data.get('official_confirmed', False)}",
        "",
        "æœç´¢ç»“æœ:",
    ]

    for i, result in enumerate(results[:3], 1):
        lines.append(
            f"{i}. {result.get('title', 'N/A')} (æ¥æº: {result.get('source', 'N/A')}, è¯„åˆ†: {result.get('score', 0.0)})"
        )

    return "\n".join(lines)
```

---

### 8. `src/ai/deep_analysis/graph.py`

**èŒè´£**: LangGraph å›¾æ„å»ºï¼ˆ~50 è¡Œï¼‰

```python
"""LangGraph graph builder for tool-enhanced deep analysis."""

import logging
from langgraph.graph import END, StateGraph

from .nodes import ContextGatherNode, ToolPlannerNode, ToolExecutorNode, SynthesisNode

logger = logging.getLogger(__name__)


def build_deep_graph(engine):
    """Build LangGraph for tool-enhanced deep analysis.

    Args:
        engine: GeminiDeepAnalysisEngine instance

    Returns:
        Compiled LangGraph
    """
    from .gemini import DeepAnalysisState

    graph = StateGraph(DeepAnalysisState)

    # Create node instances
    context_node = ContextGatherNode(engine)
    planner_node = ToolPlannerNode(engine)
    executor_node = ToolExecutorNode(engine)
    synthesis_node = SynthesisNode(engine)

    # Add nodes
    graph.add_node("context_gather", context_node.execute)
    graph.add_node("planner", planner_node.execute)
    graph.add_node("executor", executor_node.execute)
    graph.add_node("synthesis", synthesis_node.execute)

    # Define edges
    graph.set_entry_point("context_gather")
    graph.add_edge("context_gather", "planner")

    # Conditional routing
    graph.add_conditional_edges(
        "planner",
        _route_after_planner,
        {"executor": "executor", "synthesis": "synthesis"},
    )

    graph.add_conditional_edges(
        "executor",
        _route_after_executor,
        {"planner": "planner", "synthesis": "synthesis"},
    )

    graph.add_edge("synthesis", END)

    return graph.compile()


def _route_after_planner(state):
    """Router after Tool Planner."""
    if not state.get("next_tools"):
        return "synthesis"
    return "executor"


def _route_after_executor(state):
    """Router after Tool Executor."""
    if state["tool_call_count"] >= state["max_tool_calls"]:
        logger.info("è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè¿›å…¥æœ€ç»ˆæ¨ç†")
        return "synthesis"
    return "planner"
```

---

### 9. `src/ai/deep_analysis/gemini.py` (ç®€åŒ–å)

**èŒè´£**: ä¸»å¼•æ“åè°ƒå™¨ï¼ˆ~150 è¡Œï¼‰

```python
"""Gemini deep analysis engine with tool-enhanced flow."""

# ... (existing imports)
from .graph import build_deep_graph

class GeminiDeepAnalysisEngine(DeepAnalysisEngine):
    """Execute deep analysis via Gemini with optional tool enhancement."""

    def __init__(self, ...):
        # ... (existing init)

        # Tool-enhanced flow setup
        self._config = config or SimpleNamespace()
        self._search_tool = None

        # Daily quota tracking
        self._tool_call_daily_limit = getattr(config, "DEEP_ANALYSIS_TOOL_DAILY_LIMIT", 50)
        self._tool_call_count_today = 0
        self._tool_call_reset_date = datetime.now(timezone.utc).date()

        # Initialize search tool
        if config and getattr(config, "TOOL_SEARCH_ENABLED", False):
            from src.ai.tools import SearchTool
            try:
                self._search_tool = SearchTool(config)
                logger.info("ğŸ” æœç´¢å·¥å…·å·²åˆå§‹åŒ–")
            except Exception as exc:
                logger.warning("âš ï¸ æœç´¢å·¥å…·åˆå§‹åŒ–å¤±è´¥: %s", exc)

    async def analyse(self, payload, preliminary):
        """Execute deep analysis with optional tool-enhanced flow."""
        tools_enabled = getattr(self._config, "DEEP_ANALYSIS_TOOLS_ENABLED", False)

        if not tools_enabled:
            logger.debug("å·¥å…·å¢å¼ºæµç¨‹æœªå¯ç”¨")
            return await self._analyse_with_function_calling(payload, preliminary)

        # Tool-enhanced flow with LangGraph
        max_calls = getattr(self._config, "DEEP_ANALYSIS_MAX_TOOL_CALLS", 3)

        try:
            logger.info("=== å¯åŠ¨ LangGraph å·¥å…·å¢å¼ºæ·±åº¦åˆ†æ ===")
            graph = build_deep_graph(self)  # Use external graph builder

            initial_state = DeepAnalysisState(
                payload=payload,
                preliminary=preliminary,
                search_evidence=None,
                memory_evidence=None,
                next_tools=[],
                search_keywords="",
                tool_call_count=0,
                max_tool_calls=max_calls,
                final_response="",
            )

            final_state = await graph.ainvoke(initial_state)
            final_payload = final_state.get("final_response")

            if not final_payload:
                raise DeepAnalysisError("LangGraph æœªè¿”å›æœ€ç»ˆç»“æœ")

            result = self._parse_json(final_payload)
            logger.info("=== LangGraph æ·±åº¦åˆ†æå®Œæˆ ===")
            return result

        except Exception as exc:
            logger.error("LangGraph å·¥å…·ç¼–æ’å¤±è´¥ï¼Œé™çº§: %s", exc, exc_info=True)
            return await self._analyse_with_function_calling(payload, preliminary)

    async def _analyse_with_function_calling(self, payload, preliminary):
        """Traditional Function Calling implementation (backward compatible)."""
        # ... (existing implementation)
        pass

    # ... (keep existing methods: _run_tool_loop, _dispatch_tool, _tool_fetch_memories, _build_tools)
```

---

## ğŸ“Š ä»£ç é‡å¯¹æ¯”

| æ–‡ä»¶ | è¡Œæ•° | èŒè´£ |
|------|------|------|
| **æ‹†åˆ†å‰** | | |
| gemini.py | ~844 | æ‰€æœ‰é€»è¾‘æ··æ‚ |
| **æ‹†åˆ†å** | | |
| gemini.py | ~150 | ä¸»å¼•æ“åè°ƒ |
| nodes/base.py | ~20 | èŠ‚ç‚¹åŸºç±» |
| nodes/context_gather.py | ~40 | è®°å¿†æ”¶é›† |
| nodes/tool_planner.py | ~120 | AI å†³ç­– |
| nodes/tool_executor.py | ~80 | å·¥å…·æ‰§è¡Œ |
| nodes/synthesis.py | ~60 | è¯æ®ç»¼åˆ |
| helpers/memory.py | ~80 | è®°å¿†é€»è¾‘ |
| helpers/prompts.py | ~200 | Prompt æ„å»º |
| graph.py | ~50 | å›¾æ„å»º |
| **æ€»è®¡** | **~800** | **èŒè´£æ¸…æ™°** |

---

## âœ… å®æ–½å»ºè®®

### æ–¹æ¡ˆé€‰æ‹©

**æ¨è**: **æ¨¡å—åŒ–æ‹†åˆ†æ–¹æ¡ˆ**

**ç†ç”±**:
1. âœ… å•ä¸ªæ–‡ä»¶ < 200 è¡Œï¼Œå¯è¯»æ€§å¥½
2. âœ… èŒè´£åˆ†ç¦»ï¼Œæ˜“äºæµ‹è¯•
3. âœ… ä¾¿äº Phase 2 æ‰©å±•ï¼ˆæ·»åŠ æ–°èŠ‚ç‚¹ï¼‰
4. âœ… Helper æ–¹æ³•å¯å¤ç”¨ï¼ˆFunction Calling + LangGraphï¼‰

### å®æ–½æ­¥éª¤

1. **åˆ›å»ºç›®å½•ç»“æ„**:
   ```bash
   mkdir -p src/ai/deep_analysis/nodes
   mkdir -p src/ai/deep_analysis/helpers
   ```

2. **å®æ–½é¡ºåº**:
   - Day 1: åˆ›å»º base.py + helpers (memory, prompts)
   - Day 2: å®ç° 4 ä¸ªèŠ‚ç‚¹ç±»
   - Day 3: åˆ›å»º graph.py + æ›´æ–° gemini.py
   - Day 4: å•å…ƒæµ‹è¯•
   - Day 5: é›†æˆæµ‹è¯•

3. **å‘åå…¼å®¹**:
   - ä¿ç•™ gemini.py ä¸­çš„ Function Calling é€»è¾‘
   - `DEEP_ANALYSIS_TOOLS_ENABLED=false` æ—¶ä½¿ç”¨æ—§é€»è¾‘
   - é€æ­¥è¿ç§»ï¼Œé™ä½é£é™©

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### å•å…ƒæµ‹è¯•

æ¯ä¸ªèŠ‚ç‚¹å¯ç‹¬ç«‹æµ‹è¯•ï¼š

```python
# tests/ai/deep_analysis/nodes/test_tool_planner.py
@pytest.mark.asyncio
async def test_tool_planner_whitelist():
    """Test whitelist event types force search."""
    engine = MockEngine()
    node = ToolPlannerNode(engine)

    state = {
        "payload": mock_payload,
        "preliminary": mock_preliminary(event_type="hack"),
        "tool_call_count": 0,
    }

    result = await node.execute(state)

    assert result["next_tools"] == ["search"]
    assert len(result["search_keywords"]) > 0
```

### é›†æˆæµ‹è¯•

```python
# tests/ai/deep_analysis/test_graph_integration.py
@pytest.mark.asyncio
async def test_full_langgraph_flow():
    """Test complete LangGraph flow."""
    engine = create_test_engine()
    graph = build_deep_graph(engine)

    initial_state = {...}
    final_state = await graph.ainvoke(initial_state)

    assert final_state["final_response"] is not None
```

---

## ğŸ“š æ–‡æ¡£æ›´æ–°

éœ€è¦æ›´æ–°ä»¥ä¸‹æ–‡æ¡£ï¼š

1. âœ… æœ¬æ–‡æ¡£ (`phase1_module_architecture.md`) - æ¨¡å—åŒ–è®¾è®¡
2. ğŸ”„ `phase1_search_tool_implementation_cn.md` - æ›´æ–°å®æ–½ä»»åŠ¡
3. ğŸ”„ `phase1_langgraph_integration_guide.md` - æ›´æ–°é›†æˆæ­¥éª¤
4. ğŸ”„ `README_PHASE1_IMPLEMENTATION.md` - æ›´æ–°æ–‡ä»¶ç»“æ„

---

## ğŸ¯ æ€»ç»“

### âœ… æ¨èä½¿ç”¨æ¨¡å—åŒ–æ‹†åˆ†

**ä¼˜åŠ¿**:
- ä»£ç æ›´æ¸…æ™°ï¼ˆå•ä¸ªæ–‡ä»¶ < 200 è¡Œï¼‰
- èŒè´£åˆ†ç¦»ï¼Œæ˜“äºç»´æŠ¤
- å¯ç‹¬ç«‹æµ‹è¯•ï¼Œæé«˜è´¨é‡
- ä¾¿äº Phase 2 æ‰©å±•

**æˆæœ¬**:
- éœ€è¦åˆ›å»ºæ›´å¤šæ–‡ä»¶ï¼ˆ+9 ä¸ªæ–‡ä»¶ï¼‰
- éœ€è¦æ›´æ–°å¯¼å…¥è·¯å¾„
- éœ€è¦ç¼–å†™æ›´å¤šå•å…ƒæµ‹è¯•

**ROI**: **å€¼å¾—æŠ•èµ„** - é•¿æœŸå¯ç»´æŠ¤æ€§è¿œè¶…åˆæœŸæˆæœ¬

---

**æœ€åæ›´æ–°**: 2025-10-11
**å†³ç­–**: âœ… é‡‡ç”¨æ¨¡å—åŒ–æ‹†åˆ†æ–¹æ¡ˆ
**ä¸‹ä¸€æ­¥**: æ›´æ–°å®æ–½æ–‡æ¡£ï¼ŒæŒ‰æ¨¡å—åŒ–æ–¹æ¡ˆé‡æ–°ç»„ç»‡ä»£ç 
