# æ•°æ®å­˜å‚¨è®¾è®¡ï¼ˆæ–°é—»ä¸ä¿¡å·ï¼‰

> ç›®æ ‡ï¼šæŒä¹…åŒ– Telegram ç­‰æ¸ é“æŠ“å–çš„åŸå§‹æ–°é—»ã€AI è§£æè¾“å‡ºçš„ç»“æ„åŒ–ä¿¡å·ï¼Œä»¥åŠç”¨äºå›æµ‹ä¸ç›‘æ§çš„è¾…åŠ©å…ƒæ•°æ®ã€‚è®¾è®¡éµå¾ª Supabase/PostgreSQL ç”Ÿæ€ï¼Œå­—æ®µå‘½åä¸æ•°æ®ç±»å‹å¯è·¨é¡¹ç›®å…±ç”¨ã€‚

## 1. æ€»è§ˆ

æ•°æ®æµåˆ†ä¸ºä¸‰å±‚ï¼š

1. **åŸå§‹äº‹ä»¶å±‚ï¼ˆRaw Layerï¼‰**ï¼šæŒ‰æ¶ˆæ¯ç²’åº¦ä¿ç•™æ¥æºæ–‡æœ¬ã€é™„ä»¶å¼•ç”¨ã€å“ˆå¸Œï¼Œç”¨äºè¿½æº¯ä¸å»é‡ã€‚
2. **ä¿¡å·å†³ç­–å±‚ï¼ˆSignal Layerï¼‰**ï¼šå­˜å‚¨ AI è§£æç»“æœã€è¡ŒåŠ¨å»ºè®®ã€ç½®ä¿¡åº¦ç­‰ç»“æ„åŒ–å­—æ®µï¼Œå…³è”åˆ°åŸå§‹äº‹ä»¶ã€‚
3. **èšåˆæ´å¯Ÿå±‚ï¼ˆInsight Layerï¼‰**ï¼šå¯é€‰ï¼Œç”¨äºäººå·¥æ•´ç†ã€ç­–ç•¥è°ƒå‚æˆ–å¤šäº‹ä»¶åˆæˆã€‚

```
[source_feeds] -> [news_events] -> [ai_signals] -> [strategy_insights]
                                 â†˜ [market_snapshots]*
```

`market_snapshots` ä¸ºå¯é€‰è¡Œæƒ…å¿«ç…§ï¼Œä¾¿äºå›æµ‹ã€‚æ˜Ÿå·è¡¨ç¤ºæŒ‰éœ€å¯ç”¨ã€‚

## 2. `news_events` â€” åŸå§‹æ–°é—»è¡¨

| åˆ—å | ç±»å‹ | è¯´æ˜ | çº¦æŸ / é»˜è®¤ |
| --- | --- | --- | --- |
| `id` | `bigserial` | ä¸»é”® | `primary key` |
| `created_at` | `timestamptz` | å†™å…¥æ—¶é—´ | `default now()` |
| `updated_at` | `timestamptz` | æ›´æ–°æ—¶é—´ | `default now()`ï¼Œè‡ªåŠ¨è§¦å‘å™¨æ›´æ–° |
| `source` | `text` | æ¥æºé€šé“åç§°ï¼ˆå¦‚ `Onchain Lens Channel`ï¼‰ | `not null` |
| `source_message_id` | `text` | æ¥æºå¹³å°æ¶ˆæ¯ IDï¼ˆTelegram message idï¼‰ | `not null`ï¼ŒåŒæºå”¯ä¸€ |
| `source_url` | `text` | åŸå§‹æ¶ˆæ¯/å¸–å­é“¾æ¥ | å¯ä¸ºç©º |
| `language` | `varchar(12)` | è‡ªåŠ¨è¯†åˆ«è¯­è¨€ | é»˜è®¤ `unknown` |
| `published_at` | `timestamptz` | æ¶ˆæ¯å‘å¸ƒæ—¶é—´ï¼ˆè‹¥ç¼ºå¤±å–æŠ“å–æ—¶é—´ï¼‰ | `not null` |
| `content_text` | `text` | åŸæ–‡æ–‡æœ¬ | `not null` |
| `summary` | `text` | åŸå§‹æ–°é—»æ‘˜è¦ï¼ˆå¦‚æœæ¥æºæä¾›ï¼‰ | å¯ä¸ºç©º |
| `translated_text` | `text` | è¯‘æ–‡ï¼ˆè‹¥å¯ç”¨ç¿»è¯‘ï¼‰ | å¯ä¸ºç©º |
| `media_refs` | `jsonb` | é™„ä»¶ä¿¡æ¯ï¼ˆå›¾ç‰‡ã€é“¾æ¥ã€æ–‡æ¡£ï¼‰ | é»˜è®¤ `[]` |
| `hash_raw` | `char(64)` | åŸæ–‡ SHA-256ï¼Œç”¨äºå»é‡ | `not null`ï¼Œå»ºå”¯ä¸€ç´¢å¼• |
| `hash_canonical` | `char(64)` | å½’ä¸€åŒ–åå“ˆå¸Œï¼ˆå»æ‰ç©ºæ ¼ã€URL ç­‰ï¼‰ | å¯ç©º |
| `embedding` | `vector(1536)` | åŸæ–‡è¯­ä¹‰å‘é‡ï¼Œç”¨äºè¯­ä¹‰å»é‡/æ£€ç´¢ | å¯ç©ºï¼Œ`pgvector`ï¼ŒåŸºäº OpenAI `text-embedding-3-small` |
| `keywords_hit` | `jsonb` | å‘½ä¸­å…³é”®è¯åˆ—è¡¨ | é»˜è®¤ `[]` |
| `ingest_status` | `varchar(32)` | å¤„ç†çŠ¶æ€ï¼š`pending/processed/error` | é»˜è®¤ `pending` |
| `metadata` | `jsonb` | é¢å¤–å…ƒæ•°æ®ï¼ˆæŠ“å–å»¶è¿Ÿã€æœºå™¨äººç‰ˆæœ¬ï¼‰ | é»˜è®¤ `{}` |

**ç´¢å¼•å»ºè®®**ï¼š
- `unique (source, source_message_id)` é˜²é‡å¤å†™å…¥ã€‚
- `unique (hash_raw)` æ”¯æŒè·¨æºå»é‡ã€‚
- `gin (keywords_hit)` æ–¹ä¾¿å…³é”®è¯æŸ¥è¯¢ã€‚
- `index (published_at desc)` æ”¯æŒæ—¶é—´åºåˆ—æŸ¥è¯¢ã€‚
- `index (ingest_status)` åŠ é€ŸçŠ¶æ€ç­›é€‰ã€‚
- `index (updated_at desc)` è¿½è¸ªæ›´æ–°è®°å½•ã€‚
- `ivfflat (embedding)` æˆ– `hnsw (embedding)` æ”¯æŒå‘é‡ç›¸ä¼¼åº¦ç­›æŸ¥æ½œåœ¨é‡å¤ã€‚

## 3. `ai_signals` â€” AI å†³ç­–ä¿¡å·è¡¨

| åˆ—å | ç±»å‹ | è¯´æ˜ | çº¦æŸ / é»˜è®¤ |
| --- | --- | --- | --- |
| `id` | `bigserial` | ä¸»é”® | `primary key` |
| `news_event_id` | `bigint` | å¯¹åº”åŸå§‹äº‹ä»¶ ID | å¤–é”® `references news_events(id)`ï¼Œ`on delete cascade` |
| `created_at` | `timestamptz` | å†™å…¥æ—¶é—´ | `default now()` |
| `model_name` | `text` | è°ƒç”¨çš„æ¨¡å‹ï¼ˆå¦‚ `gemini-2.0-flash`ï¼‰ | `not null` |
| `summary_cn` | `text` | AI ä¸­æ–‡æ‘˜è¦ | `not null` |
| `event_type` | `varchar(32)` | äº‹ä»¶åˆ†ç±»ï¼ˆæšä¸¾ï¼šlisting/hack/whale/...ï¼‰ | `not null` |
| `assets` | `varchar(120)` | å½±å“èµ„äº§ä»£ç ï¼Œé€—å·åˆ†éš” | é»˜è®¤ `NONE` |
| `asset_names` | `text` | èµ„äº§ä¸­æ–‡åæˆ–æè¿° | å¯ä¸ºç©º |
| `action` | `varchar(24)` | å»ºè®®åŠ¨ä½œï¼š`buy/sell/observe` | `not null` |
| `direction` | `varchar(24)` | `long/short/neutral` | é»˜è®¤ `neutral` |
| `confidence` | `float4` | 0â€“1 ç½®ä¿¡åº¦ | é»˜è®¤ `0` |
| `strength` | `varchar(16)` | `low/medium/high` | é»˜è®¤ `low` |
| `risk_flags` | `jsonb` | é£é™©æ ‡ç­¾æ•°ç»„ | é»˜è®¤ `[]` |
| `notes` | `text` | æ¨¡å‹è¡¥å……è¯´æ˜ | å¯ä¸ºç©º |
| `links` | `jsonb` | å…³è”é“¾æ¥åˆ—è¡¨ | é»˜è®¤ `[]` |
| `execution_path` | `varchar(16)` | `hot/warm/cold/skip` | é»˜è®¤ `cold` |
| `should_alert` | `boolean` | æ˜¯å¦æ¨é€ | é»˜è®¤ `false` |
| `latency_ms` | `integer` | ä»æŠ“å–åˆ°å‡ºä¿¡å·çš„å»¶è¿Ÿ | å¯ä¸ºç©º |
| `raw_response` | `jsonb` | æ¨¡å‹åŸå§‹ JSONï¼ˆæˆªæ–­æˆ–å‹ç¼©ï¼‰ | å¯ä¸ºç©º |

**ç´¢å¼•å»ºè®®**ï¼š
- `index on news_event_id` ç”¨äºè”æŸ¥ã€‚
- `index on created_at desc` æ”¯æŒæ—¶é—´åºåˆ—ã€‚
- `partial index where should_alert = true` åŠ é€Ÿå¾…æ¨é€æŸ¥è¯¢ã€‚
- `index on event_type` æ”¯æŒäº‹ä»¶ç±»å‹ç­›é€‰ã€‚
- `index on execution_path` æ”¯æŒæ‰§è¡Œè·¯å¾„æŸ¥è¯¢ã€‚

## 4. `strategy_insights` â€” æ´å¯Ÿ/äººå·¥æ ‡æ³¨è¡¨ï¼ˆå¯é€‰ï¼‰

| åˆ—å | ç±»å‹ | è¯´æ˜ |
| --- | --- | --- |
| `id` | `bigserial` | ä¸»é”® |
| `created_at` / `updated_at` | `timestamptz` | é»˜è®¤ `now()`ï¼Œè‡ªåŠ¨è§¦å‘å™¨æ›´æ–° |
| `title` | `text` | æ´å¯Ÿæ ‡é¢˜ï¼ˆå¦‚"Solana CME æœªå¹³ä»“é‡æš´å¢"ï¼‰ |
| `summary` | `text` | æ´å¯Ÿæ‘˜è¦ |
| `narrative` | `text` | é•¿æ–‡æè¿°ï¼Œæ”¯æŒæ€»ç»“å¤šæ¡äº‹ä»¶ |
| `relation` | `text` | äº‹ä»¶é—´å…³ç³»æè¿° |
| `action` | `text` | å»ºè®®åŠ¨ä½œæˆ–ç­–ç•¥ |
| `confidence` | `float4` | ä¸»è§‚ä¿¡å¿ƒå€¼ |
| `source_urls` | `jsonb` | å…³è”é“¾æ¥æ•°ç»„ |
| `news_event_ids` | `_int8` | å…³è”çš„æ–°é—»äº‹ä»¶ ID åˆ—è¡¨ |
| `ai_signal_ids` | `_int8` | å…³è”çš„ä¿¡å· ID åˆ—è¡¨ |
| `tags` | `jsonb` | è‡ªå®šä¹‰æ ‡ç­¾ï¼ˆå™äº‹ã€æ¿å—ç­‰ï¼‰ |
| `url_hash` | `text` | URL å“ˆå¸Œï¼Œç”¨äºå»é‡ |
| `content_hash` | `text` | å†…å®¹å“ˆå¸Œï¼Œç”¨äºå»é‡ |
| `embedding` | `vector(1536)` | ï¼ˆå¯é€‰ï¼‰ç”¨äºè¯­ä¹‰æ£€ç´¢ï¼ˆOpenAI `text-embedding-3-small` è¾“å‡ºï¼‰ |

**ç´¢å¼•å»ºè®®**ï¼š
- `index on created_at desc` æ”¯æŒæ—¶é—´åºåˆ—æŸ¥è¯¢ã€‚
- `gin (tags)` æ”¯æŒæ ‡ç­¾æŸ¥è¯¢ã€‚
- `unique (url_hash) where url_hash is not null` URL å»é‡ã€‚
- `index on content_hash` å†…å®¹å»é‡ç­›æŸ¥ã€‚

## 5. `market_snapshots` â€” è¡Œæƒ…å¿«ç…§ï¼ˆå¯é€‰ï¼‰

ç”¨äºå›æµ‹ä¿¡å·è¡¨ç°ï¼ŒæŒ‰éœ€ä¿å­˜ä¸»è¦äº¤æ˜“å¯¹è¡Œæƒ…ã€‚

| åˆ—å | ç±»å‹ | è¯´æ˜ | çº¦æŸ / é»˜è®¤ |
| --- | --- | --- | --- |
| `id` | `bigserial` | ä¸»é”® | `primary key` |
| `captured_at` | `timestamptz` | æˆªå–æ—¶é—´ | `not null` |
| `asset` | `varchar(32)` | èµ„äº§ä»£ç  | `not null` |
| `price` | `numeric(18,8)` | å³æ—¶ä»·æ ¼ | `not null` |
| `volume_1h` | `numeric(20,2)` | è¿‘ 1 å°æ—¶æˆäº¤é‡ | å¯ä¸ºç©º |
| `open_interest` | `numeric(20,2)` | è¡ç”Ÿå“æœªå¹³ä»“é‡ | å¯ä¸ºç©º |
| `external_source` | `text` | æ•°æ®æ¥æºï¼ˆBinance API ç­‰ï¼‰ | å¯ä¸ºç©º |
| `metadata` | `jsonb` | é¢å¤–æŒ‡æ ‡ï¼ˆèµ„é‡‘è´¹ç‡ã€æ·±åº¦ç­‰ï¼‰ | é»˜è®¤ `{}` |

**ç´¢å¼•å»ºè®®**ï¼š
- `unique (asset, captured_at)` é˜²æ­¢åŒä¸€æ—¶åˆ»é‡å¤è®°å½•
- `index (captured_at desc)` æ”¯æŒæ—¶é—´åºåˆ—æŸ¥è¯¢
- `index (asset)` æ”¯æŒæŒ‰èµ„äº§ç­›é€‰

å¯ç»“åˆ `ai_signals.execution_path` åš T+5m / T+1h è¡¨ç°è¯„ä¼°ã€‚

## 6. äº‹ä»¶ç”Ÿå‘½å‘¨æœŸ

1. **æŠ“å–**ï¼š`listener.py` æ•è·æ¶ˆæ¯ï¼Œå†™å…¥ `news_events`ï¼Œè®¡ç®— `hash_raw` / `hash_canonical`ï¼Œå¹¶æ ‡è®° `ingest_status='pending'`ã€‚
2. **å»é‡ + ç¿»è¯‘**ï¼šè‹¥æ£€æµ‹é‡å¤åˆ™ç›´æ¥å…³è”å·²æœ‰è®°å½•ï¼›æˆåŠŸç¿»è¯‘åæ›´æ–° `translated_text`ã€`language`ã€`metadata.translation_confidence`ã€‚
   - å»é‡ç­–ç•¥ç»“åˆ `hash_raw` ä¸ `embedding` è¿‘é‚»æœç´¢ï¼ˆå¦‚ `cosine_distance < 0.1`ï¼‰ï¼Œé¿å…è·¨æ¸ é“æ”¹å†™çš„é‡å¤æ–°é—»ã€‚
3. **AI ä¿¡å·**ï¼šè°ƒç”¨ `AiSignalEngine`ï¼Œç»“æœå†™å…¥ `ai_signals`ï¼ˆå« `news_event_id`ï¼‰ï¼Œå¹¶å†³å®šæ˜¯å¦æ¨é€ä¸æ‰§è¡Œã€‚
4. **è¿½è¸ªæ‰§è¡Œ**ï¼ˆå¯é€‰ï¼‰ï¼šè‹¥è§¦å‘çƒ­è·¯å¾„äº¤æ˜“ï¼Œåœ¨åŒäº‹åŠ¡æˆ–å¼‚æ­¥ä»»åŠ¡ä¸­æ›´æ–° `ai_signals.execution_path='hot'`ï¼Œå¹¶å†™å…¥äº¤æ˜“æ—¥å¿—è¡¨ï¼ˆæ­¤å¤„ç•¥ï¼‰ã€‚
5. **å›æµ‹/æ´å¯Ÿ**ï¼šç ”å‘æˆ–ç­–ç•¥äººå‘˜å¯åœ¨ `strategy_insights` ä¸­è®°å½•å¤ç›˜è¦ç‚¹ï¼Œå¹¶é€šè¿‡ `news_event_ids` / `ai_signal_ids` è¿›è¡Œå…³è”ã€‚

## 7. å®æ–½å»ºè®®

- **æ•°æ®åº“**ï¼šä½¿ç”¨ Supabaseï¼ˆPostgreSQL 16 + pgvectorï¼‰ï¼Œä¸ç°æœ‰é¡¹ç›®å¯¹é½ã€‚
- **è¿ç§»ç®¡ç†**ï¼šé‡‡ç”¨ `sqlx migrate` æˆ– `dbmate`ï¼Œä¿æŒ DDL å¯è¿½è¸ªã€‚
- **å‘é‡ç”Ÿæˆ**ï¼šåœ¨ ingest æµç¨‹ä¸­è°ƒç”¨ `text-embedding-3-small`ï¼ˆ1536 ç»´ï¼‰ç­‰æ¨¡å‹å†™å…¥ `embedding`ï¼Œå¹¶å®šæœŸé‡å»º `ivfflat`/`hnsw` ç´¢å¼•ï¼›è‹¥æ¢æ¨¡å‹éœ€åŒæ­¥è°ƒæ•´åˆ—ç»´åº¦ã€‚
- **æ•°æ®ä¿ç•™**ï¼šå»ºè®®å¯¹ `raw_response`ã€`media_refs` è®¾å®š 30 å¤© TTLï¼Œè¿‡æœŸè½¬å­˜åˆ° S3 ä»¥å‡å°‘ä¸»åº“å‹åŠ›ã€‚
- **è®¿é—®æƒé™**ï¼š
  - æœåŠ¡ç«¯è§’è‰²ï¼š`ingest_writer`ï¼ˆåªèƒ½å†™å…¥ rawï¼‰ã€`signal_writer`ï¼ˆåªèƒ½å†™å…¥ä¿¡å·ï¼‰ã€`analyst_reader`ï¼ˆåªè¯»è§†å›¾ï¼‰ã€‚
  - å‰ç«¯ / BIï¼šé€šè¿‡åªè¯»è§†å›¾ï¼Œä¾‹å¦‚ `v_signal_feed`ï¼ˆjoin åŸå§‹äº‹ä»¶ + ä¿¡å·ï¼‰ã€‚
- **è´¨é‡ç›‘æ§**ï¼š
  - å»ºç«‹å®šæ—¶ä»»åŠ¡ç»Ÿè®¡ `should_alert=true` çš„ä¿¡å·æ•°é‡ã€æ¨¡å‹å»¶è¿Ÿã€é‡å¤ç‡ã€‚
  - å¯¹ `confidence` < é˜ˆå€¼ä½†ä»æ¨é€çš„æ¡ˆä¾‹è®°å½• `risk_flags`ï¼Œä¾¿äºè°ƒå‚ã€‚

## 8. Supabase é›†æˆå®ç°æ–¹æ¡ˆ

### 8.1 æ¨¡å—ç»“æ„

```
src/db/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ supabase_client.py   # è´Ÿè´£åˆå§‹åŒ–å¹¶ç¼“å­˜ Supabase å®¢æˆ·ç«¯
â”œâ”€â”€ repositories.py      # Repository å±‚å°è£… CRUD
â””â”€â”€ models.py            # å¯é€‰çš„æ•°æ®æ¨¡å‹/ç±»å‹æç¤º
```

- `supabase_client.py`ï¼šä»ç¯å¢ƒå˜é‡è¯»å– `SUPABASE_URL`ã€`SUPABASE_SERVICE_KEY`ï¼Œæ„å»ºå•ä¾‹å®¢æˆ·ç«¯ï¼›è‹¥ç¦ç”¨æŒä¹…åŒ–åˆ™è¿”å›ç©ºå®ç°ã€‚
- `repositories.py`ï¼šæ‹†åˆ†ä¸º `NewsEventRepository`ã€`AiSignalRepository`ã€`StrategyInsightRepository`ï¼Œå¯¹å¤–æä¾›å¼‚æ­¥æ–¹æ³•ï¼ˆ`insert_event`ã€`insert_signal`ã€`check_duplicate` ç­‰ï¼‰ã€‚
- `models.py`ï¼šå®šä¹‰æ•°æ®ç±»/TypedDictï¼Œçº¦æŸå…¥å‚ç»“æ„ï¼Œä¾¿äºé™æ€æ£€æŸ¥ã€‚

### 8.2 æ•°æ®å†™å…¥æµç¨‹

**ä¸»æµç¨‹ï¼ˆåŒæ­¥ï¼‰ï¼š**

1. **æ”¶é›†åŸå§‹æ•°æ®**ï¼ˆ`listener._handle_new_message`ï¼‰
   - ä» Telegram event æå–ï¼š
     ```python
     source_message_id = str(event.message.id)
     source_url = f"https://t.me/c/{chat_id}/{message_id}"  # ç§æœ‰é¢‘é“
     published_at = event.message.date  # datetime å¯¹è±¡
     media_refs = await self._extract_media(event.message)
     ```
   - å·²æœ‰æ•°æ®ï¼š`message_text`ã€`translated_text`ã€`language`ã€`keywords_hit`

2. **è®¡ç®—å“ˆå¸Œä¸å»é‡**
   ```python
   import hashlib
   import re

   def compute_hash_raw(text: str) -> str:
       return hashlib.sha256(text.encode('utf-8')).hexdigest()

   def compute_hash_canonical(text: str) -> str:
       # å½’ä¸€åŒ–ï¼šå»é™¤ç©ºç™½ã€URLã€emojiã€æ ‡ç‚¹
       normalized = re.sub(r'\s+', '', text)
       normalized = re.sub(r'https?://\S+', '', normalized)
       normalized = re.sub(r'[^\w\u4e00-\u9fff]', '', normalized)  # ä¿ç•™ä¸­è‹±æ–‡
       return hashlib.sha256(normalized.encode('utf-8')).hexdigest()

   hash_raw = compute_hash_raw(message_text)
   hash_canonical = compute_hash_canonical(message_text)
   ```

3. **ç”Ÿæˆ Embedding**ï¼ˆåŒæ­¥ï¼ŒPhase 1 å³å¯ç”¨ï¼‰
   ```python
   from openai import AsyncOpenAI

   openai_client = AsyncOpenAI(api_key=config.OPENAI_API_KEY)

   # ç”Ÿæˆå‘é‡
   try:
       response = await openai_client.embeddings.create(
           model="text-embedding-3-small",
           input=message_text[:8000]  # é™åˆ¶é•¿åº¦
       )
       embedding = response.data[0].embedding  # 1536 ç»´
   except Exception as e:
       logger.warning("Embedding ç”Ÿæˆå¤±è´¥ï¼Œè·³è¿‡å‘é‡å»é‡: %s", e)
       embedding = None
   ```

4. **å»é‡æ£€æŸ¥**ï¼ˆè‹¥å¯ç”¨ `ENABLE_DB_PERSISTENCE=true`ï¼‰
   ```python
   # Level 1: ç²¾ç¡®å“ˆå¸Œå»é‡
   existing_id = await NewsEventRepository.check_duplicate_by_hash(hash_raw)
   if existing_id:
       logger.debug("ç²¾ç¡®å»é‡å‘½ä¸­: event_id=%s", existing_id)
       return existing_id

   # Level 2: è¯­ä¹‰å‘é‡å»é‡ï¼ˆä»…å½“ embedding ç”ŸæˆæˆåŠŸï¼‰
   if embedding:
       similar = await NewsEventRepository.check_duplicate_by_embedding(
           embedding=embedding,
           threshold=0.92,  # ç›¸ä¼¼åº¦é˜ˆå€¼
           time_window_hours=72  # åªæŸ¥ 3 å¤©å†…
       )
       if similar:
           logger.info(
               "è¯­ä¹‰å»é‡å‘½ä¸­: event_id=%s similarity=%.3f",
               similar.id,
               similar.similarity
           )
           # æ ‡è®°ä¸ºè¯­ä¹‰é‡å¤ï¼Œä½†ä»å†™å…¥ï¼ˆå¯é€‰ï¼‰
           return similar.id
   ```

5. **å†™å…¥åŸå§‹äº‹ä»¶**ï¼ˆå« embeddingï¼‰
   ```python
   news_event_id = await NewsEventRepository.insert_event({
       "source": source_name,
       "source_message_id": source_message_id,
       "source_url": source_url,
       "published_at": published_at.isoformat(),
       "content_text": message_text,
       "translated_text": translated_text,
       "language": language,
       "hash_raw": hash_raw,
       "hash_canonical": hash_canonical,
       "embedding": embedding,  # ğŸ†• ç›´æ¥å†™å…¥å‘é‡
       "keywords_hit": keywords_hit,
       "media_refs": media_refs,
       "ingest_status": "processed",  # å·²æœ‰ embeddingï¼Œç›´æ¥æ ‡è®°ä¸º processed
       "metadata": {
           "translation_confidence": translation_confidence,
           "embedding_model": "text-embedding-3-small",
           "embedding_generated_at": datetime.now().isoformat(),
           "bot_version": __version__,
           "ingestion_latency_ms": int((datetime.now() - event_time).total_seconds() * 1000)
       }
   })
   ```

6. **å†™å…¥ AI ä¿¡å·**ï¼ˆè‹¥æœ‰ç»“æœï¼‰
   ```python
   if signal_result and signal_result.status in ("success", "skip"):
       latency_ms = int((datetime.now() - event_time).total_seconds() * 1000)

       # åˆ¤å®šæ‰§è¡Œè·¯å¾„
       execution_path = "cold"
       if signal_result.should_execute_hot_path:
           execution_path = "hot"
       elif signal_result.confidence >= 0.7:
           execution_path = "warm"
       elif signal_result.status == "skip":
           execution_path = "skip"

       await AiSignalRepository.insert_signal({
           "news_event_id": news_event_id,
           "model_name": config.AI_MODEL_NAME,
           "summary_cn": signal_result.summary,
           "event_type": signal_result.event_type,
           "assets": signal_result.asset,
           "asset_names": signal_result.asset_names,
           "action": signal_result.action,
           "direction": signal_result.direction,
           "confidence": signal_result.confidence,
           "strength": signal_result.strength,
           "risk_flags": signal_result.risk_flags,
           "notes": signal_result.notes,
           "links": signal_result.links,
           "execution_path": execution_path,
           "should_alert": forwarded,  # å®é™…æ˜¯å¦æ¨é€
           "latency_ms": latency_ms,
           "raw_response": signal_result.raw_response[:5000]  # æˆªæ–­é¿å…è¿‡å¤§
       })
   ```

7. **å‘é‡ç´¢å¼•åˆ›å»º**ï¼ˆPhase 1 å®Œæˆåç«‹å³æ‰§è¡Œï¼‰
   ```sql
   -- å½“è¡¨ä¸­æœ‰æ•°æ®åï¼Œç«‹å³åˆ›å»ºå‘é‡ç´¢å¼•
   create index concurrently idx_news_events_embedding
     on news_events using ivfflat(embedding vector_cosine_ops)
     with (lists = 100);
   ```

**Phase 2 ä¼˜åŒ–ï¼ˆå¼‚æ­¥ Embeddingï¼‰ï¼š**

8. **æ”¹ä¸ºå¼‚æ­¥ç”Ÿæˆ**ï¼ˆPhase 2 æ€§èƒ½ä¼˜åŒ–ï¼‰
   ```python
   # å†™å…¥æ—¶å…ˆä¸ç”Ÿæˆ embeddingï¼Œæ ‡è®°ä¸º pending
   news_event_id = await NewsEventRepository.insert_event({
       ...
       "embedding": None,  # æš‚ä¸ç”Ÿæˆ
       "ingest_status": "pending",  # ç­‰å¾… embedding
   })

   # åå°ä»»åŠ¡å¼‚æ­¥ç”Ÿæˆ
   asyncio.create_task(generate_embedding_async(news_event_id, message_text))
   ```

9. **åå° Embedding Worker**
   ```python
   async def embedding_worker():
       while True:
           events = await NewsEventRepository.get_pending_embedding(limit=10)
           if events:
               # æ‰¹é‡ç”Ÿæˆ
               texts = [e.content_text for e in events]
               response = await openai_client.embeddings.create(
                   model="text-embedding-3-small",
                   input=texts
               )
               for event, emb_data in zip(events, response.data):
                   await NewsEventRepository.update_embedding(
                       event.id,
                       emb_data.embedding
                   )
           await asyncio.sleep(5)  # æ¯ 5 ç§’ä¸€æ‰¹
   ```

### 8.3 äº‹åŠ¡ä¸é‡è¯•ç­–ç•¥

**äº‹åŠ¡å¤„ç†ï¼š**

Supabase REST API ä¸æ”¯æŒåŸç”Ÿäº‹åŠ¡ï¼Œé‡‡ç”¨ä»¥ä¸‹è¡¥å¿ç­–ç•¥ï¼š

1. **ä¸¤é˜¶æ®µæäº¤æ¨¡å¼**
   ```python
   news_event_id = None
   try:
       # Phase 1: å†™å…¥ news_events
       news_event_id = await NewsEventRepository.insert_event(...)

       # Phase 2: å†™å…¥ ai_signals
       if signal_result:
           await AiSignalRepository.insert_signal(news_event_id=news_event_id, ...)
   except Exception as e:
       # è¡¥å¿ï¼šåˆ é™¤å­¤ç«‹çš„ news_event
       if news_event_id and not signal_result:
           await NewsEventRepository.delete(news_event_id)
       raise
   ```

2. **å¤–é”®çº§è”**
   - åˆ©ç”¨æ•°æ®åº“ `on delete cascade` ä¿è¯æ•°æ®ä¸€è‡´æ€§
   - åˆ é™¤ news_event æ—¶è‡ªåŠ¨æ¸…ç†å…³è”çš„ ai_signals

**é‡è¯•æœºåˆ¶ï¼š**

```python
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    retry=retry_if_exception_type((NetworkError, TimeoutError))
)
async def insert_with_retry(...):
    return await supabase.insert(...)
```

- **å¯é‡è¯•é”™è¯¯**ï¼šç½‘ç»œè¶…æ—¶ã€503 Service Unavailableã€429 Rate Limit
- **ä¸å¯é‡è¯•é”™è¯¯**ï¼šå”¯ä¸€ç´¢å¼•å†²çªï¼ˆé‡å¤æ•°æ®ï¼‰ã€æ•°æ®æ ¼å¼é”™è¯¯
- **é‡è¯•ç­–ç•¥**ï¼šæŒ‡æ•°é€€é¿ï¼Œ1s â†’ 2s â†’ 4s â†’ 8sï¼ˆæœ€å¤š 3 æ¬¡ï¼‰
- **è¶…æ—¶é˜ˆå€¼**ï¼šå•æ¬¡è¯·æ±‚ 5 ç§’è¶…æ—¶ï¼Œæ€»é‡è¯•æ—¶é•¿ä¸è¶…è¿‡ 30 ç§’

**å¤±è´¥é™çº§ï¼š**

```python
try:
    await persist_to_db(...)
except SupabaseError as e:
    logger.error("æ•°æ®åº“å­˜å‚¨å¤±è´¥: %s", e)

    # é™çº§æ–¹æ¡ˆï¼šå†™å…¥æœ¬åœ°æ–‡ä»¶é˜Ÿåˆ—
    await write_to_local_queue({
        "event": event_data,
        "signal": signal_data,
        "timestamp": datetime.now().isoformat(),
        "retry_count": 0
    })

    # ä¸é˜»æ–­ä¸»æµç¨‹ï¼Œç»§ç»­è½¬å‘æ¶ˆæ¯
```

**æœ¬åœ°é˜Ÿåˆ—æ¢å¤**ï¼ˆåå°ä»»åŠ¡ï¼‰ï¼š
- å®šæœŸæ‰«ææœ¬åœ°é˜Ÿåˆ—æ–‡ä»¶
- é‡è¯•å†™å…¥ Supabase
- æˆåŠŸååˆ é™¤é˜Ÿåˆ—æ–‡ä»¶

### 8.4 å¤šå±‚å»é‡ç­–ç•¥

**Level 1: å†…å­˜ç¼“å­˜å»é‡**ï¼ˆæœ€å¿«ï¼Œ~0.1msï¼‰
```python
# ç»´æŠ¤æœ€è¿‘ 1000 æ¡æ¶ˆæ¯çš„å“ˆå¸Œ LRU ç¼“å­˜
from functools import lru_cache

class HashCache:
    def __init__(self, maxsize=1000):
        self._cache = {}
        self._order = []
        self._maxsize = maxsize

    def contains(self, hash_raw: str) -> bool:
        return hash_raw in self._cache

    def add(self, hash_raw: str, event_id: int):
        if len(self._cache) >= self._maxsize:
            oldest = self._order.pop(0)
            del self._cache[oldest]
        self._cache[hash_raw] = event_id
        self._order.append(hash_raw)
```

**Level 2: ç²¾ç¡®å“ˆå¸Œå»é‡**ï¼ˆå¿«ï¼Œ~5msï¼‰
- ä¾èµ– `hash_raw` å”¯ä¸€ç´¢å¼•
- æ•°æ®åº“æŸ¥è¯¢ï¼š
  ```sql
  select id from news_events where hash_raw = $1 limit 1;
  ```
- è‹¥å‘½ä¸­ï¼šè·³è¿‡å†™å…¥ï¼Œå¤ç”¨å·²æœ‰ `news_event_id`

**Level 3: å½’ä¸€åŒ–å“ˆå¸Œå»é‡**ï¼ˆä¸­ç­‰ï¼Œ~10msï¼‰
- ä½¿ç”¨ `hash_canonical`ï¼ˆå»é™¤ç©ºç™½ã€URLã€emojiã€æ ‡ç‚¹åçš„å“ˆå¸Œï¼‰
- æ•è·è½»å¾®æ”¹å†™çš„é‡å¤å†…å®¹
- æŸ¥è¯¢ï¼š
  ```sql
  select id from news_events
  where hash_canonical = $1
  limit 1;
  ```

**Level 3: è¯­ä¹‰å‘é‡å»é‡**ï¼ˆPhase 1 å³å¯ç”¨ï¼Œ~100-300msï¼‰
- ç”Ÿæˆ embedding åç«‹å³æ‰§è¡Œ
- ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢ï¼š
  ```sql
  select
    id,
    content_text,
    1 - (embedding <=> $1::vector) as similarity
  from news_events
  where embedding is not null
    and created_at > now() - interval '72 hours'  -- åªæŸ¥è¿‘ 3 å¤©
  order by embedding <=> $1::vector
  limit 1;
  ```
- åˆ¤å®šè§„åˆ™ï¼ˆPhase 1 ä¿å®ˆé˜ˆå€¼ï¼‰ï¼š
  - `similarity >= 0.92` â†’ ç¡®å®šé‡å¤ï¼Œè·³è¿‡å†™å…¥
  - `0.85 <= similarity < 0.92` â†’ ç–‘ä¼¼é‡å¤ï¼Œå†™å…¥ä½†æ ‡è®° `metadata.similar_to`
  - `similarity < 0.85` â†’ ä¸é‡å¤

**å»é‡å†³ç­–æ ‘ï¼ˆPhase 1 ç‰ˆæœ¬ï¼‰ï¼š**
```
1. ç”Ÿæˆ embeddingï¼ˆåŒæ­¥è°ƒç”¨ OpenAI APIï¼‰
   â†“
2. æ£€æŸ¥ hash_raw â†’ å‘½ä¸­ï¼Ÿè·³è¿‡
   â†“ æœªå‘½ä¸­
3. æ£€æŸ¥ embedding ç›¸ä¼¼åº¦ï¼ˆsimilarity >= 0.92ï¼‰â†’ å‘½ä¸­ï¼Ÿè·³è¿‡
   â†“ æœªå‘½ä¸­
4. å†™å…¥æ•°æ®åº“ï¼ˆå« embeddingï¼‰
```

**å»é‡å†³ç­–æ ‘ï¼ˆPhase 2 ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ï¼š**
```
1. æ£€æŸ¥å†…å­˜ç¼“å­˜ â†’ å‘½ä¸­ï¼Ÿè·³è¿‡
   â†“ æœªå‘½ä¸­
2. æ£€æŸ¥ hash_raw â†’ å‘½ä¸­ï¼Ÿè·³è¿‡
   â†“ æœªå‘½ä¸­
3. å¼‚æ­¥ç”Ÿæˆ embeddingï¼Œå…ˆå†™å…¥ï¼ˆingest_status=pendingï¼‰
   â†“
4. åå°ä»»åŠ¡ï¼šç”Ÿæˆ embedding å®Œæˆåï¼Œæ£€æŸ¥ç›¸ä¼¼åº¦
   â†“
5. è‹¥å‘ç°é‡å¤ï¼Œæ ‡è®° metadata.semantic_duplicate_of
```

**é˜ˆå€¼è°ƒä¼˜å»ºè®®ï¼š**
- **æ–°é—»å¿«è®¯**ï¼šé˜ˆå€¼ 0.92ï¼ˆä¿å®ˆï¼Œå‡å°‘è¯¯åˆ¤ï¼‰
- **ç¤¾äº¤åª’ä½“**ï¼šé˜ˆå€¼ 0.88ï¼ˆå®½æ¾ï¼Œæ•è·æ”¹å†™ï¼‰
- **å®˜æ–¹å…¬å‘Š**ï¼šé˜ˆå€¼ 0.95ï¼ˆä¸¥æ ¼ï¼Œç²¾ç¡®å»é‡ï¼‰

### 8.5 é…ç½®ä¸ä¾èµ–

- `config.py` ä¸­æ–°å¢ï¼š
  ```python
  SUPABASE_URL = os.getenv("SUPABASE_URL", "")
  SUPABASE_SERVICE_KEY = os.getenv("SUPABASE_SERVICE_KEY", "")
  ENABLE_DB_PERSISTENCE = _as_bool(os.getenv("ENABLE_DB_PERSISTENCE", "false"))
  ```
- `.env` ç¤ºä¾‹ï¼š
  ```
  SUPABASE_URL=https://crypto-signal-lab.supabase.co
  SUPABASE_SERVICE_KEY=******
  ENABLE_DB_PERSISTENCE=true
  ```
- ä¾èµ–ï¼šå®‰è£… `supabase` æˆ–ä½¿ç”¨ `httpx` è°ƒç”¨ Supabase RESTï¼›åµŒå…¥ç”Ÿæˆä½¿ç”¨ OpenAI SDKï¼ˆ`text-embedding-3-small`ï¼‰ã€‚

### 8.6 åˆ†é˜¶æ®µå®æ–½è·¯çº¿å›¾

**Phase 1: MVP + Embedding å»é‡** âœ… ä¼˜å…ˆçº§ï¼šP0
- [ ] åˆ›å»º `src/db/` æ¨¡å—ç»“æ„
- [ ] å®ç° `SupabaseClient` å•ä¾‹
- [ ] å®ç°å“ˆå¸Œè®¡ç®—å·¥å…·ï¼ˆ`hash_raw`, `hash_canonical`ï¼‰
- [ ] å®ç° `NewsEventRepository.insert_event()`
- [ ] å®ç° `AiSignalRepository.insert_signal()`
- [ ] é›†æˆ OpenAI `text-embedding-3-small` API
- [ ] å®ç°åŒæ­¥ embedding ç”Ÿæˆï¼ˆå†™å…¥æ—¶ç”Ÿæˆï¼‰
- [ ] å®ç° `NewsEventRepository.check_duplicate()` - æ”¯æŒå“ˆå¸Œ + å‘é‡å»é‡
- [ ] å®ç°è¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ï¼ˆä½™å¼¦è·ç¦»ï¼‰
- [ ] åœ¨ `listener._persist_event()` é›†æˆè°ƒç”¨
- [ ] é…ç½® `.env` æ·»åŠ  Supabase å’Œ OpenAI å‡­è¯
- [ ] åŸºç¡€é”™è¯¯å¤„ç†ï¼ˆæ•è·å¼‚å¸¸ï¼Œä¸é˜»æ–­ä¸»æµç¨‹ï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- æ–°æ¶ˆæ¯æˆåŠŸå†™å…¥ `news_events` è¡¨ï¼Œè‡ªåŠ¨ç”Ÿæˆ embedding
- AI ä¿¡å·æˆåŠŸå†™å…¥ `ai_signals` è¡¨
- ç²¾ç¡®é‡å¤ï¼ˆhash_rawï¼‰è¢«å»é‡
- è¯­ä¹‰é‡å¤ï¼ˆsimilarity >= 0.92ï¼‰è¢«å»é‡
- æ•°æ®åº“æ•…éšœæ—¶ç¨‹åºä¸å´©æºƒ

**æ€§èƒ½ç›®æ ‡ï¼š**
- å•æ¡æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ < 500msï¼ˆå« embedding ç”Ÿæˆï¼‰
- Embedding API è°ƒç”¨æˆåŠŸç‡ > 95%

---

**Phase 2: æ€§èƒ½ä¼˜åŒ–** ğŸ”„ ä¼˜å…ˆçº§ï¼šP1
- [ ] æ·»åŠ å†…å­˜å“ˆå¸Œç¼“å­˜ï¼ˆLRU 1000 æ¡ï¼‰
- [ ] Embedding æ”¹ä¸ºå¼‚æ­¥ç”Ÿæˆï¼ˆåå°é˜Ÿåˆ—ï¼‰
- [ ] å®Œå–„ `source_message_id` æå–é€»è¾‘
- [ ] æ·»åŠ  `source_url` æ„å»ºï¼ˆTelegram æ¶ˆæ¯é“¾æ¥ï¼‰
- [ ] é‡è¯•æœºåˆ¶ï¼ˆæŒ‡æ•°é€€é¿ï¼‰
- [ ] æœ¬åœ°é˜Ÿåˆ—é™çº§æ–¹æ¡ˆ
- [ ] æ‰¹é‡ embedding ç”Ÿæˆï¼ˆ10 æ¡/æ‰¹æ¬¡ï¼‰

**éªŒæ”¶æ ‡å‡†ï¼š**
- å†…å­˜ç¼“å­˜å‘½ä¸­ç‡ > 80%
- å•æ¡æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ < 100msï¼ˆå¼‚æ­¥ embeddingï¼‰
- æ•°æ®åº“æš‚æ—¶ä¸å¯ç”¨æ—¶ï¼Œæ¶ˆæ¯å†™å…¥æœ¬åœ°é˜Ÿåˆ—

---

**Phase 3: å‘é‡ç´¢å¼•ä¸é«˜çº§å»é‡** ğŸš€ ä¼˜å…ˆçº§ï¼šP2
- [ ] åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆivfflat/hnswï¼‰
- [ ] è¯­ä¹‰å»é‡é˜ˆå€¼åŠ¨æ€è°ƒä¼˜
- [ ] ç›¸ä¼¼æ¶ˆæ¯èšç±»åˆ†æ
- [ ] è·¨æ—¶é—´çª—å£å»é‡ï¼ˆ7 å¤©å†…ï¼‰
- [ ] å®šæ—¶ä»»åŠ¡ï¼šè¡¥é½å†å²æ•°æ® embedding

**éªŒæ”¶æ ‡å‡†ï¼š**
- å‘é‡æœç´¢å“åº”æ—¶é—´ < 50ms
- å»é‡å‡†ç¡®ç‡ > 98%
- è¯¯åˆ¤ç‡ < 1%

---

**Phase 4: æ€§èƒ½ä¼˜åŒ–ä¸ç›‘æ§** ğŸ“Š ä¼˜å…ˆçº§ï¼šP3
- [ ] æ‰¹é‡å†™å…¥ä¼˜åŒ–ï¼ˆç´¯ç§¯ 10 æ¡åæ‰¹é‡æäº¤ï¼‰
- [ ] æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–
- [ ] ç›‘æ§ä»ªè¡¨æ¿ï¼ˆGrafana/Supabase Dashboardï¼‰
- [ ] æ…¢æŸ¥è¯¢åˆ†æä¸ç´¢å¼•ä¼˜åŒ–
- [ ] æ•°æ®ä¿ç•™ç­–ç•¥ï¼ˆ30 å¤©åå½’æ¡£ `raw_response`ï¼‰
- [ ] å¤‡ä»½ä¸æ¢å¤æµç¨‹

**éªŒæ”¶æ ‡å‡†ï¼š**
- å†™å…¥å»¶è¿Ÿ P95 < 50ms
- æ•°æ®åº“ CPU ä½¿ç”¨ç‡ < 60%
- è‡ªåŠ¨å¤‡ä»½æ­£å¸¸è¿è¡Œ

---

**Phase 5: é«˜çº§åŠŸèƒ½** ğŸ”¬ ä¼˜å…ˆçº§ï¼šP4
- [ ] å®ç° `strategy_insights` è¡¨äººå·¥æ ‡æ³¨
- [ ] å®ç° `market_snapshots` è¡Œæƒ…å¿«ç…§
- [ ] ä¿¡å·å›æµ‹åˆ†æï¼ˆT+1h æ”¶ç›Šç‡ï¼‰
- [ ] å¤šç§Ÿæˆ·æ”¯æŒï¼ˆworkspace_idï¼‰
- [ ] Row Level Security (RLS) æƒé™æ§åˆ¶
- [ ] æ•°æ®å¯¼å‡ºåˆ° S3/Data Lake

**éªŒæ”¶æ ‡å‡†ï¼š**
- æ”¯æŒäººå·¥æ ‡æ³¨å’Œå¤ç›˜
- ä¿¡å·å‡†ç¡®ç‡å¯è¿½æº¯
- æ•°æ®å¯ä¾› BI åˆ†æ

### 8.7 é”™è¯¯å¤„ç†ä¸é™çº§ç­–ç•¥

**åˆ†å±‚é”™è¯¯å¤„ç†ï¼š**

```python
async def _persist_event(self, ...):
    if not self.config.ENABLE_DB_PERSISTENCE:
        logger.debug("æ•°æ®åº“æŒä¹…åŒ–å·²ç¦ç”¨ï¼Œè·³è¿‡å­˜å‚¨")
        return None

    try:
        # Level 1: å°è¯•ç›´æ¥å†™å…¥
        news_event_id = await self._try_insert_event(...)

        if signal_result:
            await self._try_insert_signal(news_event_id, signal_result)

        logger.debug("æ•°æ®æŒä¹…åŒ–æˆåŠŸ: news_event_id=%s", news_event_id)
        return news_event_id

    except DuplicateError as e:
        # å»é‡å†²çªï¼šæ­£å¸¸æƒ…å†µï¼Œä¸æ˜¯é”™è¯¯
        logger.debug("æ¶ˆæ¯å·²å­˜åœ¨ï¼Œè·³è¿‡: hash=%s", e.hash_raw)
        return e.existing_id

    except NetworkError as e:
        # Level 2: ç½‘ç»œé”™è¯¯ â†’ é‡è¯•
        logger.warning("ç½‘ç»œé”™è¯¯ï¼Œå°è¯•é‡è¯•: %s", e)
        return await self._retry_with_backoff(...)

    except SupabaseError as e:
        # Level 3: æ•°æ®åº“é”™è¯¯ â†’ é™çº§åˆ°æœ¬åœ°é˜Ÿåˆ—
        logger.error("Supabase é”™è¯¯ï¼Œé™çº§åˆ°æœ¬åœ°é˜Ÿåˆ—: %s", e)
        await self._write_to_local_queue(...)
        self.stats["db_fallback_count"] += 1
        return None

    except Exception as e:
        # Level 4: æœªçŸ¥é”™è¯¯ â†’ è®°å½•å¹¶ç»§ç»­
        logger.exception("æ•°æ®æŒä¹…åŒ–å¤±è´¥ï¼Œä½†ä¸å½±å“ä¸»æµç¨‹: %s", e)
        self.stats["db_error_count"] += 1
        return None
```

**é™çº§ç­–ç•¥çŸ©é˜µï¼š**

| é”™è¯¯ç±»å‹ | å¤„ç†ç­–ç•¥ | æ˜¯å¦é‡è¯• | æ˜¯å¦é™çº§ | æ˜¯å¦å‘Šè­¦ |
|---------|---------|---------|---------|---------|
| å”¯ä¸€ç´¢å¼•å†²çª | è·³è¿‡å†™å…¥ | âŒ | âŒ | âŒ |
| ç½‘ç»œè¶…æ—¶ | æŒ‡æ•°é€€é¿é‡è¯• | âœ… (3æ¬¡) | âœ… æœ¬åœ°é˜Ÿåˆ— | âš ï¸ |
| 503 Service Unavailable | é‡è¯• | âœ… (3æ¬¡) | âœ… æœ¬åœ°é˜Ÿåˆ— | âš ï¸ |
| 401/403 è®¤è¯é”™è¯¯ | ç«‹å³å¤±è´¥ | âŒ | âœ… ç¦ç”¨æŒä¹…åŒ– | ğŸš¨ |
| æ•°æ®æ ¼å¼é”™è¯¯ | è®°å½•æ—¥å¿— | âŒ | âŒ | ğŸš¨ |
| æœªçŸ¥å¼‚å¸¸ | æ•è·å¹¶ç»§ç»­ | âŒ | âœ… è®°å½•åˆ°æ–‡ä»¶ | ğŸš¨ |

**æœ¬åœ°é˜Ÿåˆ—è®¾è®¡ï¼š**

```python
# é˜Ÿåˆ—æ–‡ä»¶æ ¼å¼: data/db_queue/{timestamp}_{hash}.json
{
    "event_data": { ... },
    "signal_data": { ... },
    "retry_count": 0,
    "max_retries": 5,
    "created_at": "2025-10-02T10:30:00Z",
    "last_error": "Connection timeout"
}
```

**é˜Ÿåˆ—æ¢å¤ä»»åŠ¡ï¼š**
- æ¯ 5 åˆ†é’Ÿæ‰«æ `data/db_queue/` ç›®å½•
- æŒ‰æ—¶é—´é¡ºåºé‡è¯•å†™å…¥
- æˆåŠŸååˆ é™¤æ–‡ä»¶
- è¶…è¿‡ `max_retries` çš„æ–‡ä»¶ç§»è‡³ `data/db_failed/`

**ç›‘æ§æŒ‡æ ‡ï¼š**
- `db_success_rate`: æˆåŠŸç‡ï¼ˆç›®æ ‡ > 99.9%ï¼‰
- `db_avg_latency`: å¹³å‡å»¶è¿Ÿï¼ˆç›®æ ‡ < 50msï¼‰
- `db_fallback_count`: é™çº§æ¬¡æ•°ï¼ˆç›®æ ‡ < 10/å¤©ï¼‰
- `db_queue_size`: é˜Ÿåˆ—ç§¯å‹ï¼ˆç›®æ ‡ < 100ï¼‰

**å¥åº·æ£€æŸ¥ï¼š**
```python
async def health_check(self) -> bool:
    try:
        result = await supabase.from_("news_events").select("id").limit(1).execute()
        return result.data is not None
    except:
        return False
```

**ç†”æ–­æœºåˆ¶ï¼š**
```python
if self.stats["db_error_count"] > 50:  # 1 åˆ†é’Ÿå†… 50 æ¬¡é”™è¯¯
    logger.critical("æ•°æ®åº“è¿ç»­å¤±è´¥ï¼Œå¯åŠ¨ç†”æ–­ï¼Œç¦ç”¨æŒä¹…åŒ– 5 åˆ†é’Ÿ")
    self.config.ENABLE_DB_PERSISTENCE = False
    await asyncio.sleep(300)  # 5 åˆ†é’Ÿåæ¢å¤
    self.config.ENABLE_DB_PERSISTENCE = True
```

## 9. å‚è€ƒè§†å›¾

ä¸ºå¸¸è§æŸ¥è¯¢å‡†å¤‡è§†å›¾ç¤ºä¾‹ï¼š

```sql
create view v_signal_feed as
select
  s.id as signal_id,
  e.published_at,
  e.source,
  e.content_text,
  e.translated_text,
  s.summary_cn,
  s.event_type,
  s.assets,
  s.action,
  s.direction,
  s.confidence,
  s.risk_flags,
  s.links
from ai_signals s
join news_events e on e.id = s.news_event_id
where s.should_alert = true
order by e.published_at desc;
```

```sql
create materialized view mv_signal_perf_1h as
select
  s.id,
  s.assets,
  s.action,
  s.confidence,
  snap.price as price_t0,
  snap1h.price as price_t1h,
  snap1h.price - snap.price as delta_abs,
  (snap1h.price / nullif(snap.price, 0) - 1) as delta_pct
from ai_signals s
join market_snapshots snap on snap.asset = split_part(s.assets, ',', 1) and snap.captured_at = s.created_at
left join market_snapshots snap1h on snap1h.asset = snap.asset and snap1h.captured_at = s.created_at + interval '1 hour';
```

> materialized view å¯å¼‚æ­¥åˆ·æ–°ï¼Œä¾›æ—¥æŠ¥æˆ– BI ä½¿ç”¨ã€‚

## 10. åç»­æ‰©å±•

- è‹¥éœ€å…¨æ–‡æœç´¢ï¼Œå»ºè®®åœ¨ `news_events.content_text` ä¸Šå¯ç”¨ `pg_search` æˆ–æ¥å…¥ OpenSearchã€‚
- å¦‚éœ€å¤šç§Ÿæˆ·éš”ç¦»ï¼Œå¯åœ¨å„è¡¨å¢åŠ  `workspace_id`ï¼Œå¹¶ä¸ºè§†å›¾åŠ  `row level security`ã€‚
- å¯ä»¥å¯¹ `ai_signals.raw_response` åŠ `news_events.metadata` å®šæœŸè½åœ°åˆ° S3 + Icebergï¼Œä¸ºåç»­å¤§æ•°æ®åˆ†æåšå‡†å¤‡ã€‚
